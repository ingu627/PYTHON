# **머신러닝 정리**

### chapter 1

- 무엇(X)으로 무엇(Y)을 예측하고 싶다.
- 데이터(행렬)이어야 한다.
- 머신러닝 : 인공 지능의 한 분야로, 컴퓨터가 학습할 수 있도록 하는 알고리즘과 기술을 개발하는 분야를 말한다.
- y = f(x)  => f: 모형(머신 러닝 알고리즘)
  1. 주어진 데이터를 통해서 입력변수와 출력변수간의 관계를 만드는 함수 f를 만드는 것 
  2. 주어진 데이터 속에서 데이터의 특징을 찾아내는 함수f를 만드는 것 

- 머신 러닝으로 할 수 있는 것들(챕터 1.pdf 참조)
- f : 정해졌지만 알 수 없는 함수
- 오차항 : 예측값과 실제값의 차이 
- Y = f(X) + e



### chapter 2

- 지도 학습(supervised learning) : y=f(x)에 대하여 입력 변수(x)와 출력 변수(y)의 관계에 대하여 모델링하는 것(Y에 대하여 예측 또는 분류하는 문제)
- 회귀 = 연속형 변수 Y를 예측 / 분류 = 이산형 변수 Y를 예측
- 비지도 학습(unsupervised learning) : y가 존재하지 않고, 입력 변수(x)간의 관계에 대해 모델링 하는 것 => 군집 분석(유사한 데이터끼리 그룹화) / PCA : 독립변수들의 차원을 축소화
- 강화학습(reinforcement learning) : 수 많은 시뮬레이션을 통해 현재의 선택이 먼 미래에 보상이 최대가 되도록 학습 
  - Agent가 action을 취하고 환경에서 보상을 받고 이 보상이 최대가 되도록 최적의 action을 취하는 방법을 배움



### chapter 3

- 선형 회귀분석(Linear Regression) : 독립변수와 종속변수가 선형적인 관계가 있다라는 가정하에 분석
  - 직선을 통해 종속변수를 예측하기 때문에 독립변수의 중요도와 영향력을 파악하기 쉬움
- 의사결정나무(Decision Tree) : 독립 변수의 조건에 따라 종속변수를 분리 (비가 내린다 -> 축구를 하지 않는다.) / 이해하기 쉬우나 overfitting이 잘 일어남
- KNN(K-Nearest Neighbor) : 새로 들어온 데이터의 주변 k개의 데이터의 class로 분류하는 기법 (k는 사람이 지정한다 = hyper parameter)
- Neural Network : 입력, 은닉 출력층으로 구성된 모형으로서 각 층을 연결하는 노드의 가중치를 업데이트하면서 학습(Overfitting이 심하게 일어나고 학습시간이 매우 오래 걸림)
- SVM(Support Vector Machine) : Class 간의 거리(margin)가 최대가 되도록 decision boundary를 만드는 방법 (학습시간이 오래걸린다.)
- Ensemble(조합) Learning : 여러 개의(classifier or base learner)을 결합하여 사용하는 모델 
- K-means clustering : Label없이 데이터의 군집으로 k개로 생성 (k에 따라 군집이 결정됨)



### chapter 4 

- Deep Learning : 다층의 layter를 통해 복잡한 데이터의 학습이 가능토록 함 (graphical representation learning) / 알고리즘 및 GPU의 발전이 Deep learning의 부흥을 이끔
- 이미지 처리에 사용되는 CNN
- 기존 모델 : 각각의 픽셀 값늘어뜨려서)을 독립변수로 사용, 독립변수들은 각각 독립이라는 기본적인 가정에서 어긋남 => CNN : 이미지의 지역별 feature을 뽑아서 neural network학습
- 딥러닝은 다양한 형태로 발전
- 네트워크 구조의 발전 (ResNet, DenseNet 등)



### **chapter 5**

- GAN(Generative Adversarial Network) : Data를 만들어낸 Generator와 만들어진 data를 평가하는 Discriminator가 서로 대립(Adversarial)적으로 학습해가며 성능을 점차 개선해 나가자는 개념 (생성해 내는게 목적)

  - Discriminator를 학습시킬 때에는 D(x)가 1이 되고 D(G(z))가 0이 되도록 학습시킴

    (진짜 데이터를 진짜로 판별하고, 가짜데이터를 가짜로 판별할 수 있도록)

  - Generator를 학습시킬 때에는 D(G(z))가 1이 되도록 학습시킴

    (가짜 데이터를 discriminator가 구분못하도록 학습, discriminator를 헷갈리게 하도록)

- 강화학습 : Q-learning : 현재 상태에서부터 먼 미래까지 가장 큰 보상을 얻을 수 있는 행동을 학습하게 하는 것
- 논문 : 'Amplifying the imitation effect for reinforcement learning of UCAV's Mission Exeuction'



### chapter 6

