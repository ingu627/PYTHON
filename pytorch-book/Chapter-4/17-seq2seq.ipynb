{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Encoder-Decoder\n",
    "\n",
    "> 4.3 장에 해당하는 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 4-1\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"Encoder\"\"\"\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, n_layers, bidirec=False):\n",
    "        \"\"\"\n",
    "        args:\n",
    "         - vocab_size: 소스 단어장 크기\n",
    "         - embed_size: 인코더 임베딩 크기\n",
    "         - hidden_size: 인코더 히든 크기 \n",
    "         - n_layers: 인코더 층의 깊이\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.n_direc = 2 if bidirec else 1\n",
    "        # 인코더 임베딩 층\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        # 인코더 RNN 층\n",
    "        self.gru = nn.GRU(embed_size, \n",
    "                          hidden_size, \n",
    "                          n_layers, \n",
    "                          bidirectional=bidirec, \n",
    "                          batch_first=True)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        입력의 크기는 다음과 같으며 각 심볼이 의미하는 바는 다음과 같다.\n",
    "        Inputs:\n",
    "        - inputs: B, T_e\n",
    "        Outputs:\n",
    "        - outputs: B, T_e, n_directions*H_e\n",
    "        - hiddens: 1, B, n_directions*H_e\n",
    "        ==========================================\n",
    "        B: 미니배치 크기\n",
    "        T_e: 인코더에 입력된 문장의 최대 길이\n",
    "        E_e: 인코더 임베딩 크기\n",
    "        H_e: 인코더 은닉층 크기\n",
    "        \"\"\"\n",
    "        # 임베딩 된 텐서의 크기 변화: (B, T_e) > (B, T_e, E_e)\n",
    "        embeded = self.embedding(inputs)\n",
    "        \n",
    "        # gru 출력의 크기, output 은 안쓰이기 때문에 _ 에다 저장해주었다.\n",
    "        # output: (B, T_e, n_directions*H_e)\n",
    "        # hidden: (n_layers*n_directions, B, H_e)\n",
    "        _, hidden = self.gru(embeded)\n",
    "        \n",
    "        # 마지막 층의 은닉 상태를 가져오고 인코더의 출력으로 전달한다.\n",
    "        # 크기: (1, B, n_directions*H)\n",
    "        last_hidden = torch.cat([h for h in hidden[-self.n_direc:]], 1)\n",
    "        \n",
    "        return last_hidden.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 4-2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"Decoder\"\"\"\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, n_layers, sos_idx=2):\n",
    "        \"\"\"\n",
    "        args:\n",
    "         - vocab_size: 타겟 단어장 크기\n",
    "         - embed_size: 디코더 임베딩 크기\n",
    "         - hidden_size: 디코더 히든 크기 = \"인코더 히든 크기 * 인코더의 RNN 방향 개수\" 로 설정한다.\n",
    "         - n_layers: 디코더 층의 깊이\n",
    "         - sos_idx: 타겟 단어장에서 시작 토큰의 인덱스\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.sos_idx = sos_idx\n",
    "        # 디코더 임베딩 층\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        # 디코더 RNN 층\n",
    "        self.gru = nn.GRU(embed_size+hidden_size, hidden_size, n_layers, bidirectional=False, \n",
    "                          batch_first=True)\n",
    "        # 선형결합층\n",
    "        self.linear = nn.Linear(embed_size+2*hidden_size, vocab_size, bias=False)\n",
    "\n",
    "    def init_sos(self, batch_size, device):\n",
    "        # 시작을 알리는 <s> 토큰을 텐서로 생성한다. 크기는 (B, 1)\n",
    "        return torch.LongTensor([self.sos_idx]*batch_size).unsqueeze(1).to(device)\n",
    "    \n",
    "    def forward(self, hiddens, maxlen=None, eos_idx=None):\n",
    "        \"\"\"\n",
    "        입력의 크기는 다음과 같으며 각 심볼이 의미하는 바는 다음과 같다.\n",
    "        Inputs:\n",
    "        - hiddens: 1, B, n_direction(encoder)*H_d \n",
    "        - max_len: T_d\n",
    "        - eos_idx: 테스트 용도\n",
    "        Outputs:\n",
    "        - scores: results of all predictions = B, T_d, vocab_size\n",
    "        ==========================================\n",
    "        B: 미니배치 크기\n",
    "        T_d: 디코더에 입력된 문장의 최대 길이\n",
    "        E_d: 디코더 임베딩 크기\n",
    "        H_d: 디코더 은닉층 크기\n",
    "        \"\"\"\n",
    "        maxlen = 32 if maxlen is None else maxlen\n",
    "        \n",
    "        # 시작 토큰으로 디코더 입력값을 초기화 한다. 크기는 (B, 1)\n",
    "        inputs = self.init_sos(hiddens.size(1), device=hiddens.device)\n",
    "        \n",
    "        # 임베딩 층을 통과한다. 크기는 (B, 1, E_d)\n",
    "        embeded = self.embedding(inputs)\n",
    "        \n",
    "        # 인코더에서 가져온 은닉층을 디코더의 초기화 값으로 적용하기 위해 디코더 RNN 층의 개수로 맞춰준다.\n",
    "        # 크기 변화: (1, B, H_d) > (n_layers, B, H_d)\n",
    "        if hiddens.size(0) != self.n_layers: \n",
    "            hiddens = hiddens.repeat(self.n_layers, 1, 1)\n",
    "        \n",
    "        # 손실함수에 전달하기 위해 예측 스코어를 저장한다.\n",
    "        scores = []  \n",
    "        \n",
    "        for i in range(1, maxlen):\n",
    "            # RNN에 들어갈 입력값을 만들어준다 concat(y_{t-1}, c)\n",
    "            # cat[(B, 1, E_d), (B, 1, H_d)] > (B, seq_len=1, E_d+H_d)\n",
    "            inputs = torch.cat((embeded, hiddens[-1, :, :].unsqueeze(1)), dim=2)\n",
    "            \n",
    "            # RNN 출력 값을 얻는다. h_t = f(h{i-1}, y{i-1}, c): \n",
    "            # 크기변화 (B, 1, E_d+H_d) > (n_layers, B, H_d)\n",
    "            _, hiddens = self.gru(inputs, hiddens)\n",
    "            \n",
    "            # 확률을 예측하기 전, 선형결합의 출력값을 얻는다\n",
    "            # score = g(h{i}, y{i-1}, c)\n",
    "            # 합쳐진 입력값(inputs)과 RNN의 마지막 층의 정보(hiddens)를 결합한다.\n",
    "            # 크기 변화: cat[(B, E_d+H_d), (B, H_d)] > (B, E_d+H_d+H_d)\n",
    "            linear_inputs = torch.cat((inputs.squeeze(1), hiddens[-1, :, :]), dim=1)\n",
    "            # linear 크기 변화: (B, E_d+H_d+H_d) > (B, vocab_size)\n",
    "            score = self.linear(linear_inputs)\n",
    "            scores.append(score)\n",
    "            \n",
    "            # score를 바탕으로 다음 타겟 토큰을 예측한다.\n",
    "            inputs, stop_decode = self.decode(score=score, eos_idx=eos_idx)\n",
    "            if stop_decode:\n",
    "                break\n",
    "        # 손실함수에 전달하기 위해 텐서의 형태를 변화한다. \n",
    "        # (T_d, B, vocab_size) > (B, T_d, vocab_size)\n",
    "        scores = torch.stack(scores).permute(1, 0, 2).contiguous()  \n",
    "        return scores\n",
    "    \n",
    "    def decode(self, score, eos_idx=None):\n",
    "        \"\"\"\n",
    "        score를 기반으로 다음 타겟 토큰을 예측한다. \n",
    "        다음 타겟 토큰을 임베딩 층을 통과시킨 값을 출력으로 반환한다\n",
    "        \"\"\"\n",
    "        # 테스트 단계에서 디코드를 멈춰야할지 결정하는 변수, 훈련시 사용안한다.\n",
    "        stop_decode = False\n",
    "        \n",
    "        # 다음 토큰 예측\n",
    "        pred = score.softmax(-1).argmax(-1)\n",
    "        \n",
    "        # 다음 타겟 토큰을 임베딩 층으로 건낸다. \n",
    "        # 크기변화: (B, 1) > (B, 1, E_d)\n",
    "        inputs = self.embedding(pred)\n",
    "        \n",
    "        if (eos_idx is not None) and (pred.view(-1).item() == eos_idx):\n",
    "            stop_decode = True\n",
    "        \n",
    "        return inputs, stop_decode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: Encoder-Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 4-3\n",
    "\n",
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"Encoder - Decoder\"\"\"\n",
    "    def __init__(self, enc_vocab_size, dec_vocab_size, embed_size, hidden_size, \n",
    "                 num_layers, batch_first=True, bidirec=False, sos_idx=2, ):\n",
    "        \"\"\"\n",
    "        단순 Encoder와 Decoder 를 연결시킨 클래스다.\n",
    "        \n",
    "        args:\n",
    "         - enc_vocab_size: 소스 단어장 크기\n",
    "         - dec_vocab_size: 타겟 단어장 크기\n",
    "         - embed_size: 임베딩 크기\n",
    "         - hidden_size: RNN 은닉층 크기\n",
    "         - num_layers: RNN 층수\n",
    "         - batch_first: 미니배치 크기가 텐서의 제일 앞에 오는 지의 여부\n",
    "         - bidirec: 인코더 RNN 층의 양방향 여부\n",
    "         - sos_idx: \n",
    "        \"\"\"\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        n_direct = 2 if bidirec else 1\n",
    "        self.encoder = Encoder(vocab_size=enc_vocab_size, \n",
    "                               embed_size=embed_size, \n",
    "                               hidden_size=hidden_size, \n",
    "                               n_layers=num_layers, \n",
    "                               bidirec=bidirec)\n",
    "        self.decoder = Decoder(vocab_size=dec_vocab_size, \n",
    "                               embed_size=embed_size, \n",
    "                               hidden_size=n_direct*hidden_size, \n",
    "                               n_layers=num_layers, \n",
    "                               sos_idx=sos_idx)\n",
    "        \n",
    "    def forward(self, inputs, maxlen=None, eos_idx=None):\n",
    "        \"\"\"\n",
    "        scores 크기: (B, T_d, vocab_size)\n",
    "        \"\"\"\n",
    "        enc_outputs = self.encoder(inputs)\n",
    "        scores = self.decoder(enc_outputs, maxlen, eos_idx)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 예제 소스-타겟 문장\n",
    "src = \"나 는 가수 다 .\".split()\n",
    "trg = \"<s> I am Singer . </s>\".split()\n",
    "\n",
    "# 단어장을 만드는 함수\n",
    "build_vocab = lambda x: {tkn: i for i, tkn in enumerate(x)}\n",
    "\n",
    "# 수치화를 하는 함수\n",
    "numericalize = lambda x, vocab: torch.LongTensor([vocab.get(tkn) for tkn in x]).unsqueeze(0)\n",
    "\n",
    "# 단어장 생성\n",
    "src_vocab = build_vocab(src)\n",
    "trg_vocab = build_vocab(trg)\n",
    "\n",
    "# 문장의 수치화\n",
    "src_data = numericalize(src, src_vocab)\n",
    "trg_data = numericalize(trg, trg_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 선언에 필요한 인자 설정\n",
    "enc_vocab_size = len(src_vocab)\n",
    "dec_vocab_size = len(trg_vocab)  \n",
    "embed_size = 5  # E: 임베딩 크기\n",
    "hidden_size = 10  # D: 은닉층 크기\n",
    "num_layers = 3  # RNN 층의 개수\n",
    "batch_first = True  # RNN 입력의 첫번째 차원이 미니배치 크기인 경우 활성화\n",
    "bidirec = True  # 양방향 순환 신경망 사용 여부\n",
    "device = 'cpu'\n",
    "\n",
    "# 모델 선언\n",
    "model = EncoderDecoder(\n",
    "    enc_vocab_size=enc_vocab_size, \n",
    "    dec_vocab_size=dec_vocab_size, \n",
    "    embed_size=embed_size, \n",
    "    hidden_size=hidden_size, \n",
    "    num_layers=num_layers, \n",
    "    batch_first=True, \n",
    "    bidirec=bidirec, \n",
    "    sos_idx=0).to(device)\n",
    "\n",
    "# 손실함수와 옵티마이저 선언\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "sgd_optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [1] Loss: 1.8012\n",
      "Step [11] Loss: 1.2208\n",
      "Step [21] Loss: 0.6760\n",
      "Step [31] Loss: 0.3335\n",
      "Step [41] Loss: 0.1342\n",
      "Step [51] Loss: 0.0528\n",
      "Step [61] Loss: 0.0278\n",
      "Step [71] Loss: 0.0178\n",
      "Step [81] Loss: 0.0129\n",
      "Step [91] Loss: 0.0102\n"
     ]
    }
   ],
   "source": [
    "for step in range(100):\n",
    "    \n",
    "    model.train()\n",
    "    sgd_optimizer.zero_grad()\n",
    "    scores = model(src_data, maxlen=trg_data.size(1))\n",
    "    train_loss = loss_function(scores.view(-1, scores.size(-1)), \n",
    "                               trg_data[:, 1:].contiguous().view(-1))\n",
    "    train_loss.backward()\n",
    "    sgd_optimizer.step()\n",
    "    if step % 10 == 0:\n",
    "        print(\"Step [{}] Loss: {:.4f}\".format(step+1, train_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:  나 는 가수 다 .\n",
      "Target:  I am Singer .\n",
      "Predicted:  I am Singer .\n"
     ]
    }
   ],
   "source": [
    "# 모델 테스트\n",
    "model.eval()\n",
    "scores = model(src_data, maxlen=50, eos_idx=trg_vocab['</s>'])\n",
    "preds = scores.softmax(-1).argmax(-1).squeeze().tolist()[:-1]\n",
    "inv_trg_vocab = {v: k for k, v in trg_vocab.items()}\n",
    "\n",
    "print(\"Source: \",\" \".join(src))\n",
    "print(\"Target: \",\" \".join(trg[1:-1]))\n",
    "print(\"Predicted: \",\" \".join([inv_trg_vocab.get(i) for i in preds]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(torchenv)",
   "language": "python",
   "name": "torchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
