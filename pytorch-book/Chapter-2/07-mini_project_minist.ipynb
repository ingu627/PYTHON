{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-Project: 나만의 딥러닝 모델로 Mnist Dataset 학습하기\n",
    "\n",
    "> 2.2.8 장에 해당하는 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 패키기 불러오기 및 GUI 프로그램 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 2-22\n",
    "\n",
    "import os\n",
    "# matplotlib 패키지 결과물을 노트북을 실행한 브라우저 안에 보일 수 있도록 하는 명령어다. \n",
    "%matplotlib inline\n",
    "# numpy 와 pytorch 패키지 불러오기 \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# 데이터로더 및 mnist 가 내장 되어있는 torchvision 패키지에서 데이터셋 불러오기\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# 손글씨를 써볼 수 있는 GUI 프로그램\n",
    "from drawing import Drawing\n",
    "# 그림 시각화 처리를 위한 패키지\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def drawing_custom_number(preprocess, filepath=\"./figs\", return_img=True):\n",
    "    \"\"\"손글씨 입력 GUI 미니 프로그램\"\"\"\n",
    "    if (not os.path.isdir(\"figs\")) and (filepath == \"./figs\"):\n",
    "        os.mkdir(\"figs\")\n",
    "    draw = Drawing()\n",
    "    draw.main(preprocess=preprocess, filepath=filepath)\n",
    "    img = Image.open(draw.file)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.show()\n",
    "    if return_img:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0\n",
      "Size of Image: (28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 코드 2-23\n",
    "\n",
    "torch.manual_seed(70)\n",
    "\n",
    "# 데이터셋 정의하기\n",
    "train_dataset = datasets.MNIST(root='./data',  # 데이터 경로\n",
    "                               train=True,  # 훈련데이터의 여부\n",
    "                               download=True,  # 기존에 없다면 root 경로에 다운로드를 받게 된다.\n",
    "                               transform=transforms.ToTensor())  # 텐서로 바꾸는 전처리를 한다.\n",
    "test_dataset = datasets.MNIST(root='./data', # 데이터 경로\n",
    "                              train=False,  # 훈련데이터의 여부\n",
    "                              transform=transforms.ToTensor())  # 텐서로 바꾸는 전처리를 한다.\n",
    "\n",
    "# 데이터 살펴보기: 훈련데이터 중 임의의 데이터를 골라서 보여준다\n",
    "idx = torch.randint(0, len(train_dataset), (1,)).item()\n",
    "random_image = train_dataset[idx][0].squeeze().numpy()\n",
    "target_num = train_dataset[idx][1]\n",
    "print(\"Target: {}\".format(target_num))\n",
    "print(\"Size of Image: {}\".format(random_image.shape))\n",
    "plt.imshow(random_image, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 2-24\n",
    "\n",
    "# 미니배치크기\n",
    "BATCH = 64\n",
    "# 디바이스 설정: cuda 사용할지 cpu 사용할지\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# 총 스텝 크기\n",
    "STEP = 10\n",
    "\n",
    "# 훈련 데이터로더 선언\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH, \n",
    "                          shuffle=True)\n",
    "# 테스트 데이터 로더 설정\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH, \n",
    "                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for (data, target) in train_loader:\n",
    "    print(data.size(), target.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 2-30\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.flatten = lambda x: x.view(x.size(0), -1)\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear3 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 2-25\n",
    "\n",
    "# 모델 선언\n",
    "model = Net(input_size=28*28, hidden_size=100, output_size=10).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 89610\n"
     ]
    }
   ],
   "source": [
    "# 코드 2-26\n",
    "\n",
    "# 손실함수와 옵티마이저 선언\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# 매개변수 개수 확인하기\n",
    "num_params = 0\n",
    "for params in model.parameters():\n",
    "    num_params += params.view(-1).size(0)\n",
    "print(\"Total number of parameters: {}\".format(num_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 2-27\n",
    "\n",
    "def train(model, train_loader, loss_func, optimizer, step, device, print_step=200):\n",
    "    \"\"\"train function: 1 스텝 동안 발생하는 학습과정\"\"\"\n",
    "    # 모델에게 훈련단계이라고 선언함\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # 입력과 타겟 텐서에 GPU 를 사용여부 전달\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # 경사 초기화\n",
    "        model.zero_grad()\n",
    "        # 순방향 전파\n",
    "        output = model(data)\n",
    "        # 손실값 계산\n",
    "        loss = loss_func(output, target)\n",
    "        # 역방향 전파\n",
    "        loss.backward()\n",
    "        # 매개변수 업데이트\n",
    "        optimizer.step()\n",
    "        # 중간 과정 print\n",
    "        if batch_idx % print_step == 0:\n",
    "            print('Train Step: {} ({:05.2f}%)  \\tLoss: {:.4f}'.format(\n",
    "                step, 100.*(batch_idx*train_loader.batch_size)/len(train_loader.dataset), \n",
    "                loss.item()))\n",
    "            \n",
    "def test(model, test_loader, loss_func, device):\n",
    "    \"\"\"test function\"\"\"\n",
    "    # 모델에게 평가단계이라고 선언함\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            # 입력과 타겟 텐서에 GPU 를 사용여부 전달\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # 순방향전파\n",
    "            output = model(data)\n",
    "            # 손실값 계산(합)\n",
    "            test_loss += loss_func(output, target, reduction=\"sum\").item()\n",
    "            # 예측 값에 해당하는 클래스 번호 반환\n",
    "            pred = output.softmax(1).argmax(dim=1, keepdim=True)\n",
    "            # 정확하게 예측한 개수를 기록한다\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc = correct / len(test_loader.dataset)\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:05.2f}%)'.format(\n",
    "        test_loss, correct, len(test_loader.dataset), 100. * test_acc))\n",
    "    return test_loss, test_acc\n",
    "\n",
    "def main(model, train_loader, test_loader, loss_func, optimizer, n_step, device, save_path=None, print_step=200):\n",
    "    \"\"\"메인 학습 함수\"\"\"\n",
    "    test_accs = []\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for step in range(1, n_step+1):\n",
    "        # 훈련 단계\n",
    "        train(model, train_loader, loss_func, optimizer, \n",
    "              step=step, device=device, print_step=print_step)\n",
    "        # 평가 단계\n",
    "        test_loss, test_acc = test(model, test_loader, \n",
    "                                   loss_func=F.cross_entropy, \n",
    "                                   device=device)\n",
    "        # 테스트 정확도 기록\n",
    "        test_accs.append(test_acc)\n",
    "        # 모델 최적의 매개변수값을 저장할지 결정하고 기록한다.\n",
    "        if len(test_accs) >= 2:\n",
    "            if test_acc >= best_acc:\n",
    "                best_acc = test_acc\n",
    "                best_state_dict = model.state_dict()\n",
    "                print(\"discard previous state, best model state saved!\")\n",
    "        print(\"\")\n",
    "\n",
    "    # 매개변수 값 저장하기\n",
    "    if save_path is not None:\n",
    "        torch.save(best_state_dict, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Step: 1 (00.00%)  \tLoss: 2.3176\n",
      "Train Step: 1 (21.33%)  \tLoss: 0.2704\n",
      "Train Step: 1 (42.67%)  \tLoss: 0.3944\n",
      "Train Step: 1 (64.00%)  \tLoss: 0.1376\n",
      "Train Step: 1 (85.33%)  \tLoss: 0.2473\n",
      "Test set: Average loss: 0.1566, Accuracy: 9543/10000 (95.43%)\n",
      "\n",
      "Train Step: 2 (00.00%)  \tLoss: 0.2037\n",
      "Train Step: 2 (21.33%)  \tLoss: 0.1473\n",
      "Train Step: 2 (42.67%)  \tLoss: 0.1313\n",
      "Train Step: 2 (64.00%)  \tLoss: 0.1170\n",
      "Train Step: 2 (85.33%)  \tLoss: 0.0972\n",
      "Test set: Average loss: 0.1198, Accuracy: 9610/10000 (96.10%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 3 (00.00%)  \tLoss: 0.0749\n",
      "Train Step: 3 (21.33%)  \tLoss: 0.1048\n",
      "Train Step: 3 (42.67%)  \tLoss: 0.0381\n",
      "Train Step: 3 (64.00%)  \tLoss: 0.0404\n",
      "Train Step: 3 (85.33%)  \tLoss: 0.0462\n",
      "Test set: Average loss: 0.1066, Accuracy: 9662/10000 (96.62%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 4 (00.00%)  \tLoss: 0.0631\n",
      "Train Step: 4 (21.33%)  \tLoss: 0.0844\n",
      "Train Step: 4 (42.67%)  \tLoss: 0.0425\n",
      "Train Step: 4 (64.00%)  \tLoss: 0.0341\n",
      "Train Step: 4 (85.33%)  \tLoss: 0.0798\n",
      "Test set: Average loss: 0.0888, Accuracy: 9721/10000 (97.21%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 5 (00.00%)  \tLoss: 0.0155\n",
      "Train Step: 5 (21.33%)  \tLoss: 0.1525\n",
      "Train Step: 5 (42.67%)  \tLoss: 0.0196\n",
      "Train Step: 5 (64.00%)  \tLoss: 0.0421\n",
      "Train Step: 5 (85.33%)  \tLoss: 0.0361\n",
      "Test set: Average loss: 0.0906, Accuracy: 9718/10000 (97.18%)\n",
      "\n",
      "Train Step: 6 (00.00%)  \tLoss: 0.0214\n",
      "Train Step: 6 (21.33%)  \tLoss: 0.0265\n",
      "Train Step: 6 (42.67%)  \tLoss: 0.0912\n",
      "Train Step: 6 (64.00%)  \tLoss: 0.0678\n",
      "Train Step: 6 (85.33%)  \tLoss: 0.0150\n",
      "Test set: Average loss: 0.0797, Accuracy: 9767/10000 (97.67%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 7 (00.00%)  \tLoss: 0.0510\n",
      "Train Step: 7 (21.33%)  \tLoss: 0.0306\n",
      "Train Step: 7 (42.67%)  \tLoss: 0.0495\n",
      "Train Step: 7 (64.00%)  \tLoss: 0.0219\n",
      "Train Step: 7 (85.33%)  \tLoss: 0.0104\n",
      "Test set: Average loss: 0.0896, Accuracy: 9742/10000 (97.42%)\n",
      "\n",
      "Train Step: 8 (00.00%)  \tLoss: 0.0198\n",
      "Train Step: 8 (21.33%)  \tLoss: 0.0558\n",
      "Train Step: 8 (42.67%)  \tLoss: 0.0046\n",
      "Train Step: 8 (64.00%)  \tLoss: 0.0162\n",
      "Train Step: 8 (85.33%)  \tLoss: 0.0485\n",
      "Test set: Average loss: 0.0845, Accuracy: 9755/10000 (97.55%)\n",
      "\n",
      "Train Step: 9 (00.00%)  \tLoss: 0.0835\n",
      "Train Step: 9 (21.33%)  \tLoss: 0.0571\n",
      "Train Step: 9 (42.67%)  \tLoss: 0.0281\n",
      "Train Step: 9 (64.00%)  \tLoss: 0.0133\n",
      "Train Step: 9 (85.33%)  \tLoss: 0.1205\n",
      "Test set: Average loss: 0.0839, Accuracy: 9761/10000 (97.61%)\n",
      "\n",
      "Train Step: 10 (00.00%)  \tLoss: 0.0048\n",
      "Train Step: 10 (21.33%)  \tLoss: 0.0023\n",
      "Train Step: 10 (42.67%)  \tLoss: 0.0027\n",
      "Train Step: 10 (64.00%)  \tLoss: 0.0094\n",
      "Train Step: 10 (85.33%)  \tLoss: 0.0429\n",
      "Test set: Average loss: 0.0909, Accuracy: 9765/10000 (97.65%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 코드 2-28\n",
    "\n",
    "main(model=model, \n",
    "     train_loader=train_loader, \n",
    "     test_loader=test_loader, \n",
    "     loss_func=loss_function, \n",
    "     optimizer=optimizer, \n",
    "     n_step=STEP,\n",
    "     device=DEVICE,\n",
    "     save_path=\"mnist_model.pt\", \n",
    "     print_step=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved ./figs/img.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 만약에 해당 프로그램이 계속 실행안되고 재시작을 한다면 ssh 접속시\n",
    "# $ ssh -Y [host 이름]\n",
    "# 으로 실행해주시면 됩니다.\n",
    "img = drawing_custom_number(preprocess=True, return_img=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted number is 7.\n"
     ]
    }
   ],
   "source": [
    "# 코드 2-29\n",
    "\n",
    "# 내가 그린 이미지 테스트\n",
    "# 이미지를 (1, 28, 28) 크기의 텐서로 바꿔준다\n",
    "test_input = torch.Tensor(np.array(img)).unsqueeze(0).to(DEVICE)\n",
    "pred = model(test_input)\n",
    "print(\"Predicted number is {}.\".format(pred.softmax(1).argmax().item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(torchenv)",
   "language": "python",
   "name": "torchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
