{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 토큰화(Tokenization)\r\n",
    "- 주어진 코퍼스(corpus)에서 토큰(token)이라 불리는 단위로 나누는 \r\n",
    "- 토큰의 단위가 상황에 따라 다르지만, 보통 의미있는 단위로 토큰을 정의"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# 구두점이란, 마침표(.), 컴마(,), 물음표(?), 세미콜론(;), 느낌표(!) 등과 같은 기호\r\n",
    "# NLTK는 영어 코퍼스를 토큰화하기 위한 도구들을 제공\r\n",
    "from nltk.tokenize import word_tokenize"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "print(word_tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))  "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Do', \"n't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr.', 'Jone', \"'s\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from nltk.tokenize import sent_tokenize\r\n",
    "\r\n",
    "# sent_tokenize : 영어 문장의 토큰화를 수행"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "text=\"His barber kept his word.\\\r\n",
    " But keeping such a huge secret to himself was driving him crazy. \\\r\n",
    "  Finally, the barber went up a mountain and almost to the edge of a cliff. \\\r\n",
    "  He dug a hole in the midst of some reeds. He looked about, to make sure no one was near.\"\r\n",
    "print(sent_tokenize(text))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['His barber kept his word.', 'But keeping such a huge secret to himself was driving him crazy.', 'Finally, the barber went up a mountain and almost to the edge of a cliff.', 'He dug a hole in the midst of some reeds.', 'He looked about, to make sure no one was near.']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "text=\"I am actively looking for Ph.D. students. and you are a Ph.D student.\"\r\n",
    "print(sent_tokenize(text))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['I am actively looking for Ph.D. students.', 'and you are a Ph.D student.']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# !pip install kss"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting kss\n",
      "  Downloading kss-3.1.0.4.tar.gz (42.3 MB)\n",
      "Collecting emoji\n",
      "  Downloading emoji-1.4.2.tar.gz (184 kB)\n",
      "Building wheels for collected packages: kss, emoji\n",
      "  Building wheel for kss (setup.py): started\n",
      "  Building wheel for kss (setup.py): finished with status 'done'\n",
      "  Created wheel for kss: filename=kss-3.1.0.4-py3-none-any.whl size=42336579 sha256=aee218cb10dbdb43f4254f50465fd7cfedc72c92689e60dafb4227f81e8d2c00\n",
      "  Stored in directory: c:\\users\\poeun\\appdata\\local\\pip\\cache\\wheels\\65\\7e\\ae\\6b3a20a8451b2c8154e8f6fc599ffab090cd113c60c65b8f14\n",
      "  Building wheel for emoji (setup.py): started\n",
      "  Building wheel for emoji (setup.py): finished with status 'done'\n",
      "  Created wheel for emoji: filename=emoji-1.4.2-py3-none-any.whl size=186452 sha256=c5ddcd65314a2326dec500cb7c4e8321c4c05f7f89f7d59f48c847eb655f8b49\n",
      "  Stored in directory: c:\\users\\poeun\\appdata\\local\\pip\\cache\\wheels\\71\\4d\\3c\\cada364d4ea0026deee7208dee1e61bcebd20aa2ae5dc154ba\n",
      "Successfully built kss emoji\n",
      "Installing collected packages: emoji, kss\n",
      "Successfully installed emoji-1.4.2 kss-3.1.0.4\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import kss"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Korean Sentence Splitter]: Initializing Kss...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "text='딥 러닝 자연어 처리가 재미있기는 합니다. \\\r\n",
    "그런데 문제는 영어보다 한국어로 할 때 너무 어려워요. \\\r\n",
    "농담아니에요. 이제 해보면 알걸요?'\r\n",
    "print(kss.split_sentences(text))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['딥 러닝 자연어 처리가 재미있기는 합니다.', '그런데 문제는 영어보다 한국어로 할 때 너무 어려워요. 농담아니에요.', '이제 해보면 알걸요?']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 대부분의 한국어 NLP에서 조사는 분리해줄 필요가 있습니다.\r\n",
    "# 형태소(morpheme)란 뜻을 가진 가장 작은 말의 단위\r\n",
    "# 자립 형태소 : 접사, 어미, 조사와 상관없이 자립하여 사용할 수 있는 형태소.\r\n",
    "# 그 자체로 단어가 된다. 체언(명사, 대명사, 수사), 수식언(관형사, 부사), 감탄사 등이 있다.\r\n",
    "# 의존 형태소 : 다른 형태소와 결합하여 사용되는 형태소. 접사, 어미, 조사, 어간를 말한다.\r\n",
    "\r\n",
    "# ex) 문장 : 에디가 딥러닝책을 읽었다\r\n",
    "# 자립 형태소 : 에디, 딥러닝책\r\n",
    "# 의존 형태소 : -가, -을, 읽-, -었, -다\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "01612b57d529331fccfbf5f7721e88005b4682ef99b242f62a508f06b6f08c6a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}