{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "\n",
    "미리 만들어둔 document - term matrix 를 이용하여 LDA 를 학습합니다. X 는 (document, term) matrix 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soynlp=0.0.49\n",
      "added lovit_textmining_dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30091, 9774)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import config\n",
    "from lovit_textmining_dataset.navernews_10days import get_bow\n",
    "\n",
    "TRAIN_LDA = True\n",
    "\n",
    "x, idx_to_vocab, vocab_to_idx = get_bow(date='2016-10-20', tokenize='noun')\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version check\n",
    "\n",
    "Gensim 은 scipy 를 이용합니다. 이전 버전의 scipy 를 이용하는 경우 학습 시 오류가 발생할 수 있습니다. scipy 의 버전을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gensim == 3.6.0\n",
      "scipy == 1.1.0\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import scipy\n",
    "\n",
    "print('gensim == {}'.format(gensim.__version__))\n",
    "print('scipy == {}'.format(scipy.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data format\n",
    "\n",
    "Gensim 의 LDA 가 이용하는 학습데이터의 형식 각 문서를 list of tuple 로 표현하는 Corpus 라는 형식입니다. tuple 은 (term_index, frequency) 입니다.\n",
    "\n",
    "```\n",
    "from gensim import corpora\n",
    "\n",
    "# create a toy corpus of 2 documents, as a plain Python list\n",
    "corpus = [[(1, 0.5)], []]\n",
    "```\n",
    "\n",
    "scikit-learn 을 이용하여 sparse matrix 를 미리 만들었다면 gensim.matutils.Sparse2Corpus 를 이용하여 이를 변형합니다. 그런데, gensim 은 sparse matrix 를(term, doc) matrix 라고 가정합니다. 그래서 Sparse2Corpus 의 documents_columns 를 False 로 지정해줍니다. Default 는 True 입니다. Corpus format 은 [여기][corpus_format]를 참고하세요\n",
    "\n",
    "```\n",
    "from scipy.io import mmread\n",
    "\n",
    "scipy_sparse_matrix = mmread(mm_fname)    \n",
    "# corpus = gensim.matutils.Sparse2Corpus(scipy_sparse_matrix)\n",
    "corpus = gensim.matutils.Sparse2Corpus(x, documents_columns=False)\n",
    "```\n",
    "\n",
    "\n",
    "[corpus_format]: https://radimrehurek.com/gensim/tut1.html#corpus-formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#doc= 0:  [] ...\n",
      "#doc= 1:  [(200, 1), (219, 1), (593, 1), (349, 1)] ...\n",
      "#doc= 2:  [(6161, 1), (8337, 2), (6274, 7), (1104, 3), (4627, 7), (6017, 5), (1244, 8), (1499, 1), (234, 4), (6170, 9)] ...\n",
      "#doc= 3:  [(6017, 2), (234, 1), (5668, 1), (9051, 2), (3732, 1), (8883, 1), (6738, 1), (5179, 1), (1997, 1), (4797, 1)] ...\n"
     ]
    }
   ],
   "source": [
    "corpus = gensim.matutils.Sparse2Corpus(x, documents_columns=False)\n",
    "\n",
    "for i, doc in enumerate(corpus):\n",
    "    if i > 3: break\n",
    "    print('#doc= %d: ' % i, doc[:10], '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30,091 개의 문서임을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30091"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim LDA 는 각 column index 에 해당하는 단어를 list of str 이 아닌 {int:str} 형식으로 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'아이오아이'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word = dict(enumerate(idx_to_vocab))\n",
    "id2word[5537]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LDA\n",
    "\n",
    "이제 데이터를 gensim LDA format으로 맞추는 일이 끝났습니다.\n",
    "\n",
    "num_topics 는 토픽의 개수를 정하는 부분입니다. id2word 를 입력하지 않으면 단어가 term index 로 출력됩니다. Gensim 의 id2word 는 list of str 이 아닌, dict 구조여야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lovit/anaconda2/envs/scrapper/lib/python3.6/site-packages/gensim/models/ldamodel.py:1023: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 19s, sys: 6min 24s, total: 8min 43s\n",
      "Wall time: 49.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "ldamodel_fname = './2016-10-20-lda.pkl'\n",
    "\n",
    "if TRAIN_LDA:\n",
    "    ldamodel = LdaModel(corpus=corpus, num_topics=100, id2word=id2word)\n",
    "    import pickle\n",
    "    with open(ldamodel_fname, 'wb') as f:\n",
    "        pickle.dump(ldamodel, f)\n",
    "else:\n",
    "    with open(ldamodel_fname, 'rb') as f:\n",
    "        ldamodel = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print_topic은 특정 topic에 대하여 설명력이 좋은 (topic probability가 높은) topn개의 단어를 prob.와 함께 출력해줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.103*\"브랜드\" + 0.031*\"6개\" + 0.025*\"공간\" + 0.025*\"시즌\" + 0.023*\"냉장고\"'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.print_topic(0, topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 topic 의 단어생성확률은 아래의 함수로 가져올 수 있습니다. LdaModel.expElogbeta 에도 비슷한 정보가 포함되어 있지만, 이는 학습에 이용하는 temporal variable 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 9774)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.expElogbeta.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확한 topic - term probability 는 아래의 함수를 이용해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 9774)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_topic_term_prob(lda_model):\n",
    "    topic_term_freqs = lda_model.state.get_lambda()\n",
    "    topic_term_prob = topic_term_freqs / topic_term_freqs.sum(axis=1)[:, None]\n",
    "    return topic_term_prob\n",
    "\n",
    "beta = get_topic_term_prob(ldamodel)\n",
    "beta.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 topic 별로 생성 확률이 큰 10 개의 단어들을 선택합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10)\n"
     ]
    }
   ],
   "source": [
    "topn = 10\n",
    "important_terms = beta.argsort(axis=1)[:,-topn:]\n",
    "print(important_terms.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 print_topic() 함수의 결과는 아래의 과정을 거쳐 출력된 함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "topic #0 : 브랜드 6개 공간 시즌 냉장고 출시 보관 신제품 마케팅 이지\n",
      "topic #1 : 공개 출연 영화 사진 매력 선보 앨범 기자 함께 팬들\n",
      "topic #2 : 감독 주지홍 제작진 김윤혜 친구 기자 첫사랑 세상 모습 종영\n",
      "topic #3 : 훈련 기뢰 가계대출 개편 기대감 218 해군 실전 계열사인 레드\n",
      "topic #4 : 중국 미국 대통령 주석 베이징 양국 협력 분쟁 남중국해 기증\n",
      "\n",
      "topic #5 : 원전 운영 건설 세계 이번 수출 수주 체결 사업 한국형\n",
      "topic #6 : 고문 사장 재판 1심 상임고문 관할 판결 법원 사람 이혼\n",
      "topic #7 : 회의 의학 참석 장관 인사 20일 기자 나누고 이승 16일\n",
      "topic #8 : 울산 방지 진화 이동 디지털 충돌 장착 대우조선 칼럼니스트 조사\n",
      "topic #9 : 총기 경찰 사제 성씨 서울 경위 제작 총격 인근 사제총\n",
      "\n",
      "topic #10 : 제품 라인 사용 부장 전자 생산 스마트폰 재배포 교체 세트장\n",
      "topic #11 : 지원 협약 체결 경기 확대 농산물 농촌 사회공헌 합격자 상생\n",
      "topic #12 : 방송 시청자들 뉴미디어 시청자 정원 질문 깜짝 보도자료 시사 상대방\n",
      "topic #13 : 트럼프 클린턴 토론 미국 후보 대선 3차 앵커 대통령 주장\n",
      "topic #14 : 트와이스 08 영주 평가 아시아 사회적 지난주 지수 기업 올해\n",
      "\n",
      "topic #15 : 재배포 두테르테 작품 작가 수상 정상회담 드라마 롤링 잠시 11시\n",
      "topic #16 : 네이버 여성 독도 서비스 검색 인터넷 이탈 포털 공무원들 현실\n",
      "topic #17 : 전시 공연 함께 제공 축제 관광 관광객 진행 발굴 이번\n",
      "topic #18 : 서비스 고객 은행 가입 이용 상품 보험 카드 금액 중복\n",
      "topic #19 : 승객 열차 출입문 출발 운전 목숨 어제 목격자 신고 속보\n",
      "\n",
      "topic #20 : 사고 기관사 전동차 확인 조사 안전문 김포공항역 오전 발생 경찰\n",
      "topic #21 : 오후 전남 오전 21일 22일 시민들 시민 19일 30분 발인\n",
      "topic #22 : 사진 뉴스 제보 기자 영상 금지 현대백화점 20일 드림 기사\n",
      "topic #23 : 촬영 에너지 사진 공유 인스타그램 변신 평양 모습 완벽 소녀\n",
      "topic #24 : 회고록 의원 송민순 당시 답변 원장 북한 국정원장 관련 2007년\n",
      "\n",
      "topic #25 : 온라인 지출 결제 모바일 연예 소화 무대 서비스 포인트 이하\n",
      "topic #26 : 건축 탈당 가수 갈아 대권 개그우먼 작곡 끊임없이 상실 여러분\n",
      "topic #27 : 대표 선언 손학규 기자회견 정계복귀 고문 더불어민주당 민주당 강진 국회\n",
      "topic #28 : 파업 운행 참사 성과연봉제 철회 노조 김영란법 중단 4시 인력\n",
      "topic #29 : 경찰 남성 사건 체포 용의자 지난 경사 여성 것으로 살해\n",
      "\n",
      "topic #30 : 무단 금지 인턴기자 스포츠월드 기자 불구 20일 연결 회원들 구청\n",
      "topic #31 : 서울 컬렉션 아파트 기자 20일 중구 신도시 인근 지하 예정\n",
      "topic #32 : 고양이 건강 드론 패션 남성 피부 이미지 여성 선보 소재\n",
      "topic #33 : 경북 경주시 남편 출근 구미 남한 출신 2호선 기자간담회 충북\n",
      "topic #34 : 3분기 증가 것으로 전망 불법조업 어업 지난 실적 전년 개선\n",
      "\n",
      "topic #35 : 대출 부동산 분양 시장 대책 정부 신용대출 규제 공급 협회\n",
      "topic #36 : 검찰 재배포 혐의 카톡 의장 재판 기소 아이폰7 갑질 변호사\n",
      "topic #37 : 영화 포즈 취하고 옥상 관객들 진행 서울 예약 관객 기자\n",
      "topic #38 : 혐의 단속 지난 받고 것으로 위반 조사 불법 계정 사실\n",
      "topic #39 : 경남 전공 가정 미세먼지 노후 공군 안녕 합동 전국 김동\n",
      "\n",
      "topic #40 : 회장 국내 업계 글로벌 해외 유럽 경영 투자 부문 일본\n",
      "topic #41 : 재배포 중소기업 임금 대기업 초청 94 이사장 고용 심화 가이드\n",
      "topic #42 : 2017 디자이너 동대문디자인플라자 참석 서울 헤라서울패션위크 기기 20일 모바일 삼성전자\n",
      "topic #43 : 문제 대통령 정부 지금 상황 우리 주장 대한 것이다 대표\n",
      "topic #44 : 결혼 부부 만남 박세 체질 경북도 한방 가족 사연 모형\n",
      "\n",
      "topic #45 : 보조금 강원 뉴욕타임스 박경 마크 인연 위원회 글에서 이슈 통신\n",
      "topic #46 : 의혹 검찰 수사 최씨 최순실 재단 관련 대통령 스포츠 청와대\n",
      "topic #47 : 인도 기업 투쟁 인수 벗어나지 지사 금융당국 그냥 20대 사무총장\n",
      "topic #48 : 조성 재배포 계획 내년 예정 설계 단지 금지 착공 지역\n",
      "topic #49 : 아르헨티나 캐릭터 하늘 제작발표회 아부다비 270 집필 도깨비 소속사 하단\n",
      "\n",
      "topic #50 : 재배포 금지 서울 20일 기자 2016 오후 참석 진행 참가\n",
      "topic #51 : 지급 제도 지원 설명회 경우 대상 확대 출산 취업 중점\n",
      "topic #52 : 크루즈 교육 제주 학생들 학생 경기 강정 박람회 내년 학교\n",
      "topic #53 : 상승 기록 은행들 44 하락 대비 개인 포인트 순이익 16\n",
      "topic #54 : 한옥 제주 주제 대한민국 교수 역사 미래 선임기자 조형물 나아\n",
      "\n",
      "topic #55 : 아버지 사람 내가 자신 모습 라고 가는 성폭력 소리 아내\n",
      "topic #56 : 걸그룹 1위 데뷔 싱글 차트 진영 기대감 대표 엔터테인먼트 고수\n",
      "topic #57 : 남자 드라마 수애 김영광 우리 20일 기자 웹툰 오후 아빠\n",
      "topic #58 : 북한 미국 한미 외교 배치 대응 장관 논의 양국 워싱턴\n",
      "topic #59 : 노래 예능 눈물 스타 미소 애정 강렬 위로 고민 어머니\n",
      "\n",
      "topic #60 : 공항 혼잡 속초시 안전 철도 확충 계획 2020년 투자 고속도로\n",
      "topic #61 : 센터 게임 398 201 199 포토 맞춤 유리 경기 장비\n",
      "topic #62 : 보험사 대구 일본 이전 인공 10월 용역 참가자들 보험금 지난\n",
      "topic #63 : 재배포 금지 그녀 연기 엄마 매주 비밀 감정 대본 참사\n",
      "topic #64 : 현대 자산 제외 지분 저출산 계열사 매각 일괄 패션쇼 현대상선\n",
      "\n",
      "topic #65 : 국회 국감 국정감사 새누리당 원내대표 위원장 수석 우병우 출석 민정수석\n",
      "topic #66 : 방송 재배포 오늘 모습 공개 이날 금지 남편 아침 이에\n",
      "topic #67 : 지난 것으로 이상 올해 국내 증가 불황 외국인 평균 최근\n",
      "topic #68 : 2016 19 000 23 21 스트리밍 기사 02 166 실시간\n",
      "topic #69 : 행사 재배포 서울 기자 20일 진행 금지 2016 구매 오후\n",
      "\n",
      "topic #70 : 유성구 재배포 아이 대전 연구 원자력 교수 4개 구청장 반입\n",
      "topic #71 : 당초 주민들 연장 주민 대한 반대 아이들 통로 보장 문제\n",
      "topic #72 : 지역 대회 재배포 경기 참가 활동 어린이들 울산시 교사 12개\n",
      "topic #73 : 무단 기사 그룹 화학 직원들 01 부회장 한진해운 서울대 바이오\n",
      "topic #74 : 면접 광주 이성 친구들 출입 설치 남구 주말 친구 여고생\n",
      "\n",
      "topic #75 : 차량 연비 현대차 표시 싼타페 결과 자동차 실제 14 소송\n",
      "topic #76 : 경주 제시 지진 협상 가입자 가이드라인 경보 이번 규모 발생\n",
      "topic #77 : 사랑 영화 때문 차태현 김유정 배우 서현진 서울 기자 힐링\n",
      "topic #78 : 루이 시청률 복원 쇼핑왕 부산 누적 서인국 등재 기록 지난\n",
      "topic #79 : 재배포 가구 금지 20여 부산 시간대 시중 브로커 차장 훌쩍\n",
      "\n",
      "topic #80 : 환자 수술 병원 전북대병원 치료 재배포 백남기 상태 전원 부검\n",
      "topic #81 : 필리핀 메이크업 30대 동생 광역 이들 카페 에게 플러스 구형\n",
      "topic #82 : 마당 대표 전시회 가면 그림 교환 블랙 갤러리 민화 가치관\n",
      "topic #83 : 생각 사람 하지 때문 자신 이야기 사람들 라고 우리 이런\n",
      "topic #84 : 진학 콘텐츠 외국어 별관 학습 영어 행사장 제공 광장 텔레콤\n",
      "\n",
      "topic #85 : 남양주 1987년 트위터 매진 화성 식물 분리 산들 안착 러시아\n",
      "topic #86 : 미국 영국 음식 한국 살피는 열연 60년 스크린 이끌고 치즈\n",
      "topic #87 : 대통령 재단 기업들 의혹 청와대 관련 확산 문화 순수 논란\n",
      "topic #88 : 북한 발사 미사일 아기 무수단 임신 실패 지난 것으로 추정\n",
      "topic #89 : 있습니다 멤버 행진 실제 모델 테슬라 집회 부드 시간 매장\n",
      "\n",
      "topic #90 : 한국일보 총장 교수 이화여대 학생들 규명 특혜 입학 전자신문 학교\n",
      "topic #91 : 예산 요리 2단계 스타일 음식 심사 편성 있도록 1단계 2017년\n",
      "topic #92 : 경위 김창 서울 빈소 오후 경감 희생 추서 시민에게 송파구\n",
      "topic #93 : 무단 여행 기자 개방 납품 전북 24 20일 관람 전주\n",
      "topic #94 : 세계 이번 분야 기술 영역 주제 참여 교육 한국 진행\n",
      "\n",
      "topic #95 : 사업 추진 호텔 설계 제공 시설 관광 부지 정부 공사\n",
      "topic #96 : 한전 계약 광주시 간담회 김씨 관련 해안 조경 열기 유출\n",
      "topic #97 : 조사 재배포 부착 컴퓨터 본사 본체 관련 조작 서울 이스트\n",
      "topic #98 : 시위 한국경제 남녀 앞에서 실패 발생 엉뚱 증상 죽음 퇴근\n",
      "topic #99 : 주택 보는 경제 금리 중앙 보고서 회사 조정 수출 인상\n"
     ]
    }
   ],
   "source": [
    "for topic_idx in range(beta.shape[0]):\n",
    "    if topic_idx % 5 == 0:\n",
    "        print()\n",
    "\n",
    "    term_indices = important_terms[topic_idx,:].reshape(-1)\n",
    "    terms = reversed([idx_to_vocab[idx] for idx in term_indices])\n",
    "\n",
    "    print('topic #{} : {}'.format(topic_idx, ' '.join(terms)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gensim 에서 단어의 topic vector 를 직접적으로 찾아주는 함수가 구현되어 있지 않습니다. 하지만 LdaModel[bow_model]을 넣으면 bow_model 에 대한 topic vector 를 출력해줍니다. bow_model 에 단어 한 개를 넣으면 해당 단어의 topic vector 를 알 수 있습니다. \n",
    "\n",
    "bow_model 은 [(term id, weight), (term id, weight), ... ] 형식입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(53, 0.50500005)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel[[(0,1)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode(words):\n",
    "    bow = [(vocab_to_idx.get(w, -1), f) for w,f in words]\n",
    "    bow = [(w, t) for w, t in bow if w != -1]\n",
    "    return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(14, 0.505)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_model = encode([('트와이스', 1)])\n",
    "ldamodel[bow_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_document_topics() 함수를 이용하면 minimum_probability, minimum_phi_value를 조절하며 topic vector를 만들 수 있습니다. `트와이스`는 14 번 topic 에서 자주 생성되는 단어입니다. 하지만 topic weight 가 50.5 % 밖에 되지 않습니다. 이는 Gensim LDA 가 다른 topic 에 기본확률로 0.01 을 할당하고 있기 때문엡니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(14, 0.50500005)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_model = encode([('트와이스', 1)])\n",
    "ldamodel.get_document_topics(bow_model,  minimum_probability=0.01, minimum_phi_value=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`무대`라는 단어는 25 번 topic 에 크게 할당되어 있습니다. 하지만 이 역시 50.5 % 만 할당되어 있습니다. `minimum_probability` 를 0.005 로 설정하면 다른 topic 의 weight 도 출력이 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.0050000004),\n",
       " (1, 0.0050000004),\n",
       " (2, 0.0050000004),\n",
       " (3, 0.0050000004),\n",
       " (4, 0.0050000004),\n",
       " (5, 0.0050000004),\n",
       " (6, 0.0050000004),\n",
       " (7, 0.0050000004),\n",
       " (8, 0.0050000004),\n",
       " (9, 0.0050000004),\n",
       " (10, 0.0050000004),\n",
       " (11, 0.0050000004),\n",
       " (12, 0.0050000004),\n",
       " (13, 0.0050000004),\n",
       " (14, 0.0050000004),\n",
       " (15, 0.0050000004),\n",
       " (16, 0.0050000004),\n",
       " (17, 0.0050000004),\n",
       " (18, 0.0050000004),\n",
       " (19, 0.0050000004),\n",
       " (20, 0.0050000004),\n",
       " (21, 0.0050000004),\n",
       " (22, 0.0050000004),\n",
       " (23, 0.0050000004),\n",
       " (24, 0.0050000004),\n",
       " (25, 0.505),\n",
       " (26, 0.0050000004),\n",
       " (27, 0.0050000004),\n",
       " (28, 0.0050000004),\n",
       " (29, 0.0050000004),\n",
       " (30, 0.0050000004),\n",
       " (31, 0.0050000004),\n",
       " (32, 0.0050000004),\n",
       " (33, 0.0050000004),\n",
       " (34, 0.0050000004),\n",
       " (35, 0.0050000004),\n",
       " (36, 0.0050000004),\n",
       " (37, 0.0050000004),\n",
       " (38, 0.0050000004),\n",
       " (39, 0.0050000004),\n",
       " (40, 0.0050000004),\n",
       " (41, 0.0050000004),\n",
       " (42, 0.0050000004),\n",
       " (43, 0.0050000004),\n",
       " (44, 0.0050000004),\n",
       " (45, 0.0050000004),\n",
       " (46, 0.0050000004),\n",
       " (47, 0.0050000004),\n",
       " (48, 0.0050000004),\n",
       " (49, 0.0050000004),\n",
       " (50, 0.0050000004),\n",
       " (51, 0.0050000004),\n",
       " (52, 0.0050000004),\n",
       " (53, 0.0050000004),\n",
       " (54, 0.0050000004),\n",
       " (55, 0.0050000004),\n",
       " (56, 0.0050000004),\n",
       " (57, 0.0050000004),\n",
       " (58, 0.0050000004),\n",
       " (59, 0.0050000004),\n",
       " (60, 0.0050000004),\n",
       " (61, 0.0050000004),\n",
       " (62, 0.0050000004),\n",
       " (63, 0.0050000004),\n",
       " (64, 0.0050000004),\n",
       " (65, 0.0050000004),\n",
       " (66, 0.0050000004),\n",
       " (67, 0.0050000004),\n",
       " (68, 0.0050000004),\n",
       " (69, 0.0050000004),\n",
       " (70, 0.0050000004),\n",
       " (71, 0.0050000004),\n",
       " (72, 0.0050000004),\n",
       " (73, 0.0050000004),\n",
       " (74, 0.0050000004),\n",
       " (75, 0.0050000004),\n",
       " (76, 0.0050000004),\n",
       " (77, 0.0050000004),\n",
       " (78, 0.0050000004),\n",
       " (79, 0.0050000004),\n",
       " (80, 0.0050000004),\n",
       " (81, 0.0050000004),\n",
       " (82, 0.0050000004),\n",
       " (83, 0.0050000004),\n",
       " (84, 0.0050000004),\n",
       " (85, 0.0050000004),\n",
       " (86, 0.0050000004),\n",
       " (87, 0.0050000004),\n",
       " (88, 0.0050000004),\n",
       " (89, 0.0050000004),\n",
       " (90, 0.0050000004),\n",
       " (91, 0.0050000004),\n",
       " (92, 0.0050000004),\n",
       " (93, 0.0050000004),\n",
       " (94, 0.0050000004),\n",
       " (95, 0.0050000004),\n",
       " (96, 0.0050000004),\n",
       " (97, 0.0050000004),\n",
       " (98, 0.0050000004),\n",
       " (99, 0.0050000004)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_model = encode([('무대', 1)])\n",
    "ldamodel.get_document_topics(bow_model,  minimum_probability=0.005, minimum_phi_value=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "새로운 문서에 대해서도 BOW list 를 만들어 topic probability vector 를 inferring 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(14, 0.5025402), (25, 0.25245988)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_model = encode([('트와이스', 2), ('무대', 1)])\n",
    "ldamodel.get_document_topics(bow_model, minimum_probability=0.01, minimum_phi_value=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
