{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifiers 를 비교하기 위하여 10 개 영화의 평점 데이터를 이용합니다. Day 1 때 만들어둔 데이터입니다. 1 ~ 3 점은 negative, 9 ~ 10 은 positive class 이며, 4 ~ 8 점의 데이터는 무시하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset version\n",
      "[navermovie_comments.data] is latest (0.0.1)\n",
      "[navermovie_comments.models] is latest (0.0.1)\n",
      "[navernews_10days.data] is latest (0.0.1)\n",
      "[navernews_10days.models] is latest (0.0.1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from config import dataset_dir\n",
    "sys.path.append('{}/lovit_textmining_dataset/'.format(dataset_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 4808)\n"
     ]
    }
   ],
   "source": [
    "from navermovie_comments import load_sentiment_dataset\n",
    "\n",
    "texts, x, y, idx_to_vocab = load_sentiment_dataset(data_name='10k', tokenize='komoran')\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy.unique 를 이용하면 실제 값들을 확인할 수 있습니다. negative 는 -1, positive 는 1 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree 의 depth 별로 classification 의 성능과 decision tree 가 이용하는 features 의 개수를 확인합니다.\n",
    "\n",
    "Depth 외의 다른 features 는 기본값으로 고정합니다.\n",
    "\n",
    "cross validation 을 이용하여 일반화 성능을 추정합니다. 10-fold cross validation 을 이용하였고, 이용하는 features 의 개수를 확인하기 위하여 데이터 모두를 이용하여 학습시켰습니다.\n",
    "\n",
    "scikit-learn = 0.20.0 부터 cross_val_score 는 sklearn.cross_validation.cross_val_score 에서 sklearn.mdoel_selection.cross_val_score 로 이동하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth = 10, cross-validation average = 0.7656, n useful featuers = 100\n",
      "depth = 20, cross-validation average = 0.7774, n useful featuers = 246\n",
      "depth = 30, cross-validation average = 0.7802, n useful featuers = 359\n",
      "depth = 50, cross-validation average = 0.7843, n useful featuers = 500\n",
      "depth = 100, cross-validation average = 0.7821, n useful featuers = 729\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "n_cv = 10\n",
    "\n",
    "# for each depth\n",
    "for depth in [10, 20, 30, 50, 100]:\n",
    "    \n",
    "    # build decision tree\n",
    "    decision_tree = DecisionTreeClassifier(\n",
    "        max_features=None,\n",
    "        max_depth=depth\n",
    "    )\n",
    "    \n",
    "    # train cross-validation\n",
    "    scores = cross_val_score(\n",
    "        decision_tree, x, y, cv=n_cv)\n",
    "    average_score = sum(scores) / n_cv\n",
    "    \n",
    "    # re-train using all data\n",
    "    decision_tree.fit(x,y)\n",
    "    \n",
    "    # number of used features\n",
    "    useful_features = list(\n",
    "        filter(lambda x:x[1]>0,\n",
    "               enumerate(decision_tree.feature_importances_)\n",
    "              )\n",
    "    )\n",
    "    n_useful_features = len(useful_features)\n",
    "\n",
    "    print('depth = {}, cross-validation average = {:.4}, n useful featuers = {}'.format(depth, average_score, n_useful_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L1 regularization 을 적용하는 lasso regression 을 학습합니다. Lasso 도 decision tree 처럼 유용한 features 를 선택하는 특징이 있습니다. 이 둘의 성능을 비교합니다.\n",
    "\n",
    "Lasso regression 이 이용하는 features 의 개수는 regularization cost 를 통하여 조절할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 lambda = 0.01, cross-validation = 0.8206, n useful features = 2496\n",
      "L1 lambda = 0.1, cross-validation = 0.8477, n useful features = 2172\n",
      "L1 lambda = 1.0, cross-validation = 0.858, n useful features = 1108\n",
      "L1 lambda = 10.0, cross-validation = 0.8193000000000001, n useful features = 181\n",
      "L1 lambda = 100.0, cross-validation = 0.7269999999999999, n useful features = 20\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# for each cost\n",
    "for cost in [100, 10, 1, 0.1, 0.01]:\n",
    "\n",
    "    # build lasso regression\n",
    "    logistic_regression = LogisticRegression(\n",
    "        penalty='l1', C=cost)\n",
    "\n",
    "    # train cross validation\n",
    "    scores = cross_val_score(\n",
    "        logistic_regression, x, y, cv=n_cv)\n",
    "    average_score = sum(scores) / n_cv\n",
    "\n",
    "    # re-train using all data\n",
    "    logistic_regression.fit(x,y)\n",
    "\n",
    "    # number of used features\n",
    "    useful_features = list(\n",
    "        filter(lambda x:abs(x[1])>0,\n",
    "               enumerate(logistic_regression.coef_[0])\n",
    "              )\n",
    "    )\n",
    "\n",
    "    n_useful_features = len(useful_features)\n",
    "\n",
    "    print('L1 lambda = {}, cross-validation = {}, n useful features = {}'.format(1/cost, average_score, n_useful_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso 대신 L2 regularization 을 적용한 logistic regression 도 함께 돌려봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 lambda = 0.01, cross-validation = 0.8423, n features abs > 0.01 = 4419\n",
      "L2 lambda = 0.1, cross-validation = 0.8549, n features abs > 0.01 = 4556\n",
      "L2 lambda = 1.0, cross-validation = 0.8638999999999999, n features abs > 0.01 = 4585\n",
      "L2 lambda = 10.0, cross-validation = 0.8517000000000001, n features abs > 0.01 = 4261\n",
      "L2 lambda = 100.0, cross-validation = 0.8221999999999999, n features abs > 0.01 = 2059\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# for each cost\n",
    "for cost in [100, 10, 1, 0.1, 0.01]:\n",
    "\n",
    "    # build lasso regression\n",
    "    logistic_regression = LogisticRegression(\n",
    "        penalty='l2', C=cost)\n",
    "\n",
    "    # train cross validation\n",
    "    scores = cross_val_score(\n",
    "        logistic_regression, x, y, cv=n_cv)\n",
    "    average_score = sum(scores) / n_cv\n",
    "\n",
    "    # re-train using all data\n",
    "    logistic_regression.fit(x,y)\n",
    "\n",
    "    # number of used features\n",
    "    useful_features = list(\n",
    "        filter(lambda x:abs(x[1])>0.01,\n",
    "               enumerate(logistic_regression.coef_[0])\n",
    "              )\n",
    "    )\n",
    "\n",
    "    n_useful_features = len(useful_features)\n",
    "\n",
    "    print('L2 lambda = {}, cross-validation = {}, n features abs > 0.01 = {}'.format(1/cost, average_score, n_useful_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
