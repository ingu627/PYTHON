{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soynlp=0.0.49\n",
      "Dataset version\n",
      "[navermovie_comments.data] is latest (0.0.1)\n",
      "[navermovie_comments.models] is latest (0.0.1)\n",
      "[navernews_10days.data] is latest (0.0.1)\n",
      "[navernews_10days.models] is latest (0.0.1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from config import dataset_dir\n",
    "sys.path.append('{}/lovit_textmining_dataset'.format(dataset_dir))\n",
    "\n",
    "from navernews_10days import get_news_paths\n",
    "from soynlp.utils import DoublespaceLineCorpus\n",
    "\n",
    "corpus_path = get_news_paths(date='2016-10-20')\n",
    "corpus = DoublespaceLineCorpus(corpus_path, iter_sent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L-R graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L-R graph는 L 왼쪽에 어떤 R들이 등장하는지 확인하기 위한 그래프로 dict[L]에는 [R]들이 몇 번 오른쪽에 등장하였는지의 빈도수 입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "lr_graph = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for sent in corpus:\n",
    "    for eojeol in sent.split():\n",
    "        for e in range(1, len(eojeol) + 1):\n",
    "            (l, r) = (eojeol[:e], eojeol[e:])\n",
    "            lr_graph[l][r] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L인 word가 주어지면 R들의 분포를 가져오기 위해서 get 함수를 이용합시다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "드라마 - : 1268\n",
      "드라마 - 를: 164\n",
      "드라마 - 다: 152\n",
      "드라마 - 의: 140\n",
      "드라마 - 로: 138\n",
      "드라마 - 에서: 98\n",
      "드라마 - 와: 62\n",
      "드라마 - 에: 55\n",
      "드라마 - 는: 55\n",
      "드라마 - 가: 48\n",
      "드라마 - 이다: 24\n",
      "드라마 - 라는: 15\n",
      "드라마 - 인: 14\n",
      "드라마 - 하우스: 14\n",
      "드라마 - 나: 13\n",
      "드라마 - 관계자는: 8\n",
      "드라마 - 도: 8\n",
      "드라마 - 틱했던: 7\n",
      "드라마 - 에서는: 6\n",
      "드라마 - 타운: 5\n"
     ]
    }
   ],
   "source": [
    "def get_r(word, topk=-1):\n",
    "    r = sorted(lr_graph.get(word, {}).items(), key=lambda x:-x[1])\n",
    "    if topk > 0:\n",
    "        return r[:topk]\n",
    "    return r\n",
    "\n",
    "word = '드라마'\n",
    "for r, freq in get_r(word, 20):\n",
    "    print('%s - %s: %d' % (word, r, freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R feature score table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "세종말뭉치에 존재하는 r set 들의 명사 가능 점수를 계산한 table 을 로딩합니다. 탭으로 구분된 텍스트 파일입니다.\n",
    "\n",
    "```\n",
    "을까를\t   -1.000000\n",
    "스러워하는\t    1.000000\n",
    "다주는\t   -1.000000\n",
    "냔\t    0.080570\n",
    "하다보니\t    1.000000\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num r features = 2398\n"
     ]
    }
   ],
   "source": [
    "with open('noun_score_sejong', encoding='utf-8') as f:\n",
    "    r_score = {}\n",
    "    for line in f:\n",
    "        r, score = line.strip().split('\\t')\n",
    "        score = float(score)\n",
    "        r_score[r] = score\n",
    "    print('num r features = %d' % len(r_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noun classification with r fetaures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어 word 가 주어졌을 때, r features 를 가져온 뒤, 이를 이용하여 명사 가능 점수를 계산해 봅시다.\n",
    "\n",
    "r_features 를 가져온 뒤, 각 r 의 명사 가능 점수를, 빈도수를 weight 로 하여 가중평균 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score(박근) = -0.968\n",
      "score(박근혜) = 0.478\n",
      "score(대통령) = 0.492\n",
      "score(정) = 0.323\n",
      "score(정부) = 0.574\n",
      "score(정부의) = 0.0\n",
      "score(알아) = -0.784\n",
      "score(알아냈) = -0.885\n"
     ]
    }
   ],
   "source": [
    "def predict(word):\n",
    "    score = 0.0\n",
    "    norm = 0\n",
    "    for r, freq in get_r(word):\n",
    "        if (r in r_score) == False:\n",
    "            continue\n",
    "        score += r_score.get(r) * freq\n",
    "        norm += freq\n",
    "\n",
    "    if norm != 0:\n",
    "        score /= norm\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "for word in ['박근', '박근혜', '대통령', '정', '정부', '정부의', '알아', '알아냈']:\n",
    "    print('score({}) = {:.3}'.format(word, predict(word)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Limitation & Solutions\n",
    "\n",
    "하지만 실제 명사 추출은 이보다 복잡한 prediction 과정 및 후처리가 필요합니다.\n",
    "\n",
    "한 예로, `아이디`라는 단어는 실제로는 이날의 뉴스에서 명사로 자주 이용되지만, `아이디어`라는 명사의 `-어` 때문에 명사가 아닌 것처럼 판단될 수 있습니다. `되어`, `먹어` 처럼 `-어`는 대표적인 어미이기 때문입니다. 이를 해결할 수 있는 간단한 방법으로는 길이가 긴 subword 에 대하여 먼저 명사 점수를 계산한 뒤, 그 subword 가 명사이면 L-R graph 에서 이에 해당하는 모든 조합을 지우는 것입니다. \n",
    "\n",
    "이 방법을 이용하면 `아이디어`로부터 발생된 (L, R) 이 모두 사라지게 되기 때문에 `아이디`가 명사로 판별될 수 있습니다.\n",
    "\n",
    "`soynlp.noun.LRNounExtractor_v2` 는 이러한 기능을 포함하여 그 외의 후처리 기능들을 포함하고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score(아이디) = -0.704\n",
      "score(아이디어) = 0.859\n"
     ]
    }
   ],
   "source": [
    "for word in ['아이디', '아이디어']:\n",
    "    print('score({}) = {:.3}'.format(word, predict(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('어', 109),\n",
       " ('어를', 103),\n",
       " ('어가', 50),\n",
       " ('', 41),\n",
       " ('는', 27),\n",
       " ('어와', 21),\n",
       " ('를', 14),\n",
       " ('어는', 12),\n",
       " ('어의', 10),\n",
       " ('어로', 9)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_r('아이디', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "는 (27)\n",
      "를 (14)\n",
      "와 (9)\n",
      "가 (6)\n",
      "스홀딩스 (3)\n",
      "로 (2)\n",
      "만 (1)\n",
      "병원 (1)\n"
     ]
    }
   ],
   "source": [
    "for r, count in get_r('아이디', 30):\n",
    "    if r and r[0] != '어':\n",
    "        print('{} ({})'.format(r, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
