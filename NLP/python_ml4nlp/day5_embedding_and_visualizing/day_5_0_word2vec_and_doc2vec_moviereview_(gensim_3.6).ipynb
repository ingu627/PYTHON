{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim version\n",
    "\n",
    "gensim이 버전업데이트를 최근에 자주해서, 자료의 gensim version을 미리 적어둡니다. \n",
    "\n",
    "현재 최신버전은 3.7 입니다. 이번 실습에서도 3.6 을 이용하였습니다.\n",
    "\n",
    "곧 버전이 4.0+ 으로 올라갈 것 같은데, 지금까지는 Word2Vec.most_similar () 함수를 이용하여 유사어 검색이 가능했습니다. 4.0+ 이후에 이 함수가 Word2Vec.wv.most_similar 로 옮겨집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soynlp=0.0.49\n",
      "added lovit_textmining_dataset\n",
      "Gensim version = 3.6.0\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "import gensim\n",
    "print('Gensim version = {}'.format(gensim.__version__))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim 의 Word2Vec 을 학습하기 위해서는 한 문장이 list of str 형식인 input 이 필요합니다. 하지만 모든 리뷰들을 메모리에 올리지 않고도 학습할 수 있습니다. Generator 로 input data class 를 만든 뒤, \\_\\_iter\\_\\_ 함수를 구현하면 됩니다. 영화 평 데이터는 <영화 아이디, 영화 평, 평점> 이 tap separated 로 구분된 데이터 입니다. 이를 처리하는 부분만 아래처럼 구현합니다.\n",
    "\n",
    "```python\n",
    "for doc in f:\n",
    "    idx, text, score = doc.split('\\t')\n",
    "    yield text.split()\n",
    "```\n",
    "\n",
    "데이터를 미리 토크나이징 해두었기 때문에 띄어쓰기 만으로 단어를 구분하여 list of str 로 yield 합니다.\n",
    "\n",
    "또한, gensim 에는 verbose 기능이 없습니다. Input data 에 verbose 기능을 넣을 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecComments:\n",
    "    def __init__(self, path, verbose=False):\n",
    "        self.path = path\n",
    "        self.verbose = verbose\n",
    "        self.n_iter = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        # <idx, texts, rates>\n",
    "        with open(self.path, encoding='utf-8') as f:\n",
    "            for i, doc in enumerate(f):\n",
    "                if self.verbose and (i % 10000 == 0):\n",
    "                    print('\\riter={}, sents={} ...'.format(self.n_iter, i), end='')\n",
    "                yield self._tokenize(doc)\n",
    "            if self.verbose:\n",
    "                print('\\riter={}, sents={} done'.format(self.n_iter, i))\n",
    "            self.n_iter += 1\n",
    "\n",
    "    def _tokenize(self, doc):\n",
    "        idx, text, rate = doc.strip().split('\\t')\n",
    "        return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['크리스', '토퍼', '놀란', '에게', '우리', '는', '놀란', '다']\n",
      "['인셉션', '정말', '흥미진진', '하게', '봤', '었고', '크리스', '토퍼', '놀란', '감독님', '신작', '인터스텔라', '도', '이번', '주', '일요일', '에', '보러', '갑니다', '완전', '기대', '중']\n",
      "['놀란', '이면', '무', '조건', '봐야', '된다', '왜냐하면', '모든', '작품', '을', '다', '히트', '쳤으', '니깐']\n"
     ]
    }
   ],
   "source": [
    "from navermovie_comments import get_movie_comments_path\n",
    "\n",
    "path = get_movie_comments_path(large=False, tokenize='soynlp_unsup')\n",
    "word2vec_corpus = Word2VecComments(path, verbose=False)\n",
    "\n",
    "for i, text in enumerate(word2vec_corpus):\n",
    "    if i >= 3:\n",
    "        break\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim 의 Word2Vec 을 이용합니다. 미리 만들어둔 word2vec_corpus 를 Word2Vec 의 argument 로 입력합니다. default parameters 를 이용하여 Word2Vec을 학습힙니다. \n",
    "\n",
    "Word2Vec의 arguments 중에서 중요한 것들은 아래와 같습니다. \n",
    "\n",
    "- size: 단어의 임베딩 공간의 크기\n",
    "- alpha: learning rate\n",
    "- window: 한 단어의 좌/우의 문맥 크기\n",
    "- min_count: 모델이 학습할 단어의 최소 출현 빈도수\n",
    "- max_vocab_size: None이 아닌 숫자를 입력하면 빈도수 기준으로 상위 max_vocab_size 개수만큼의 단어만 학습\n",
    "- workers: num of threads\n",
    "- sg: 1이면 skipgram 이용\n",
    "- negative: negative sampling에서 negative sample의 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=0, sents=294492 done\n",
      "iter=1, sents=294492 done\n",
      "iter=2, sents=294492 done\n",
      "iter=3, sents=294492 done\n",
      "iter=4, sents=294492 done\n",
      "iter=5, sents=294492 done\n",
      "CPU times: user 1min 4s, sys: 484 ms, total: 1min 4s\n",
      "Wall time: 32.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "word2vec_corpus.verbose = True\n",
    "word2vec_model = Word2Vec(word2vec_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습된 Word2Vec 모델의 most_similar(단어, topn) 함수는 입력된 단어에 대하여 가장 비슷한 topn개의 다른 단어들과 유사도를 출력합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sf영화', 0.6271036863327026),\n",
       " ('작품', 0.5569660663604736),\n",
       " ('영화들', 0.5210461616516113),\n",
       " ('명화', 0.5111042261123657),\n",
       " ('영화지만', 0.5031603574752808),\n",
       " ('듯하다', 0.4901500344276428),\n",
       " ('영화라서', 0.4832218289375305),\n",
       " ('것같다', 0.47459280490875244),\n",
       " ('영화인데', 0.4547157883644104),\n",
       " ('장르', 0.45321589708328247)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.most_similar('영화')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4d', 0.9180201292037964),\n",
       " ('2D', 0.9043574333190918),\n",
       " ('4D', 0.8830397129058838),\n",
       " ('3d', 0.8714023232460022),\n",
       " ('디지털', 0.8710218667984009),\n",
       " ('쓰리디', 0.8693499565124512),\n",
       " ('4DX', 0.8601016998291016),\n",
       " ('4dx', 0.8582479953765869),\n",
       " ('VOD', 0.8573418855667114),\n",
       " ('디비디', 0.8496630191802979)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.most_similar('2d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wv.vocab 은 {str:Vocab} 형식의 dict 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab(count:109144, index:0, sample_int:923530540)\n"
     ]
    }
   ],
   "source": [
    "print(word2vec_model.wv.vocab['영화'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocab 은 namedtuple 이기 때문에 count 를 가져올 수 있습니다. index 는 각 단어의 row number 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109144"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.vocab['영화'].count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터의 양이 작아 embedding 이 잘 학습되지 않았습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26809"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2vec_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "큰 데이터로 미리 학습해둔 모델을 데이터에 넣어뒀습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from navermovie_comments import load_trained_embedding\n",
    "\n",
    "word2vec_model = load_trained_embedding(\n",
    "    data_name = 'large',\n",
    "    tokenize = 'soynlp_unsup',\n",
    "    embedding = 'word2vec'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "충분한 데이터로 학습하면 유사어도 잘 학습됩니다. 오탈자들도 유사어로 학습되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('애니', 0.7622032761573792),\n",
       " ('영회', 0.7138155102729797),\n",
       " ('애니메이션', 0.6826601028442383),\n",
       " ('영하', 0.6804906129837036),\n",
       " ('여화', 0.6422344446182251),\n",
       " ('영호ㅏ', 0.6399882435798645),\n",
       " ('명화', 0.6227416396141052),\n",
       " ('영화ㅋ', 0.6182453632354736),\n",
       " ('드라마', 0.6110595464706421),\n",
       " ('sf영화', 0.6031010746955872),\n",
       " ('영화들', 0.601367175579071),\n",
       " ('작품', 0.6008715629577637),\n",
       " ('장르영화', 0.5893300175666809),\n",
       " ('영화였고', 0.5842821598052979),\n",
       " ('영화내요', 0.5827130079269409),\n",
       " ('영화였네요', 0.5813204050064087),\n",
       " ('양화', 0.5806300640106201),\n",
       " ('영화인데', 0.572135329246521),\n",
       " ('애니매이션', 0.5695532560348511),\n",
       " ('에니메이션', 0.5671166181564331),\n",
       " ('영화인것', 0.5665518045425415),\n",
       " ('영화지만', 0.5654911994934082),\n",
       " ('영화ㅋㅋ', 0.5525494813919067),\n",
       " ('영환데', 0.5350443124771118),\n",
       " ('엉화', 0.5329785346984863),\n",
       " ('대중영화', 0.5315350294113159),\n",
       " ('블록버스터', 0.5307241678237915),\n",
       " ('영화ㅠㅠ', 0.5289486646652222),\n",
       " ('연화', 0.5288727879524231),\n",
       " ('경우', 0.5171139240264893)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.most_similar('영화', topn=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1점과 유사한 단어가 한글로 쓴 '일점', 그 이후로는 1, 2, 3, ... 이렇게 점수가 멀어져가는 것도 볼 수 있습니다\n",
    "\n",
    "'십점' 이라는 말은 점수가 들어갈 수 있는 문맥에서 나오는 말이기도 하지만, 긍정적인 표현에서 더 많이 나왔을 것입니다. 그렇기 때문에 1점 보다도, 천점, 백점 같은 단어들이 더 유사하게 학습됩니다 (네이버 영화에서 10점은 별 다섯개입니다)\n",
    "\n",
    "평론가는 평론가, 평론 단체 (씨네21 등)끼리 뭉쳐 나오는 걸 볼 수 있습니다\n",
    "\n",
    "또한 Word2Vec 은 단어가 영어, 숫자, 한글인지 전혀 중요하지 않습니다. 단어가 함께 섞여도 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similar(하정우) = 송강호 이정재 공유 황정민 이병헌 손현주 이범수 주진모 유해진 톰크루즈\n",
      "similar(1점) = 일점 별한개 2점 3점 4점 최하점 십점 5점 별하나 구점\n",
      "similar(십점) = 일점 구점 백점 1점 반점 만점 11점 최하점 삼점 천점\n",
      "similar(이동진) = 박평식 이용철 송경원 김현수 씨네21 평론가님 황진미 기자님 기자 김봉석\n",
      "similar(평론가) = 전문가 기자 씨네21 평론가들 전문가들 박평식 황진미 기자들 한겨례 이동진\n",
      "similar(평론) = 비평 평 평론가 악평 논평 평가 아는척 한줄평 전문가 댓\n",
      "similar(스토리) = 줄거리 시나리오 내용 이야기전개 영화전개 내러티브 스로리 플롯 소재 사건전개\n",
      "similar(조연) = 주조연 단역 조연들 주연 명품조연 엑스트라 연기자 명품조연들 박희순 김인권\n",
      "similar(배우) = 연기자 배우들 연기자들 베우 한석규 조연 조연들 하정우 김태리 스타들\n",
      "similar(포디) = 4디 4d 쓰리디 3디 투디 4D 4dx 4DX 삼디 아이맥스3D\n",
      "similar(4d) = 4D 3d 포디 4DX 쓰리디 3D 4dx 아이맥스 2d 3디\n",
      "similar(영등포) = 코엑스 용산 왕십리 메가박스 신촌 상암 씨지비 일산 김포공항 프리머스\n",
      "similar(롯시) = 영등포 코엑스 용산 상암 일산 메가박스 신촌 씨지비 프리머스 김포공항\n",
      "similar(ocn) = OCN 오씨엔 Tv 케이블 Ocn 공중파 일반관 출발비디오여행 tv 스타리움\n"
     ]
    }
   ],
   "source": [
    "for word in '하정우 1점 십점 이동진 평론가 평론 스토리 조연 배우 포디 4d 영등포 롯시 ocn'.split():\n",
    "    similar_words = word2vec_model.wv.most_similar(word)\n",
    "    similar_words = [word for word, sim in similar_words]\n",
    "    print('similar({}) = {}'.format(\n",
    "        word, ' '.join(similar_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec model의 단어 벡터들은 Word2Vec.wv 아래에 저장되어 있습니다. gensim version 1.x 부터 Word2Vec.wv에서 단어 벡터를 따로 관리합니다.\n",
    "\n",
    "`Word2Vec.wv.syn0`: 실제 단어가 저장되어 있는 행렬로, numpy.ndarray 형태입니다.\n",
    "\n",
    "```python\n",
    "word2vec_model.wv.vectors.shape # (93234, 100)\n",
    "```\n",
    "\n",
    "`word2vec_model.wv.vectors_norm` : cosine similarity 를 위하여 row normalize 를 한 행렬로 모양은 같지만, 벡터의 2 norm 이 1 입 니다. \n",
    "\n",
    "```python\n",
    "word2vec_model.wv.vectors_norm.shape # (93234, 100)\n",
    "sum(word2vec_model.wv.vectors[0] **2) # 318.1980813240516\n",
    "sum(word2vec_model.wv.vectors_norm[0] **2) # 1.0000001593821253\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec.wv.index2word는 단어별 index가 저장되어 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93234\n",
      "<class 'list'>\n",
      "영화\n"
     ]
    }
   ],
   "source": [
    "print(len(word2vec_model.wv.index2word))\n",
    "print(type(word2vec_model.wv.index2word))\n",
    "print(word2vec_model.wv.index2word[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc2Vec을 학습하기 위해서는 각각 문서의 label이 저장되어야 합니다. 이를 위하여 TaggedDocument라는 클래스가 이용됩니다. TaggedDocument는 단어들을 words에, 레이블 정보를 tags에 리스트 형태로 입력합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaggedDocument(['명불허전'], ['#72523'])\n",
      "TaggedDocument(['왠지', '고사', '피의', '중간', '고사', '보다', '재미', '가', '없을듯', '해요', '만약', '보게', '된다면', '실망', '할듯'], ['#72523'])\n",
      "TaggedDocument(['티아라', '사랑', '해', 'ㅜ'], ['#72523'])\n",
      "TaggedDocument(['황정음', '윤시윤', '지붕킥', '인연', '김수로', '티아라', '지연', '공부의신', '인연', '너무', '너무', '재미', '있어요'], ['#72523'])\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "class Doc2VecComments(Word2VecComments):\n",
    "    def _tokenize(self, doc):\n",
    "        idx, text, rate = doc.strip().split('\\t')\n",
    "        return TaggedDocument(\n",
    "                    words=text.split(), tags=['#%s' % idx]\n",
    "                )\n",
    "\n",
    "path = get_movie_comments_path(large='large', tokenize='soynlp_unsup')\n",
    "doc2vec_corpus = Doc2VecComments(path)\n",
    "\n",
    "for i, doc in enumerate(doc2vec_corpus):\n",
    "    if i > 3: break\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = False\n",
    "if TRAIN:\n",
    "    doc2vec_model = Doc2Vec(doc2vec_corpus)\n",
    "else:\n",
    "    doc2vec_model = load_trained_embedding(\n",
    "        data_name='large', tokenize='soynlp_unsup', embedding='doc2vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc2Vec 에서도 유사 단어 검색이 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('애니', 0.7179281115531921),\n",
       " ('영회', 0.6447778940200806),\n",
       " ('여화', 0.6053318977355957),\n",
       " ('영하', 0.592547595500946),\n",
       " ('엉화', 0.5851074457168579),\n",
       " ('애니메이션', 0.5821044445037842),\n",
       " ('sf영화', 0.581710696220398),\n",
       " ('양화', 0.5816899538040161),\n",
       " ('애니영화', 0.5751307010650635),\n",
       " ('영화였고', 0.5723588466644287)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vec_model.wv.most_similar('영화', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('톰하디', 0.8216360807418823),\n",
       " ('레오', 0.8157205581665039),\n",
       " ('브래드피트', 0.8099828958511353),\n",
       " ('니콜라스홀트', 0.8012720346450806),\n",
       " ('베네딕트', 0.8000676035881042),\n",
       " ('앤해서웨이', 0.7960273027420044),\n",
       " ('앤헤서웨이', 0.7938777208328247),\n",
       " ('로다주', 0.7688084840774536),\n",
       " ('컴버배치', 0.76687091588974),\n",
       " ('프레디', 0.7544741630554199)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vec_model.wv.most_similar('디카프리오', topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc2Vec model의 .docvecs안에는 document vector와 관련된 정보들이 저장되어 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc2vec_model.docvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.keyedvectors.Doc2VecKeyedVectors"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc2vec_model.docvecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doctags 에 들어있는 offset 은 document vector 의 임베딩 메트릭스의 row id 이며, word_count 는 각 태그에 해당하는 문서에 단어가 몇 개 있었는지, doc_count 는 각 태그에 해당하는 문서가 몇 번 등장하였는지입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#72523', Doctag(offset=0, word_count=89878, doc_count=10187)),\n",
       " ('#59845', Doctag(offset=1, word_count=139795, doc_count=13095)),\n",
       " ('#109753', Doctag(offset=2, word_count=200116, doc_count=10361))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doctags = doc2vec_model.docvecs.doctags.items()\n",
    "doctags = sorted(doctags, key=lambda x:x[1].offset)\n",
    "doctags[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`#72523` 은 offset=0 은 docvec 에서의 row id 가 0 라는 의미입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#73344', 0.8099367618560791),\n",
       " ('#48246', 0.7621855735778809),\n",
       " ('#42589', 0.7321667671203613),\n",
       " ('#102824', 0.729533314704895),\n",
       " ('#76080', 0.7153506278991699),\n",
       " ('#88225', 0.7075489163398743),\n",
       " ('#48227', 0.7025582790374756),\n",
       " ('#41450', 0.6783559918403625),\n",
       " ('#64191', 0.676222026348114),\n",
       " ('#75355', 0.6696109771728516)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vec_model.docvecs.most_similar('#72523')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document vector의 row id로도 most_similar를 찾을 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#73344', 0.8099367618560791),\n",
       " ('#48246', 0.7621855735778809),\n",
       " ('#42589', 0.7321667671203613),\n",
       " ('#102824', 0.729533314704895),\n",
       " ('#76080', 0.7153506278991699),\n",
       " ('#88225', 0.7075489163398743),\n",
       " ('#48227', 0.7025582790374756),\n",
       " ('#41450', 0.6783559918403625),\n",
       " ('#64191', 0.676222026348114),\n",
       " ('#75355', 0.6696109771728516)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vec_model.docvecs.most_similar(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec 해석하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from navermovie_comments import load_id_to_movie\n",
    "\n",
    "idx_to_movie = load_id_to_movie()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "영화 아이디를 영화 제목으로 바꿔서 해석해봅시다\n",
    "\n",
    "영화 리뷰를 기준으로 각 영화를 document vector로 표현하였을 때 라라랜드와 리뷰가 비슷한 영화는 '비긴 어게인', '어바웃 타임' 등입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라라랜드\n",
      "\n",
      "('비긴 어게인', '96379', 0.9024428129196167)\n",
      "('어바웃 타임', '92075', 0.8169595003128052)\n",
      "('인턴', '118917', 0.710594654083252)\n",
      "('인사이드 아웃', '115622', 0.6986126899719238)\n",
      "('시간을 달리는 소녀', '63513', 0.6862818002700806)\n",
      "('하울의 움직이는 성', '39640', 0.6862198114395142)\n",
      "('레미제라블', '89755', 0.6842658519744873)\n",
      "('미스 페레그린과 이상한 아이들의 집', '129383', 0.6826176047325134)\n",
      "('뷰티 인사이드', '129050', 0.6816157698631287)\n",
      "('겨울왕국', '100931', 0.6804711222648621)\n"
     ]
    }
   ],
   "source": [
    "def as_name(similar):\n",
    "    idx = similar[0][1:]\n",
    "    return (idx_to_movie.get(idx, 'unknown'), idx, similar[1])\n",
    "\n",
    "\n",
    "print('라라랜드\\n')\n",
    "\n",
    "for similar in doc2vec_model.docvecs.most_similar('#134963'):\n",
    "    print(as_name(similar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "관상\n",
      "\n",
      "('역린', '108225', 0.8302776217460632)\n",
      "('광해, 왕이 된 남자', '83893', 0.8152835369110107)\n",
      "('군도:민란의 시대', '99752', 0.7720687389373779)\n",
      "('사도', '121922', 0.7519895434379578)\n",
      "('도둑들', '78726', 0.7223831415176392)\n",
      "('검사외전', '130903', 0.719760537147522)\n",
      "('신세계', '91031', 0.7194761037826538)\n",
      "('의형제', '52548', 0.7159029245376587)\n",
      "('밀정', '137952', 0.6845557689666748)\n",
      "('쌍화점', '45232', 0.6726131439208984)\n"
     ]
    }
   ],
   "source": [
    "print('관상\\n')\n",
    "for similar in doc2vec_model.docvecs.most_similar('#93728'):\n",
    "    print(as_name(similar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "광해 왕이된 남자\n",
      "\n",
      "('관상', '93728', 0.8152835369110107)\n",
      "('의형제', '52548', 0.7779906988143921)\n",
      "('라디오 스타', '58088', 0.7411540746688843)\n",
      "('파파로티', '85640', 0.7076984643936157)\n",
      "('수상한 그녀', '107924', 0.6803666353225708)\n",
      "('시라노; 연애조작단', '73318', 0.6777384281158447)\n",
      "('왕의 남자', '39894', 0.6738080382347107)\n",
      "('미녀는 괴로워', '39157', 0.6719443798065186)\n",
      "('도둑들', '78726', 0.6672611236572266)\n",
      "('신세계', '91031', 0.6661689281463623)\n"
     ]
    }
   ],
   "source": [
    "print('광해 왕이된 남자\\n')\n",
    "for similar in doc2vec_model.docvecs.most_similar('#83893'):\n",
    "    print(as_name(similar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아바타\n",
      "\n",
      "('트랜스포머', '61521', 0.8492670059204102)\n",
      "('디스트릭트 9', '64129', 0.8323827385902405)\n",
      "('2012', '49727', 0.7791959643363953)\n",
      "('인셉션', '52515', 0.7713688015937805)\n",
      "('스카이라인', '76581', 0.7526602149009705)\n",
      "('다크 나이트', '62586', 0.746321439743042)\n",
      "('그래비티', '47370', 0.738884687423706)\n",
      "('퍼시픽 림', '86867', 0.7356865406036377)\n",
      "('리얼 스틸', '76460', 0.7262969017028809)\n",
      "('타이타닉', '18847', 0.720104455947876)\n"
     ]
    }
   ],
   "source": [
    "print('아바타\\n')\n",
    "for similar in doc2vec_model.docvecs.most_similar('#62266'):\n",
    "    print(as_name(similar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
