{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word - context matrix\n",
    "\n",
    "word - context matrix 를 만들기 위하여 4 개의 문장을 샘플로 이용합니다. KoNLPy 의 Okt 를 tokenizer 로 이용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soynlp=0.0.49\n",
      "added lovit_textmining_dataset\n",
      "konlpy == 0.5.1\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "import konlpy\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "print('konlpy == {}'.format(konlpy.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네 개의 문장을 토크나이징합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = '역사적인 남북 정상 간 핫라인이 20일 청와대와 북한 국무위원회 사이에 정식 개통됐다'\n",
    "\n",
    "tokenizer = Okt()\n",
    "words = tokenizer.pos(sent, join=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "# pprint(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "windows = 2 일 때, 앞 뒤의 2 단어씩을 contexts 로 counting 합니다. defaultdict 를 이용하여 base2context = {base: {context:freq}} 를 만듭니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['역사/Noun', '적/Suffix', '인/Josa', '남북/Noun', '정상/Noun', '간/Noun', '핫라인/Noun', '이/Josa', '20일/Number', '청와대/Noun', '와/Josa', '북한/Noun', '국무위원/Noun', '회/Noun', '사이/Noun', '에/Josa', '정식/Noun', '개통/Noun', '됐다/Verb']\n",
      "\n",
      "base = 역사/Noun\n",
      "left = []\n",
      "right = ['적/Suffix', '인/Josa']\n",
      "\n",
      "base = 적/Suffix\n",
      "left = ['역사/Noun']\n",
      "right = ['인/Josa', '남북/Noun']\n",
      "\n",
      "base = 인/Josa\n",
      "left = ['역사/Noun', '적/Suffix']\n",
      "right = ['남북/Noun', '정상/Noun']\n",
      "\n",
      "base = 남북/Noun\n",
      "left = ['적/Suffix', '인/Josa']\n",
      "right = ['정상/Noun', '간/Noun']\n",
      "\n",
      "base = 정상/Noun\n",
      "left = ['인/Josa', '남북/Noun']\n",
      "right = ['간/Noun', '핫라인/Noun']\n",
      "\n",
      "base = 간/Noun\n",
      "left = ['남북/Noun', '정상/Noun']\n",
      "right = ['핫라인/Noun', '이/Josa']\n",
      "\n",
      "base = 핫라인/Noun\n",
      "left = ['정상/Noun', '간/Noun']\n",
      "right = ['이/Josa', '20일/Number']\n",
      "\n",
      "base = 이/Josa\n",
      "left = ['간/Noun', '핫라인/Noun']\n",
      "right = ['20일/Number', '청와대/Noun']\n",
      "\n",
      "base = 20일/Number\n",
      "left = ['핫라인/Noun', '이/Josa']\n",
      "right = ['청와대/Noun', '와/Josa']\n",
      "\n",
      "base = 청와대/Noun\n",
      "left = ['이/Josa', '20일/Number']\n",
      "right = ['와/Josa', '북한/Noun']\n",
      "\n",
      "base = 와/Josa\n",
      "left = ['20일/Number', '청와대/Noun']\n",
      "right = ['북한/Noun', '국무위원/Noun']\n",
      "\n",
      "base = 북한/Noun\n",
      "left = ['청와대/Noun', '와/Josa']\n",
      "right = ['국무위원/Noun', '회/Noun']\n",
      "\n",
      "base = 국무위원/Noun\n",
      "left = ['와/Josa', '북한/Noun']\n",
      "right = ['회/Noun', '사이/Noun']\n",
      "\n",
      "base = 회/Noun\n",
      "left = ['북한/Noun', '국무위원/Noun']\n",
      "right = ['사이/Noun', '에/Josa']\n",
      "\n",
      "base = 사이/Noun\n",
      "left = ['국무위원/Noun', '회/Noun']\n",
      "right = ['에/Josa', '정식/Noun']\n",
      "\n",
      "base = 에/Josa\n",
      "left = ['회/Noun', '사이/Noun']\n",
      "right = ['정식/Noun', '개통/Noun']\n",
      "\n",
      "base = 정식/Noun\n",
      "left = ['사이/Noun', '에/Josa']\n",
      "right = ['개통/Noun', '됐다/Verb']\n",
      "\n",
      "base = 개통/Noun\n",
      "left = ['에/Josa', '정식/Noun']\n",
      "right = ['됐다/Verb']\n",
      "\n",
      "base = 됐다/Verb\n",
      "left = ['정식/Noun', '개통/Noun']\n",
      "right = []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "windows = 2\n",
    "\n",
    "# scanning (word, context) pairs\n",
    "base2contexts = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# debug code\n",
    "print(words, end='\\n\\n')\n",
    "\n",
    "n = len(words)\n",
    "\n",
    "for i, base in enumerate(words):\n",
    "\n",
    "    b = max(0, i - windows)\n",
    "    e = min(i + windows, n) + 1\n",
    "\n",
    "    # left_contexts\n",
    "    left_contexts = words[b:i]\n",
    "    for context in left_contexts:\n",
    "        base2contexts[base][context] += 1\n",
    "\n",
    "    # right_contexts\n",
    "    right_contexts = words[i+1:e]\n",
    "    for context in right_contexts:\n",
    "        base2contexts[base][context] += 1\n",
    "\n",
    "    # debug code\n",
    "    print('base = {}'.format(base))\n",
    "    print('left = {}'.format(left_contexts), end='\\n')\n",
    "    print('right = {}'.format(right_contexts), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defaultdict 를 dict 로 변환하면 pprint 하여 보기가 편합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base2contexts = dict(base2contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pprint(base2contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vocabulary 를 만듭니다. \n",
    "\n",
    "defaultdict 를 이용하면 자동으로 단어를 추가하는 dict 를 만들 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = 0\n",
      "b = 1\n",
      "c = 2\n",
      "b = 1\n",
      "d = 3\n",
      "{'a': 0, 'b': 1, 'c': 2, 'd': 3}\n"
     ]
    }
   ],
   "source": [
    "vocabulary = defaultdict(lambda: len(vocabulary))\n",
    "\n",
    "for char in 'a b c b d'.split():\n",
    "    print('{} = {}'.format(char, vocabulary[char]))\n",
    "\n",
    "print(dict(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "co-occurrence matrix 는 {row:{col:frequency}} 형식입니다. row 와 col 의 값을 vocabulary 에 넣어 index 로 만듭니다. 그리고 cooccurrence frequency 를 data 에 입력하여 csr_matrix 형식으로 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Encoding dict to vectors\n",
    "vocabulary = defaultdict(lambda: len(vocabulary))\n",
    "\n",
    "rows = []\n",
    "cols = []\n",
    "data = []\n",
    "for base, contexts in base2contexts.items():\n",
    "    base_idx = vocabulary[base]\n",
    "    for context, cooccurrence in contexts.items():\n",
    "        context_idx = vocabulary[context]\n",
    "        rows.append(base_idx)\n",
    "        cols.append(context_idx)\n",
    "        data.append(cooccurrence)\n",
    "\n",
    "x = csr_matrix((data, (rows, cols)))\n",
    "vocabulary = dict(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "co-occurrence matrix 의 크기는 (19, 19) 이며"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 19)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vocabulary 는 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'20일/Number': 8,\n",
       " '간/Noun': 5,\n",
       " '개통/Noun': 17,\n",
       " '국무위원/Noun': 12,\n",
       " '남북/Noun': 3,\n",
       " '됐다/Verb': 18,\n",
       " '북한/Noun': 11,\n",
       " '사이/Noun': 14,\n",
       " '에/Josa': 15,\n",
       " '역사/Noun': 0,\n",
       " '와/Josa': 10,\n",
       " '이/Josa': 7,\n",
       " '인/Josa': 2,\n",
       " '적/Suffix': 1,\n",
       " '정상/Noun': 4,\n",
       " '정식/Noun': 16,\n",
       " '청와대/Noun': 9,\n",
       " '핫라인/Noun': 6,\n",
       " '회/Noun': 13}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dense matrix 로 만들면 co-occurrence 를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]],\n",
       "       dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using soynlp\n",
    "\n",
    "이 과정은 soynlp 의 sent_to_word_contexts_matrix 를 이용할 수도 있습니다.\n",
    "\n",
    "tokenizer 의 기본값은 lambda x:x.split() 입니다. 앞서 이용한 Okt 의 pos(join=True) 를 이용하기 위하여 custom_tokenize 함수를 만듭니다.\n",
    "\n",
    "input 은 list of str 형식의 sentences 입니다. 이를 위해서 `sent` 를 list 로 감싸서 입력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create (word, contexts) matrix\n",
      "  - counting word frequency from 0 sents, mem=0.501 Gb\n",
      "  - scanning (word, context) pairs from 0 sents, mem=0.501 Gb\n",
      "  - (word, context) matrix was constructed. shape = (19, 19)                    \n",
      "  - done\n"
     ]
    }
   ],
   "source": [
    "from soynlp.vectorizer import sent_to_word_contexts_matrix\n",
    "\n",
    "custom_tokenizer = lambda s:tokenizer.pos(s, join=True)\n",
    "\n",
    "x, idx_to_vocab = sent_to_word_contexts_matrix(\n",
    "    [sent],\n",
    "    windows = 2,\n",
    "    min_tf = 1,\n",
    "    tokenizer = custom_tokenizer,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동일한 크기의 행렬을 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 19)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 index 가 달라져서 matrix 의 모양은 다릅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       "        [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0],\n",
       "        [1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "       dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['정상/Noun',\n",
       " '에/Josa',\n",
       " '적/Suffix',\n",
       " '인/Josa',\n",
       " '간/Noun',\n",
       " '20일/Number',\n",
       " '이/Josa',\n",
       " '정식/Noun',\n",
       " '핫라인/Noun',\n",
       " '와/Josa',\n",
       " '청와대/Noun',\n",
       " '국무위원/Noun',\n",
       " '회/Noun',\n",
       " '됐다/Verb',\n",
       " '북한/Noun',\n",
       " '사이/Noun',\n",
       " '개통/Noun',\n",
       " '역사/Noun',\n",
       " '남북/Noun']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
