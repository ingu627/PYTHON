{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word adjacent graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soynlp=0.0.491\n",
      "added lovit_textmining_dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['성씨/NNP',\n",
       " '강북/NNP',\n",
       " '인근/NNG',\n",
       " '치킨/NNP',\n",
       " '집/NNG',\n",
       " '이씨/NNP',\n",
       " '뒤/NNG',\n",
       " '쫓/VV',\n",
       " '실랑이/NNG',\n",
       " '쓰러뜨리/VV',\n",
       " '후/NNG',\n",
       " '총기/NNG',\n",
       " '가져오/VV',\n",
       " '망치/NNP',\n",
       " '이씨/NNP',\n",
       " '머리/NNG',\n",
       " '때리/VV']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import config\n",
    "from navernews_10days import get_news_paths\n",
    "from soynlp.utils import DoublespaceLineCorpus\n",
    "\n",
    "path = get_news_paths(date='2016-10-20', tokenize='komoran')\n",
    "sents = DoublespaceLineCorpus(path, iter_sent=True, num_sent=10000)\n",
    "\n",
    "def tokenizer(sent):\n",
    "    words = sent.split()\n",
    "    words = [w for w in words if ('/N' in w) or ('/V' in w)]\n",
    "    return words\n",
    "\n",
    "sent = '성씨/NNP 는/JX 강북/NNP 서/JKB 인근/NNG 치킨/NNP 집/NNG 까지/JX 이씨/NNP 뒤/NNG 를/JKO 쫓/VV 으며/EC 실랑이/NNG 하/XSV 다/EC 쓰러뜨리/VV ㄴ/ETM 후/NNG 총기/NNG 와/JC 함께/MAG 가져오/VV ㄴ/ETM 망치/NNP 로/JKB 이씨/NNP 머리/NNG 를/JKO 때리/VV 었/EP 다/EC'\n",
    "tokenizer(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "construct adjacent graph was done                    \n",
      "transforming dict to sparse was done                    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3430, 3430)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphutils import sents_to_adjacent_graph\n",
    "\n",
    "X, idx_to_vocab = sents_to_adjacent_graph(sents, tokenizer,\n",
    "    min_count=10, min_cooccurrence=3, verbose=True)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PageRank\n",
    "\n",
    "PageRank 의 구현체입니다. matrix multiplication 으로 구현하면 빠른 속도로 계산이 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "def pagerank(inbound_matrix, df=0.85, max_iter=30,\n",
    "    bias=None, ranksum=1.0, converge_threshold=0.0001):\n",
    "\n",
    "    converge_threshold_ = ranksum * converge_threshold\n",
    "    n_nodes, initial_weight, rank, bias = _initialize_rank_parameters(\n",
    "        inbound_matrix, df, bias, ranksum)\n",
    "\n",
    "    for n_iter in range(1, max_iter + 1):\n",
    "        rank_new = _update_pagerank(inbound_matrix, rank, bias, df, ranksum)\n",
    "        diff = np.sqrt(((rank - rank_new) **2).sum())\n",
    "        rank = rank_new\n",
    "\n",
    "        if diff <= converge_threshold_:\n",
    "            print('Early stop. because it already converged.')\n",
    "            break\n",
    "        print('iter {}, diff = {}'.format(n_iter, diff))\n",
    "    return rank\n",
    "\n",
    "def _initialize_rank_parameters(inbound_matrix, df, bias, ranksum):\n",
    "    # Check number of nodes and initial weight\n",
    "    n_nodes = inbound_matrix.shape[0]\n",
    "    initial_weight = ranksum / n_nodes\n",
    "\n",
    "    # Initialize rank and bias\n",
    "    rank = np.asarray([initial_weight] * n_nodes)    \n",
    "    if not bias:\n",
    "        bias = rank.copy()\n",
    "    elif not isinstance(bias, np.ndarray):\n",
    "        raise ValueError('bias must be numpy.ndarray type or None')\n",
    "\n",
    "    return n_nodes, initial_weight, rank, bias\n",
    "\n",
    "def _update_pagerank(inbound_matrix, rank, bias, df, ranksum=1.0):\n",
    "    # call scipy.sparse safe_sparse_dot()\n",
    "    rank_new = inbound_matrix.dot(rank)\n",
    "    rank_new = normalize(rank_new.reshape(1, -1), norm='l2').reshape(-1) * ranksum\n",
    "    rank_new = df * rank_new + (1 - df) * bias\n",
    "    return rank_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1, diff = 0.8466561348919707\n",
      "iter 2, diff = 0.44062735983446144\n",
      "iter 3, diff = 0.26686915892547636\n",
      "iter 4, diff = 0.19848804324946864\n",
      "iter 5, diff = 0.16350166069114333\n",
      "iter 6, diff = 0.14425921489525345\n",
      "iter 7, diff = 0.13235490490988563\n",
      "iter 8, diff = 0.12375492077623557\n",
      "iter 9, diff = 0.11667014101824227\n",
      "iter 10, diff = 0.11034544071710771\n",
      "iter 11, diff = 0.10447019812905214\n",
      "iter 12, diff = 0.09891811041387799\n",
      "iter 13, diff = 0.09363769044597278\n",
      "iter 14, diff = 0.0886070034445748\n",
      "iter 15, diff = 0.08381515790090775\n",
      "iter 16, diff = 0.07925490557011872\n",
      "iter 17, diff = 0.0749197436294102\n",
      "iter 18, diff = 0.07080293571301226\n",
      "iter 19, diff = 0.06689723521148647\n",
      "iter 20, diff = 0.06319493137026334\n",
      "iter 21, diff = 0.059687959926565906\n",
      "iter 22, diff = 0.05636805162041969\n",
      "iter 23, diff = 0.053226854437629145\n",
      "iter 24, diff = 0.05025604300006645\n",
      "iter 25, diff = 0.04744740251625334\n",
      "iter 26, diff = 0.04479289258518155\n",
      "iter 27, diff = 0.042284697415324465\n",
      "iter 28, diff = 0.039915256814848914\n",
      "iter 29, diff = 0.03767729311215398\n",
      "iter 30, diff = 0.03556382118763951\n"
     ]
    }
   ],
   "source": [
    "pr = pagerank(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "soygraph 의 PageRank 에 위의 코드를 정리해 두었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 : diff = 0.8466561348919707 (0.001 sec)\n",
      "iter 2 : diff = 0.44062735983446144 (0.001 sec)\n",
      "iter 3 : diff = 0.26686915892547636 (0.001 sec)\n",
      "iter 4 : diff = 0.19848804324946864 (0.001 sec)\n",
      "iter 5 : diff = 0.16350166069114333 (0.001 sec)\n",
      "iter 6 : diff = 0.14425921489525345 (0.001 sec)\n",
      "iter 7 : diff = 0.13235490490988563 (0.001 sec)\n",
      "iter 8 : diff = 0.12375492077623557 (0.001 sec)\n",
      "iter 9 : diff = 0.11667014101824227 (0.001 sec)\n",
      "iter 10 : diff = 0.11034544071710771 (0.001 sec)\n",
      "iter 11 : diff = 0.10447019812905214 (0.001 sec)\n",
      "iter 12 : diff = 0.09891811041387799 (0.001 sec)\n",
      "iter 13 : diff = 0.09363769044597278 (0.001 sec)\n",
      "iter 14 : diff = 0.0886070034445748 (0.001 sec)\n",
      "iter 15 : diff = 0.08381515790090775 (0.001 sec)\n",
      "iter 16 : diff = 0.07925490557011872 (0.001 sec)\n",
      "iter 17 : diff = 0.0749197436294102 (0.001 sec)\n",
      "iter 18 : diff = 0.07080293571301226 (0.001 sec)\n",
      "iter 19 : diff = 0.06689723521148647 (0.001 sec)\n",
      "iter 20 : diff = 0.06319493137026334 (0.001 sec)\n",
      "iter 21 : diff = 0.059687959926565906 (0.001 sec)\n",
      "iter 22 : diff = 0.05636805162041969 (0.001 sec)\n",
      "iter 23 : diff = 0.053226854437629145 (0.001 sec)\n",
      "iter 24 : diff = 0.05025604300006645 (0.001 sec)\n",
      "iter 25 : diff = 0.04744740251625334 (0.001 sec)\n",
      "iter 26 : diff = 0.04479289258518155 (0.001 sec)\n",
      "iter 27 : diff = 0.042284697415324465 (0.001 sec)\n",
      "iter 28 : diff = 0.039915256814848914 (0.001 sec)\n",
      "iter 29 : diff = 0.03767729311215398 (0.001 sec)\n",
      "iter 30 : diff = 0.03556382118763951 (0.001 sec)\n"
     ]
    }
   ],
   "source": [
    "from soygraph.ranking import PageRank\n",
    "\n",
    "pr = PageRank().rank(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextRank\n",
    "\n",
    "Rank 가 높은 단어들을 선택하면 `서울`, `연합뉴스`와 같은 일반 명사들이 키워드로 선택됩니다. 이유는 문서 집합이 여러 주제가 섞여 있기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| 서울/NNP | 연합뉴스/NNP | 일/NNB  | 이/VCP  | 오전/NNP | \n",
      "| 있/VV   | 이/NP   | 것/NNB  | 수/NNB  | 제공/NNG | \n",
      "| 하/VV   | 기자/NNG | 오후/NNG | 자료/NNG | 밝히/VV  | \n",
      "| 말/NNG  | 현지/NNG | 예정/NNG | 고양/NNP | 국회/NNG | \n",
      "| 되/VV   | 중/NNB  | 부산/NNP | 지나/VV  | 없/VA   | \n",
      "| 않/VX   | 계획/NNG | 백/NR   | 김/NNP  | 시/NNB  | \n",
      "| 워싱턴/NNP | 서명/NNG | 년/NNB  | 받/VV   | 보이/VV  | \n",
      "| 맞/VV   | 때문/NNB | 보/VV   | 대통령/NNG | 김현태/NNP | \n",
      "| 배/NNG  | 대표/NNG | 김주성/NNP | 명/NNB  | 경기도/NNP | \n",
      "| 장관/NNG | 알/VV   | 미국/NNP | 가/VV   | 등/NNB  | \n",
      "| 이정훈/NNP | 이날/NNG | 열리/VV  | 늘/VV   | 제주/NNP | \n",
      "| 트럼프/NNP | 세종/NNP | 황/NNP  | 서초구/NNP | 오/VV   | \n",
      "| 박철홍/NNP | 전망/NNG | 주장/NNG | 원/NNB  | 전하/VV  | \n",
      "| 주/VX   | 조/NR   | 클린턴/NNP | 홍기/NNP | 류/NNP  | \n",
      "| 홍해/NNP | 설명/NNG | 위하/VV  | 여의도/NNP | 천/NR   | \n",
      "| 시작/NNG | 강남구/NNP | 자료/NNP | 윤/NNP  | 지난달/NNG | \n",
      "| 발언/NNG | 김주형/NNP | 위원장/NNG | 신준희/NA | 이재희/NNP | \n",
      "| 북한/NNP | 세종로/NNP | 사진/NNP | 따르/VV  | 중앙/NNP | \n",
      "| 서울시/NNP | 캡처/NNP | 지/VX   | 아니/VCN | 확인/NNG | \n",
      "| 임/NNP  | 달/NNG  | 모습/NNG | 시간/NNG | 마련/NNG | "
     ]
    }
   ],
   "source": [
    "top_idxs = pr.argsort()[::-1][:100]\n",
    "top_ranks = pr[top_idxs]\n",
    "\n",
    "for i, (idx, rank) in enumerate(zip(top_idxs, top_ranks)):\n",
    "    vocab = idx_to_vocab[idx]\n",
    "    if i % 5 == 0:\n",
    "        print('\\n| ', end='')\n",
    "    print('{:6}'.format(vocab, rank), end=' | ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
