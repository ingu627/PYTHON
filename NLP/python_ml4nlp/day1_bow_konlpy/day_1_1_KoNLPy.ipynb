{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 기본 사용법\n",
    "\n",
    "[KoNLPy](http://konlpy.org/ko/latest) 는 Python에서 한국어 텍스트의 전처리를 할 수 있도록 토크나이징 / 품사 태깅 / 명사 추출을 하는 Packages입니다. \n",
    "\n",
    "KoNLPy에는 트위터 형태소 분석기, 한나눔, 꼬꼬마, 코모란, 한국어-매캅 등 다양한 종류의 공개된 한국어 형태소 분석기들이 들어있습니다. 각 형태소 분석기마다 구현된 언어가 다릅니다. 특히 자바로 구현된 형태소 분석기들을 사용하기 위해서 JPype1을 먼저 설치하여야 합니다. 설치법은 [KoNLPy 홈페이지](http://konlpy.org/ko/latest)를 참고하세요\n",
    "\n",
    "이번 실습에서는 꼬꼬마, 트위터 분석기 (open-korean-text), 코모란을 이용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5.1\n"
     ]
    }
   ],
   "source": [
    "import konlpy\n",
    "from konlpy.tag import Kkma, Okt, Komoran\n",
    "from pprint import pprint\n",
    "\n",
    "print(konlpy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KoNLPy 의 패키지들은 함수를 한 번 실행시킬 때 형태소 분석에 필요한 데이터를 로딩합니다. 뒤이어 시간 측정을 할 것이니, 세 개의 형태소 분석기 모두 한 문장씩 품사 판별을 수행합니다. pos 함수에 str 형식의 문장을 입력하면 형태소 분석 결과를 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent = '이건 테스트 문장입니다'\n",
    "kkma = Kkma()\n",
    "twitter = Okt()\n",
    "komoran = Komoran()\n",
    "\n",
    "taggers = [kkma, twitter, komoran]\n",
    "names = 'kkma twitter komoran'.split()\n",
    "for tagger in taggers:\n",
    "    poses = tagger.pos(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter 에서 한 cell 의 실행시간을 보고 싶을 때에는 %%time 예약어를 이용하면 좋습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 ms, sys: 0 ns, total: 12 ms\n",
      "Wall time: 2.46 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('이건', 'NNP'), ('테스트', 'NNP'), ('문장', 'NNG'), ('이', 'VCP'), ('ㅂ니다', 'EC')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "komoran.pos(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "명사만 선택하고 싶다면 nouns 함수를 이용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['이건', '테스트', '문장']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "komoran.nouns(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 예시에서 NNP 는 고유명사라는 의미이며, NNG 는 대표명사라는 의미입니다. 그리고 이러한 품사 체계는 형태소 분석기마다 다릅니다. 각 품사표를 확인하고 싶다면 [KoNLPy][konlpy_page]의 [품사 태그 비교표][tag_table]를 보셔도 좋고, 아래와 같이 각 형태소 분석기의 태그셋을 확인하셔도 좋습니다\n",
    "\n",
    "[konlpy_page]: http://konlpy.org/ko/v0.4.4/morph/\n",
    "[tag_table]: https://docs.google.com/spreadsheets/d/1OGAjUvalBuX-oZvZ_-9tEfYD2gQe7hTGsgUpiiBSXI8/edit#gid=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EC': '연결 어미',\n",
       " 'EF': '종결 어미',\n",
       " 'EP': '선어말어미',\n",
       " 'ETM': '관형형 전성 어미',\n",
       " 'ETN': '명사형 전성 어미',\n",
       " 'IC': '감탄사',\n",
       " 'JC': '접속 조사',\n",
       " 'JKB': '부사격 조사',\n",
       " 'JKC': '보격 조사',\n",
       " 'JKG': '관형격 조사',\n",
       " 'JKO': '목적격 조사',\n",
       " 'JKQ': '인용격 조사',\n",
       " 'JKS': '주격 조사',\n",
       " 'JKV': '호격 조사',\n",
       " 'JX': '보조사',\n",
       " 'MAG': '일반 부사',\n",
       " 'MAJ': '접속 부사',\n",
       " 'MM': '관형사',\n",
       " 'NA': '분석불능범주',\n",
       " 'NF': '명사추정범주',\n",
       " 'NNB': '의존 명사',\n",
       " 'NNG': '일반 명사',\n",
       " 'NNP': '고유 명사',\n",
       " 'NP': '대명사',\n",
       " 'NR': '수사',\n",
       " 'NV': '용언추정범주',\n",
       " 'SE': '줄임표',\n",
       " 'SF': '마침표, 물음표, 느낌표',\n",
       " 'SH': '한자',\n",
       " 'SL': '외국어',\n",
       " 'SN': '숫자',\n",
       " 'SO': '붙임표(물결,숨김,빠짐)',\n",
       " 'SP': '쉼표,가운뎃점,콜론,빗금',\n",
       " 'SS': '따옴표,괄호표,줄표',\n",
       " 'SW': '기타기호 (논리수학기호,화폐기호)',\n",
       " 'VA': '형용사',\n",
       " 'VCN': '부정 지정사',\n",
       " 'VCP': '긍정 지정사',\n",
       " 'VV': '동사',\n",
       " 'VX': '보조 용언',\n",
       " 'XPN': '체언 접두사',\n",
       " 'XR': '어근',\n",
       " 'XSA': '형용사 파생 접미사',\n",
       " 'XSN': '명사파생 접미사',\n",
       " 'XSV': '동사 파생 접미사'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "komoran.tagset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Adjective': '형용사',\n",
       " 'Adverb': '부사',\n",
       " 'Alpha': '알파벳',\n",
       " 'Conjunction': '접속사',\n",
       " 'Determiner': '관형사',\n",
       " 'Eomi': '어미',\n",
       " 'Exclamation': '감탄사',\n",
       " 'Foreign': '외국어, 한자 및 기타기호',\n",
       " 'Hashtag': '트위터 해쉬태그',\n",
       " 'Josa': '조사',\n",
       " 'KoreanParticle': '(ex: ㅋㅋ)',\n",
       " 'Noun': '명사',\n",
       " 'Number': '숫자',\n",
       " 'PreEomi': '선어말어미',\n",
       " 'Punctuation': '구두점',\n",
       " 'ScreenName': '트위터 아이디',\n",
       " 'Suffix': '접미사',\n",
       " 'Unknown': '미등록어',\n",
       " 'Verb': '동사'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.tagset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 시간 측정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12개로 이뤄진 실제 뉴스 기사에 대하여 각각의 형태소 분석기를 적용해 보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sents = ['최순실 씨가 외국인투자촉진법 개정안 통과와 예산안 반영까지 꼼꼼이 챙긴 건데, 이른바 외촉법, 어떤 법이길래 최 씨가 열심히 챙긴 걸까요. 자신의 이해관계와 맞아 떨어지는 부분이 없었는지 취재기자와 한걸음 더 들여다보겠습니다. 이서준 기자, 우선 외국인투자촉진법 개정안, 어떤 내용입니까?',\n",
    "        '한마디로 대기업이 외국 투자를 받아 계열사를 설립할 때 규제를 완화시켜 주는 법안입니다. 대기업 지주사의 손자 회사가 이른바 증손회사를 만들 때 지분 100%를 출자해야 합니다. 대기업의 문어발식 계열사 확장을 막기 위한 조치인데요. 외촉법 개정안은 손자회사가 외국 투자를 받아서 증손회사를 만들 땐 예외적으로 50% 지분만 투자해도 되게끔 해주는 내용입니다.',\n",
    "        '그만큼 쉽게 완화해주는 거잖아요. 그때 기억을 더듬어보면 야당의 반발이 매우 심했습니다. 그 이유가 뭐였죠? ',\n",
    "        '대기업 특혜 법안이라는 취지였는데요. (당연히 그랬겠죠.) 당시 박영선 의원의 국회 발언을 들어보시겠습니다. [박영선 의원/더불어민주당 (2013년 12월 31일) : 경제의 근간을 흔드는 법을 무원칙적으로 이렇게 특정 재벌 회사에게 특혜를 주기 위해 간청하는 민원법을 우리가 새해부터 왜 통과시켜야 합니까.]',\n",
    "        '최순실 씨 사건을 쫓아가다 보면 본의 아니게 이번 정부의 과거로 올라가면서 복기하는 듯한 느낌이 드는데 이것도 바로 그중 하나입니다. 생생하게 기억합니다. 이 때 장면들은. 특정 재벌 회사를 위한 특혜라고 말하는데, 어떤 기업을 말하는 건가요?',\n",
    "        'SK와 GS 입니다. 개정안이 통과되는 걸 전제로 두 회사는 외국 투자를 받아 증손회사 설립을 진행중이었기 때문인데요. 당시 개정안이 통과되지 않으면 두 기업이 수조원의 손실이 생길 수 있는 것으로 알려져 있었습니다. 허창수 GS 회장과 김창근 SK회장은 2013년 8월 박 대통령과 청와대에서 대기업 회장단 오찬자리에서 외촉법 통과를 요청한 바도 있습니다. ',\n",
    "        '물론 두 기업과 최순실 씨와 연결고리가 나온 건 아니지만, 정 전 비서관 녹취파일 속 최 씨는 외촉법에 상당히 집착을 하는 걸로 보이긴 합니다.',\n",
    "        '네 그렇습니다. 통화 내용을 다시 짚어보면요. 최 씨는 외촉법 관련 예산이 12월 2일, 반드시 되어야 한다, 작년 예산으로 돼서는 안 된다고 얘기하고 있는데요. 다시 말해서 외촉법 관련 예산안이 내년에 반영되어야 한다고 압박을 하고 있는 겁니다. 그러면서 \"국민을 볼모로 잡고 있다\"며 \"국회와 정치권에 책임을 묻겠다\"고 으름장까지 놓고 있는데요. 매우 집착하는 모습인데요. 이에 대해서 정 전 비서관이 \"예산이 그렇게 빨리 통과된 적 없습니다\"고 말하자 말을 끊으면서 매우 흥분한 듯, \"그렇더라도, 그렇더라도\" 하면서 \"야당이 공약 지키라고 하면서 협조는 안 한다\", \"대통령으로 할 수 있는 일이 없다\", \"불공정 사태와 난맥상이 나온다\"며 굉장한 압박까지 하고 있습니다.',\n",
    "        '이 얘기들만 들여다봐도 마치 본인이 대통령처럼 얘기하고 있습니다. 내용들 보면 그렇지 않습니까? 혹시 최 씨가 이 외촉법 통과로 이득을 본 경우도 있습니까. ',\n",
    "        '최 씨가 입김을 넣어 차은택 씨가 주도를 한 걸로 알려진 K컬처밸리 사업이 그렇다는 얘기가 나오고 있습니다. 외촉법을 편법으로 활용해 1% 금리를 적용받았다는 지적이 나오고 있습니다. 본격 사업이 추진되기 전 최순실 국정개입 사건이 터지기는 했지만, 이외에도 다른 혜택을 받았는지는 조사가 필요해 보입니다. ',\n",
    "        '그런데 녹취파일을 보면 \"남자1\"이 등장합니다. 이 사람은 누구입니까?',\n",
    "        '정 전 비서관을 \"정 과장님\"으로 부르며 반말을 하는 남자인데요. 최순실 씨처럼 정 전 비서관을 하대하고 있습니다. 또 청와대 내부 정보를 알고 있는 듯하고 또 인사에까지 개입하려고 하고 있습니다. 그렇기 때문에 정윤회 씨로 추정은 됩니다만 확인은 되지 않습니다.'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어떤 라이브러리를 쓸지 선택하기 전에, 내 데이터의 프로세싱 시간은 얼마나 걸리는지, 그리고 그 처리 품질은 어떤지 먼저 확인을 해야 합니다. 1개의 기사에 대하여 각각의 형태소 분석기 별 프로세싱 시간을 비교하였습니다.\n",
    "\n",
    "한 구문의 실행 시간을 측정하기 위해서는 time 을 이용할 수 있습니다. time 은 현재 시각을 초 단위로 표현합니다. do your tasks 부분이 지난 다음 다시 현재 시각을 측정하고, 이전의 시간 t 를 빼면 중간의 함수가 실행되었던 시간이 초 단위로 측정됩니다.\n",
    "\n",
    "    from time import time\n",
    "    \n",
    "    t = time.time()    \n",
    "    ... do your tasks\n",
    "    t = time.time() - t\n",
    "\n",
    "각 형태소 분석기의 결과물은 tokens 안에 넣어둡니다. 형태소 분석기 마다 결과가 어떻게 다른지 비교할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kkma    : 0.970 secs\n",
      "twitter : 0.292 secs\n",
      "komoran : 0.093 secs\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "tokens = []\n",
    "\n",
    "for name, tagger in zip(names, taggers):\n",
    "\n",
    "    t = time.time()    \n",
    "    tokens.append(\n",
    "        [pos for sent in sents for pos in tagger.pos(sent)]\n",
    "    )\n",
    "    t = time.time() - t\n",
    "\n",
    "    print('{:8}: {:.3f} secs'.format(name, t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 토큰을 그대로 나열해 보는 것은 무리가 있어보입니다. 형태소 분석기 별로 고유한 단어와 그 개수를 세어보겠습니다. 그리고 그 전에도 '최순실'이라는 이름이 꼬꼬마 형태소 분석기에서 '최', '순', '실'로 나누어지는 것이 보이네요. 이는 꼬꼬마 형태소 분석기가 학습할 때, '최순실'이라는 명사가 학습데이터에 없었기 때문입니다. 이를 out of vocabulary problem이라 부릅니다. 알려지지 않은 단어를 제대로 인식하지 못하는 문제입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('최', 'NNP'),\n",
      " ('순', 'NNG'),\n",
      " ('실', 'NNG'),\n",
      " ('씨', 'NNB'),\n",
      " ('가', 'JKS'),\n",
      " ('외국인', 'NNG'),\n",
      " ('투자', 'NNG'),\n",
      " ('촉진법', 'NNG'),\n",
      " ('개정안', 'NNG'),\n",
      " ('통과', 'NNG'),\n",
      " ('와', 'JC'),\n",
      " ('예산안', 'NNG'),\n",
      " ('반영', 'NNG'),\n",
      " ('까지', 'JX'),\n",
      " ('꼼꼼이', 'MAG')]\n"
     ]
    }
   ],
   "source": [
    "pprint(tokens[0][:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 단어 빈도수 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 단어들이 몇 번 등장하였는지 그 횟수를 카운팅하겠습니다. 이 때 가장 좋지 않은 방법인 (1) dict를 이용하는 법, 조금 더 나은 (2) defaultdict를 이용하는 법, (3) collections.Counter를 이용하는 법이 있습니다. 이 튜토리얼에서는 Counter를 이용합니다. (1), (2)에 대한 설명은 day0의 튜토리얼을 참고하세요\n",
    "\n",
    "정렬은 sorted를 이용합니다. sorted 함수의 key를 통하여 정렬의 기준을 지정할 수 있습니다. \n",
    "\n",
    "lambda는 이름이 없는 함수를 의미합니다. counter는 dict이므로 keys(), values, items()를 가집니다. 이 때 items()의 return은 [(key, value), (key, value), ...] 형태이기 때문에 정렬 대상 (key, value)를 x로 볼 때, x의 1번째 값 x[1]을 기준으로 정렬하라는 의미이며, -x[1] 은 그 값에 음수를 붙였기 때문에 오름차순의 역순인 내림차순으로 정렬하라는 의미입니다. \n",
    "\n",
    "sorted의 return type은 list이기 때문에 가장 앞쪽의 5개만 slice하여 살펴봅니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('씨', 'NNB'), 11),\n",
      " (('법', 'NNG'), 11),\n",
      " (('최', 'NNP'), 10),\n",
      " (('외촉', 'NNG'), 8),\n",
      " (('회사', 'NNG'), 8),\n",
      " (('통과', 'NNG'), 7),\n",
      " (('것', 'NNB'), 7),\n",
      " (('투자', 'NNG'), 6),\n",
      " (('정', 'NNG'), 6),\n",
      " (('순', 'NNG'), 5),\n",
      " (('실', 'NNG'), 5),\n",
      " (('개정안', 'NNG'), 5),\n",
      " (('대기업', 'NNG'), 5),\n",
      " (('전', 'NNG'), 5),\n",
      " (('내용', 'NNG'), 4),\n",
      " (('비서관', 'NNG'), 4),\n",
      " (('얘기', 'NNG'), 4)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "\n",
    "counter = Counter(tokens[0])\n",
    "counter = {\n",
    "    word:freq for word, freq in counter.items()\n",
    "    if (freq >= 4) and (word[1][:2] == 'NN')\n",
    "}\n",
    "\n",
    "pprint(sorted(counter.items(), key=lambda x:-x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 모든 형태소 분석기들로부터, '최순실'이라는 이름이 제대로 잡혔는지, 그리고 빈도수가 4 이상인 명사들은 어떤 것들이 있는지를 확인해보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Tagger name = kkma\n",
      "[(('씨', 'NNB'), 11),\n",
      " (('법', 'NNG'), 11),\n",
      " (('최', 'NNP'), 10),\n",
      " (('외촉', 'NNG'), 8),\n",
      " (('회사', 'NNG'), 8),\n",
      " (('통과', 'NNG'), 7),\n",
      " (('것', 'NNB'), 7),\n",
      " (('투자', 'NNG'), 6),\n",
      " (('정', 'NNG'), 6),\n",
      " (('순', 'NNG'), 5),\n",
      " (('실', 'NNG'), 5),\n",
      " (('개정안', 'NNG'), 5),\n",
      " (('대기업', 'NNG'), 5),\n",
      " (('전', 'NNG'), 5),\n",
      " (('내용', 'NNG'), 4),\n",
      " (('비서관', 'NNG'), 4),\n",
      " (('얘기', 'NNG'), 4)]\n",
      "\n",
      "\n",
      "Tagger name = twitter\n",
      "[(('씨', 'Noun'), 11),\n",
      " (('최', 'Noun'), 10),\n",
      " (('외촉법', 'Noun'), 8),\n",
      " (('회사', 'Noun'), 8),\n",
      " (('통과', 'Noun'), 7),\n",
      " (('이', 'Noun'), 6),\n",
      " (('실', 'Noun'), 5),\n",
      " (('개정안', 'Noun'), 5),\n",
      " (('대기업', 'Noun'), 5),\n",
      " (('말', 'Noun'), 5),\n",
      " (('정', 'Noun'), 5),\n",
      " (('전', 'Noun'), 5),\n",
      " (('요', 'Noun'), 4),\n",
      " (('내용', 'Noun'), 4),\n",
      " (('투자', 'Noun'), 4),\n",
      " (('비서', 'Noun'), 4),\n",
      " (('관', 'Noun'), 4),\n",
      " (('얘기', 'Noun'), 4)]\n",
      "\n",
      "\n",
      "Tagger name = komoran\n",
      "[(('씨', 'NNB'), 11),\n",
      " (('법', 'NNB'), 7),\n",
      " (('통과', 'NNG'), 7),\n",
      " (('법', 'NNG'), 6),\n",
      " (('회사', 'NNG'), 6),\n",
      " (('정', 'NNP'), 6),\n",
      " (('최순', 'NNP'), 5),\n",
      " (('실', 'NNP'), 5),\n",
      " (('개정안', 'NNG'), 5),\n",
      " (('최', 'NNP'), 5),\n",
      " (('대기업', 'NNP'), 5),\n",
      " (('외', 'NNB'), 5),\n",
      " (('촉', 'NNB'), 5),\n",
      " (('말', 'NNG'), 5),\n",
      " (('내용', 'NNG'), 4),\n",
      " (('투자', 'NNG'), 4),\n",
      " (('때', 'NNG'), 4),\n",
      " (('비서관', 'NNG'), 4),\n",
      " (('얘기', 'NNG'), 4)]\n"
     ]
    }
   ],
   "source": [
    "for name, tokens_ in zip(names, tokens):\n",
    "\n",
    "    print('\\n\\nTagger name = {}'.format(name))\n",
    "\n",
    "    counter = Counter(tokens_)\n",
    "    counter = {word:freq for word, freq in counter.items()\n",
    "               if (freq >= 4) and (word[1][:1] == 'N')}\n",
    "\n",
    "    pprint(sorted(counter.items(), key=lambda x:x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 데이터에 적합할 정도로 universial corpus로부터 학습된 한국어 형태소 분석기는 '아직'까지는 없습니다. 그리고 한국어로 기술되었다고 하더라도, 차용한 글자만 한글일 뿐, 한국어는 아닌 언어들도 많이 있습니다. 특히 도메인 특수 용어들이 이에 해당합니다. \n",
    "\n",
    "사용할 수 있는 알고리즘들이 여러개일 경우에는 주어진 시간 안에 작업이 끝날 수 있는지와 주어진 데이터에 대한 형태소 분석기의 경향, 정성적 품질이 어느 정도인지 반드시 확인하고 이용하여야 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(sents).count('최순실')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Komoran 에 사용자 사전 추가하기\n",
    "\n",
    "KoNLPy >= 0.5.0 부터는 Komoran 에 사용자 사전을 추가할 수 있습니다.\n",
    "\n",
    "Komoran 에는 '주간아이돌'이나 '아에오아이'가 단어로 등록되어 있지 않기 때문에 미등록단어 문제가 발생합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('주간', 'NNG'),\n",
       " ('아이돌', 'NNP'),\n",
       " ('에아', 'NNP'),\n",
       " ('이오', 'NNP'),\n",
       " ('아이', 'NNP'),\n",
       " ('가', 'JKS'),\n",
       " ('나오', 'VV'),\n",
       " ('았', 'EP'),\n",
       " ('다', 'EC')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = '주간아이돌에아이오아이가나왔다'\n",
    "komoran.pos(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용자 사전은 <단어, 품사> 가 tap 으로 구분된 텍스트 파일입니다. 예시 파일에는 두 개의 단어가 포함되어 있습니다.\n",
    "\n",
    "    아이오아이   NNP\n",
    "    주간아이돌   NNP\n",
    "    \n",
    "Komoran 을 만들 때 이 파일을 추가합니다. 다시 동일한 문장을 분석하면 두 단어가 제대로 인식됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('주간아이돌', 'NNP'),\n",
       " ('에', 'NNG'),\n",
       " ('아이오아이', 'NNP'),\n",
       " ('가', 'JKS'),\n",
       " ('나오', 'VV'),\n",
       " ('았', 'EP'),\n",
       " ('다', 'EC')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "komoran_userdic = Komoran(userdic='./userdic.txt')\n",
    "komoran_userdic.pos(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
