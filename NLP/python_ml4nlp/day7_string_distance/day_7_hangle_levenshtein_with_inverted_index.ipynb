{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어를 구성하는 글자를 features 로 생각하면 단어도 sparse vector 로 생각할 수 있습니다. Euclidean distance 는 글자의 order 가 없지만, edit distance 는 글자의 order 가 있는 vector 로 생각할 수도 있습니다. 그렇다면 inverted index 를 이용하여 edit distance 가 작은 단어 셋을 탐색할 수 있습니다.\n",
    "\n",
    "이 튜토리얼에서 이용하는 패키지는 https://github.com/lovit/inverted_index_for_hangle_editdistance 에 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soynlp=0.0.49\n",
      "added lovit_textmining_dataset\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "import fast_hangle_levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'빠른 한글 수정 거리 검색을 위한 inverted index '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_hangle_levenshtein.__title__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_hangle_levenshtein.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy example\n",
    "\n",
    "총 8 개 단어를 indexer 에 입력하여 indexing 을 합니다. _index 에는 각 글자를 key 로, 해당 글자를 포함하는 글자들이 values 에 포함되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fast_hangle_levenshtein import LevenshteinIndex\n",
    "indexer = LevenshteinIndex(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indexer.indexing('아이고 어이고 아이고야 아이고야야야야 어이구야 지화자 징화자 쟝화장'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'고': {'아이고', '아이고야', '아이고야야야야', '어이고'},\n",
       " '구': {'어이구야'},\n",
       " '아': {'아이고', '아이고야', '아이고야야야야'},\n",
       " '야': {'아이고야', '아이고야야야야', '어이구야'},\n",
       " '어': {'어이고', '어이구야'},\n",
       " '이': {'아이고', '아이고야', '아이고야야야야', '어이고', '어이구야'},\n",
       " '자': {'지화자', '징화자'},\n",
       " '장': {'쟝화장'},\n",
       " '쟝': {'쟝화장'},\n",
       " '지': {'지화자'},\n",
       " '징': {'징화자'},\n",
       " '화': {'쟝화장', '지화자', '징화자'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer._index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "초/중/종성을 분리할 경우에는 각각 _cho_index, _jung_index, _jong_index 에 동일한 형식으로 인덱싱이 되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ㄱ': {'아이고', '아이고야', '아이고야야야야', '어이고', '어이구야'},\n",
       " 'ㅇ': {'아이고', '아이고야', '아이고야야야야', '어이고', '어이구야'},\n",
       " 'ㅈ': {'쟝화장', '지화자', '징화자'},\n",
       " 'ㅎ': {'쟝화장', '지화자', '징화자'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer._cho_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "verbose on 일 때에는 query term 에 포함된 글자를 지닌 글자들의 개수를 candidates 로 표시하고, max_distance 보다 작은 distance 를 지니는 후보들을 filtering 하여 그 개수를 표시합니다. `아`, `이`, `코` 중 한 개 이상의 글자를 포함하는 단어는 5 개가 있었으며, 그 중 2 개에 대해서만 실제 거리 계산을 합니다.\n",
    "\n",
    "Levenshtein dsitance 는 오탈자 교정의 목적을 위해 이용되는 경우가 많은데, 오탈자는 한글자 혹은 두 글자 (초/중/종성 기준) 정도만 틀리기 때문에 max distance 를 충분히 작은 값으로 설정해도 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query=아이코, candidates=5 -> 2, time=0.000602 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('아이고', 1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer.verbose = True\n",
    "indexer.levenshtein_search('아이코', max_distance=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query=아이코, candidates=8 -> 3, time=0.00137 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('아이고', 0.3333333333333333), ('어이고', 0.6666666666666666)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer.jamo_levenshtein_search('아이코')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Financial text example\n",
    "\n",
    "위의 git repository 에는 금융 관련 뉴스 분석용 13 만여개의 명사 사전이 있습니다. 이 사전을 로딩합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132864"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./inverted_index_for_hangle_editdistance/data/nouns_from_financial_news.json', encoding='utf-8') as f:\n",
    "    import json    \n",
    "    noun_scores = json.load(f)\n",
    "len(noun_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['양식어가',\n",
       " '식품유통사',\n",
       " 'ETN전담팀',\n",
       " '도로주행',\n",
       " '로우프라이스펀드',\n",
       " '국가브랜드',\n",
       " '대체부지',\n",
       " '한화솔라원',\n",
       " '박준영씨',\n",
       " '온라인마트']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(noun_scores.keys())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "132,864 개의 단어를 indexing 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "financial_word_indexer = LevenshteinIndex(noun_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "character set 을 기준으로 모두 등장하는 글자를 찾기 때문에 순서는 달라질 수 있습니다. 이번에는 `분식회계`의 글자를 1 개 이상 포함하는 10,137 개의 단어 중 `max_distance = 1`  보다 작은 값을 지닌 7 개의 단어에 대해서만 거리 계산을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query=분식회계, candidates=10137 -> 7, time=0.0122 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('분식회계', 0), ('분식회계설', 1), ('분식회', 1), ('분석회계', 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_word_indexer.verbose = True\n",
    "financial_word_indexer.levenshtein_search('분식회계')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query=분식회계a, candidates=10451 -> 3, time=0.016 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('분식회계설', 1), ('분식회계', 1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_word_indexer.levenshtein_search('분식회계a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "초/중/종성을 분리하는 jamo levenshtein distance 기준으로도 검색이 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query=분식회계, candidates=129099 -> 412, time=0.399 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('분식회계', 0),\n",
       " ('분석회계', 0.3333333333333333),\n",
       " ('부실회계', 0.6666666666666666),\n",
       " ('분석체계', 1.0),\n",
       " ('분식회계설', 1),\n",
       " ('분식회', 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_word_indexer.jamo_levenshtein_search('분식회계', max_distance=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`max_distance` 를 작게 설정하면 실제 거리 계산을 하는 단어의 숫자도 줄어듭니다. 하지만 시간은 많이 줄어들지 않았습니다. Filtering 을 하는 overhead 가 무겁게 구현되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query=분식회계, candidates=129099 -> 4, time=0.321 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('분식회계', 0), ('분석회계', 0.3333333333333333)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_word_indexer.jamo_levenshtein_search('분식회계', max_distance=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Compare times\n",
    "\n",
    "Index 를 이용하는 경우와 그렇지 않은 경우의 시간을 비교합니다. 13 만여개의 단어와의 거리를 모두 계산하기 때문에 거리 계산의 시간이 걸립니다. 0.016 초에 할 수 있는 작업에 2.5 초가 걸렸습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search time = 2.328 sec\n",
      "sorting time = 2.346 sec\n",
      "[('분식회계', 0), ('분식회', 1), ('분식회계설', 1), ('분석회계', 1)]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from fast_hangle_levenshtein import levenshtein\n",
    "from fast_hangle_levenshtein import jamo_levenshtein\n",
    "\n",
    "query = '분식회계'\n",
    "\n",
    "begin_time = time.time()\n",
    "distance = {word:levenshtein(word, query) for word in noun_scores}\n",
    "search_time = time.time() - begin_time\n",
    "\n",
    "similars = sorted(filter(lambda x:x[1] <= 1, distance.items()), key=lambda x:x[1])\n",
    "sorting_time = time.time() - begin_time\n",
    "\n",
    "print('search time = {:.4} sec'.format(search_time))\n",
    "print('sorting time = {:.4} sec'.format(sorting_time))\n",
    "print(similars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "초/중/종성을 분리할 경우에는 스트링 연산을 하기 때문에 더 많이 느려집니다. 0.4 초 안에 해결되는 작업에 28 초가 걸립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search time = 35.89 sec\n",
      "[('분식회계', 0), ('분석회계', 0.3333333333333333), ('부실회계', 0.6666666666666666), ('분식회', 1), ('분석체계', 1.0), ('분식회계설', 1)]\n"
     ]
    }
   ],
   "source": [
    "search_time = time.time()\n",
    "distance = {word:jamo_levenshtein(word, query) for word in noun_scores}\n",
    "search_time = time.time() - search_time\n",
    "print('search time = {} sec'.format('%.2f'%search_time))\n",
    "\n",
    "similars = sorted(filter(lambda x:x[1] <= 1, distance.items()), key=lambda x:x[1])\n",
    "print(similars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "이처럼 index 를 이용하여 불필요한 계산을 하지 않으면 빠른 nearest neighbor search 가 가능합니다. Edit distance 기준으로는 distance 가 작은 elements 를 효율적으로 찾을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
