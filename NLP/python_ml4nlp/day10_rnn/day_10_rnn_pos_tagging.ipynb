{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch official tutorial 에서는 Recurrent Neural Network 를 이용한 Part of Speech tagger 의 구현 예시가 있습니다. 우리는 이를 통하여 RNN, 그 중 LSTM 을 이용하는 연습을 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1.post2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터는 두 개의 문장, 총 3 개의 tags 입니다. 구현 과정을 연습할 때에는 이처럼 확인 가능한 작은 데이터나, 경향을 잘 알고 있는 데이터로 하는 것이 좋습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [\n",
    "    (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "    (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "utils.py 파일에 기본적인 유틸 함수들을 만들어 두었습니다. Sentence sequence 와 tag sequence 를 각각 나눠서 vocabulary scanning 을 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import decode_sequence\n",
    "from utils import encode_sequence\n",
    "from utils import scan_vocabulary\n",
    "\n",
    "sents, tags = zip(*training_data)\n",
    "\n",
    "idx_to_vocab, vocab_to_idx = scan_vocabulary(sents)\n",
    "idx_to_tag, tag_to_idx = scan_vocabulary(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'dog', 'ate', 'the', 'apple', 'Everybody', 'read', 'that', 'book']\n",
      "['NN', 'DET', 'V']\n"
     ]
    }
   ],
   "source": [
    "print(idx_to_vocab)\n",
    "print(idx_to_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4])\n",
      "tensor([1, 0, 2, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "print(encode_sequence(sents[0], vocab_to_idx))\n",
    "print(encode_sequence(tags[0], tag_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [encode_sequence(sent, vocab_to_idx) for sent in sents]\n",
    "Y = [encode_sequence(tag, tag_to_idx) for tag in tags]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.LSTM.forward 함수의 input, output 의 size 는 각각 (seq_len, batch_size, input dim), (seq_len, batch_size, output dim) 입니다. 여기에서는 batch_size = 1 인 경우의 모델을 만들어봅니다.\n",
    "\n",
    "우리는 word embedding vectors 도 LSTM model 안에 구현할 것입니다. lookup 이 이뤄지면 LSTM layer 에 input 을 입력하고, 매 시점의 output 마다 linear layer 를 이용하여 softmax 수행 (hidden2tag ) 할 것입니다.\n",
    "\n",
    "```python\n",
    "class Model(nn.LSTM):\n",
    "    def __init__(self, ... ):\n",
    "        # ...\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "```\n",
    "\n",
    "그리고 LSTM 이 이용할 hidden layer 값을 저장할 준비를 합니다. hidden 의 format 은 (num_layers, minibatch_size, hidden_dim) 입니다. 우리는 deep RNN 이 아니기 때문에 num_layers 를 1 로 정의하였으며, 하나의 문장을 입력하여 하나의 품사열을 얻을 걷이시 때문에 minibatch_size 도 1 로 정의하였습니다.\n",
    "\n",
    "```python\n",
    "class Model(nn.LSTM):\n",
    "    # ...\n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(1, 1, self.hidden_dim),\n",
    "                torch.zeros(1, 1, self.hidden_dim))\n",
    "```\n",
    "\n",
    "PyTorch 에서의 LSTM.forward 함수의 입력/출력 값의 형식은 아래와 같습니다. (hidden, cell) 에는 마지막 hidden 과 memory cell 의 값이 저장되어 있습니다. 그렇기 때문에 우리는 init_hidden 에서 두 개의 (1, 1, hidden_dim) 의 zero tensor 를 만듭니다.\n",
    "\n",
    "    output, (hidden, cell) = LSTM.forward(input, (hidden, cell))\n",
    "\n",
    "output 은 각 input 에 대한 모든 output 이 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # (num_layers, minibatch_size, hidden_dim)\n",
    "        return (torch.zeros(1, 1, self.hidden_dim),\n",
    "                torch.zeros(1, 1, self.hidden_dim))\n",
    "\n",
    "    def forward(self, sentence, debug=False):\n",
    "        len_sen = len(sentence)\n",
    "        lstm_input = self.word_embeddings(sentence)\n",
    "        lstm_input = lstm_input.view(len_sen, 1, -1)\n",
    "        hidden, cell = self.init_hidden()\n",
    "\n",
    "        lstm_out, (hidden, cell) = self.lstm(lstm_input, (hidden, cell))\n",
    "\n",
    "        lstm_out_ = lstm_out.view(len(sentence), -1)\n",
    "        tag_space = self.hidden2tag(lstm_out_)\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "\n",
    "        if debug:\n",
    "            print('input size       : {}'.format(lstm_input.size()))            \n",
    "            print('lstm hidden size : {}'.format(hidden.size()))\n",
    "            print('lstm cell size   : {}'.format(cell.size()))\n",
    "            print('lstm_out size    : {}'.format(lstm_out.size()))\n",
    "            print('lstm_out_ size   : {}'.format(lstm_out_.size()))\n",
    "            print('tag scores size  : {}'.format(tag_scores.size()))\n",
    "\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size       : torch.Size([5, 1, 7])\n",
      "lstm hidden size : torch.Size([1, 1, 8])\n",
      "lstm cell size   : torch.Size([1, 1, 8])\n",
      "lstm_out size    : torch.Size([5, 1, 8])\n",
      "lstm_out_ size   : torch.Size([5, 8])\n",
      "tag scores size  : torch.Size([5, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8630, -1.1220, -1.3765],\n",
       "        [-0.8189, -1.1604, -1.4035],\n",
       "        [-0.7957, -1.2365, -1.3535],\n",
       "        [-0.8032, -1.2118, -1.3686],\n",
       "        [-0.8371, -1.1185, -1.4259]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 개발용 데이터이기 때문에 embedding dimension 이나 hidden dimension 이 작아도 됩니다만, 실제 모델에서는 이 값을 충분히 크게 설정해야 합니다. \n",
    "embedding_dim = 7\n",
    "hidden_dim = 8\n",
    "vocab_size = len(vocab_to_idx)\n",
    "tagset_size = len(tag_to_idx)\n",
    "\n",
    "model = Model(embedding_dim, hidden_dim, vocab_size, tagset_size)\n",
    "model(X[0], debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 현재의 모델에 forward 를 하여 중간 값을 확인하고 싶다면 torch.no_grad() 를 이용할 수 있습니다. 모델의 gradient 에 어떤 값도 저장하지 않습니다. debugging 용 방법입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size       : torch.Size([5, 1, 7])\n",
      "lstm hidden size : torch.Size([1, 1, 8])\n",
      "lstm cell size   : torch.Size([1, 1, 8])\n",
      "lstm_out size    : torch.Size([5, 1, 8])\n",
      "lstm_out_ size   : torch.Size([5, 8])\n",
      "tag scores size  : torch.Size([5, 3])\n",
      "\n",
      "## tag true\n",
      "tensor([1, 0, 2, 1, 0])\n",
      "\n",
      "## tag predicted idx\n",
      "tensor([0, 0, 0, 0, 0])\n",
      "\n",
      "## tag predicted\n",
      "['NN', 'NN', 'NN', 'NN', 'NN']\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    tag_scores = model.forward(X[0], debug=True)\n",
    "    tag_pred_idx = torch.argmax(tag_scores, dim=1)\n",
    "    tag_pred = decode_sequence(tag_pred_idx, idx_to_tag)\n",
    "    print('\\n## tag true\\n{}'.format(Y[0]))\n",
    "    print('\\n## tag predicted idx\\n{}'.format(tag_pred_idx))\n",
    "    print('\\n## tag predicted\\n{}'.format(tag_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X, Y, optimizer, loss_func, epoch):\n",
    "    loss_sum = 0\n",
    "    for words, tags in zip(X, Y):\n",
    "        model.zero_grad()\n",
    "        tag_scores = model(words)\n",
    "        loss = loss_func(tag_scores, tags)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_sum += loss.item()\n",
    "    return model, loss_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function 은 negative log likelihood loss 를 이용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 10, loss = 1.059\n",
      "epoch = 20, loss = 1.026\n",
      "epoch = 30, loss = 0.9874\n",
      "epoch = 40, loss = 0.936\n",
      "epoch = 50, loss = 0.8653\n",
      "epoch = 60, loss = 0.7707\n",
      "epoch = 70, loss = 0.6577\n",
      "epoch = 80, loss = 0.5444\n",
      "epoch = 90, loss = 0.4456\n",
      "epoch = 100, loss = 0.3645\n",
      "epoch = 110, loss = 0.299\n",
      "epoch = 120, loss = 0.2463\n",
      "epoch = 130, loss = 0.2041\n",
      "epoch = 140, loss = 0.1704\n",
      "epoch = 150, loss = 0.1436\n",
      "epoch = 160, loss = 0.1222\n",
      "epoch = 170, loss = 0.1049\n",
      "epoch = 180, loss = 0.09101\n",
      "epoch = 190, loss = 0.07966\n",
      "epoch = 200, loss = 0.07032\n",
      "epoch = 210, loss = 0.06257\n",
      "epoch = 220, loss = 0.05609\n",
      "epoch = 230, loss = 0.05062\n",
      "epoch = 240, loss = 0.04596\n",
      "epoch = 250, loss = 0.04197\n",
      "epoch = 260, loss = 0.03853\n",
      "epoch = 270, loss = 0.03553\n",
      "epoch = 280, loss = 0.03291\n",
      "epoch = 290, loss = 0.0306\n",
      "epoch = 300, loss = 0.02856\n"
     ]
    }
   ],
   "source": [
    "# Negative Log Likelihood Loss\n",
    "loss_func = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "max_epoch = 300\n",
    "for epoch in range(1, max_epoch+1):\n",
    "    model, loss = train(model, X, Y, optimizer, loss_func, epoch)\n",
    "    loss /= len(X)\n",
    "    if epoch % 10 == 0:\n",
    "        print('epoch = {}, loss = {:.4}'.format(epoch, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 이후에는 tagging 이 제대로 됨을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size       : torch.Size([5, 1, 7])\n",
      "lstm hidden size : torch.Size([1, 1, 8])\n",
      "lstm cell size   : torch.Size([1, 1, 8])\n",
      "lstm_out size    : torch.Size([5, 1, 8])\n",
      "lstm_out_ size   : torch.Size([5, 8])\n",
      "tag scores size  : torch.Size([5, 3])\n",
      "\n",
      "## tag true\n",
      "tensor([1, 0, 2, 1, 0])\n",
      "\n",
      "## tag predicted idx\n",
      "tensor([1, 0, 2, 1, 0])\n",
      "\n",
      "## tag predicted\n",
      "['DET', 'NN', 'V', 'DET', 'NN']\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    tag_scores = model.forward(X[0], debug=True)\n",
    "    tag_pred_idx = torch.argmax(tag_scores, dim=1)\n",
    "    tag_pred = decode_sequence(tag_pred_idx, idx_to_tag)\n",
    "    print('\\n## tag true\\n{}'.format(Y[0]))\n",
    "    print('\\n## tag predicted idx\\n{}'.format(tag_pred_idx))\n",
    "    print('\\n## tag predicted\\n{}'.format(tag_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
