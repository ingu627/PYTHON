{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch 의 nn.Module 에는 train / evaluation mode 가 있습니다. \n",
    "\n",
    "Dropout 은 일정한 비율로 특정 마디의 값을 0 으로 치환하는 기법입니다. 그리고 학습 시에는 dropout 을 적용하지만, 학습된 모델을 적용할 때에는 dropout 을 적용하지 않습니다. 그래서 마치 ensemble 과 같은 효과를 얻습니다. 이처럼 학습과 모델 적용 단계에 따라 Dropout layer 가 다르게 작동하도록 만들기 위하여 nn.Module 의 mode 를 변경해야 합니다.\n",
    "\n",
    "우리는 `3 - 10 - 2` 의 hidden layer 를 지니는 Feed forward neural network 를 만듭니다. activation function 은 hyper tangent 를 이용합니다.\n",
    "\n",
    "그리고 train 과 eval mode 에 따른 값의 차이를 살펴봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1.post2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, in_dim=3, hidden_dim=10, out_dim=2, dropout=0.5):\n",
    "        super(Net, self).__init__()\n",
    "        self.in_to_h1 = nn.Linear(in_dim, hidden_dim, bias=False)\n",
    "        self.h1drop = nn.Dropout(dropout)\n",
    "        self.h1_to_out = nn.Linear(hidden_dim, out_dim, bias=False)\n",
    "\n",
    "    def forward(self, x, debug=False):\n",
    "        h1 = torch.tanh(self.in_to_h1(x))\n",
    "        drop = self.h1drop(h1)\n",
    "        out = self.h1_to_out(drop)\n",
    "\n",
    "        if debug:\n",
    "            print('in_to_h1\\n{}'.format(self.in_to_h1.weight.data))\n",
    "            print('h1\\n{}'.format(h1.data), end='\\n\\n')\n",
    "            print('dropout\\n{}'.format(drop.data), end='\\n\\n')\n",
    "            print('out\\n{}'.format(out.data), end='\\n\\n')\n",
    "        return out\n",
    "\n",
    "net = Net()\n",
    "x = torch.rand((1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네트워크의 구조를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (in_to_h1): Linear(in_features=3, out_features=10, bias=False)\n",
      "  (h1drop): Dropout(p=0.5)\n",
      "  (h1_to_out): Linear(in_features=10, out_features=2, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트에 이용할 3 차원 input vector 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4617, 0.2211, 0.0504]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "net 을 train mode 로 만듭니다. 함수를 실행하지 않아도 기본으로 train mode 입니다. 첫번째 hidden 을 거친 값은 [-1, 1] 사이의 10 차원 벡터입니다. Dropout layer 를 지나면서 일부가 0 으로 변하였습니다. 0 이 아닌 값이 h1 의 두 배가 되는 이유는 loss 의 크기를 유지하기 위하여 1 - dropout ratio 의 역수로 벡터의 크기를 키우기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_to_h1\n",
      "tensor([[ 0.4802, -0.3685, -0.1947],\n",
      "        [-0.1639,  0.1439,  0.1251],\n",
      "        [-0.3477, -0.4726, -0.4202],\n",
      "        [ 0.2857,  0.2486, -0.4135],\n",
      "        [-0.3216, -0.1887,  0.1364],\n",
      "        [ 0.3519, -0.3512, -0.4188],\n",
      "        [ 0.2502, -0.1079, -0.4374],\n",
      "        [ 0.4281, -0.5304, -0.1201],\n",
      "        [ 0.2121, -0.1702,  0.1905],\n",
      "        [ 0.4310,  0.5214, -0.1435]])\n",
      "h1\n",
      "tensor([[ 0.1296, -0.0375, -0.2786,  0.1645, -0.1813,  0.0636,  0.0695,  0.0741,\n",
      "          0.0698,  0.2978]])\n",
      "\n",
      "dropout\n",
      "tensor([[ 0.0000, -0.0751, -0.0000,  0.3290, -0.3626,  0.1272,  0.1390,  0.1483,\n",
      "          0.0000,  0.5955]])\n",
      "\n",
      "out\n",
      "tensor([[-0.1116, -0.0689]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "z = net.forward(x, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "같은 input vector 를 적용하면 10 차원의 다른 노드들이 0 으로 변합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_to_h1\n",
      "tensor([[ 0.4802, -0.3685, -0.1947],\n",
      "        [-0.1639,  0.1439,  0.1251],\n",
      "        [-0.3477, -0.4726, -0.4202],\n",
      "        [ 0.2857,  0.2486, -0.4135],\n",
      "        [-0.3216, -0.1887,  0.1364],\n",
      "        [ 0.3519, -0.3512, -0.4188],\n",
      "        [ 0.2502, -0.1079, -0.4374],\n",
      "        [ 0.4281, -0.5304, -0.1201],\n",
      "        [ 0.2121, -0.1702,  0.1905],\n",
      "        [ 0.4310,  0.5214, -0.1435]])\n",
      "h1\n",
      "tensor([[ 0.1296, -0.0375, -0.2786,  0.1645, -0.1813,  0.0636,  0.0695,  0.0741,\n",
      "          0.0698,  0.2978]])\n",
      "\n",
      "dropout\n",
      "tensor([[0.0000, -0.0000, -0.0000, 0.0000, -0.0000, 0.1272, 0.1390, 0.0000, 0.1396,\n",
      "         0.5955]])\n",
      "\n",
      "out\n",
      "tensor([[ 0.0461, -0.1098]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "z = net.forward(x, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 eval mode 에서는 hidden vector 의 모든 값이 그대로 유지됨을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_to_h1\n",
      "tensor([[ 0.4802, -0.3685, -0.1947],\n",
      "        [-0.1639,  0.1439,  0.1251],\n",
      "        [-0.3477, -0.4726, -0.4202],\n",
      "        [ 0.2857,  0.2486, -0.4135],\n",
      "        [-0.3216, -0.1887,  0.1364],\n",
      "        [ 0.3519, -0.3512, -0.4188],\n",
      "        [ 0.2502, -0.1079, -0.4374],\n",
      "        [ 0.4281, -0.5304, -0.1201],\n",
      "        [ 0.2121, -0.1702,  0.1905],\n",
      "        [ 0.4310,  0.5214, -0.1435]])\n",
      "h1\n",
      "tensor([[ 0.1296, -0.0375, -0.2786,  0.1645, -0.1813,  0.0636,  0.0695,  0.0741,\n",
      "          0.0698,  0.2978]])\n",
      "\n",
      "dropout\n",
      "tensor([[ 0.1296, -0.0375, -0.2786,  0.1645, -0.1813,  0.0636,  0.0695,  0.0741,\n",
      "          0.0698,  0.2978]])\n",
      "\n",
      "out\n",
      "tensor([[ 0.0411, -0.1151]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "z = net.forward(x, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다시 train mode 로 변환하면 몇 개 마디 값이 0 으로 변함을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_to_h1\n",
      "tensor([[ 0.4802, -0.3685, -0.1947],\n",
      "        [-0.1639,  0.1439,  0.1251],\n",
      "        [-0.3477, -0.4726, -0.4202],\n",
      "        [ 0.2857,  0.2486, -0.4135],\n",
      "        [-0.3216, -0.1887,  0.1364],\n",
      "        [ 0.3519, -0.3512, -0.4188],\n",
      "        [ 0.2502, -0.1079, -0.4374],\n",
      "        [ 0.4281, -0.5304, -0.1201],\n",
      "        [ 0.2121, -0.1702,  0.1905],\n",
      "        [ 0.4310,  0.5214, -0.1435]])\n",
      "h1\n",
      "tensor([[ 0.1296, -0.0375, -0.2786,  0.1645, -0.1813,  0.0636,  0.0695,  0.0741,\n",
      "          0.0698,  0.2978]])\n",
      "\n",
      "dropout\n",
      "tensor([[ 0.0000, -0.0000, -0.5573,  0.0000, -0.0000,  0.1272,  0.1390,  0.1483,\n",
      "          0.1396,  0.5955]])\n",
      "\n",
      "out\n",
      "tensor([[ 0.1003, -0.2834]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "z = net.forward(x, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch IO (save / load)\n",
    "\n",
    "### save whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lovit/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "model_path = 'sample_model.pt'\n",
    "torch.save(net, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_to_h1\n",
      "tensor([[ 0.4802, -0.3685, -0.1947],\n",
      "        [-0.1639,  0.1439,  0.1251],\n",
      "        [-0.3477, -0.4726, -0.4202],\n",
      "        [ 0.2857,  0.2486, -0.4135],\n",
      "        [-0.3216, -0.1887,  0.1364],\n",
      "        [ 0.3519, -0.3512, -0.4188],\n",
      "        [ 0.2502, -0.1079, -0.4374],\n",
      "        [ 0.4281, -0.5304, -0.1201],\n",
      "        [ 0.2121, -0.1702,  0.1905],\n",
      "        [ 0.4310,  0.5214, -0.1435]])\n",
      "h1\n",
      "tensor([[ 0.1296, -0.0375, -0.2786,  0.1645, -0.1813,  0.0636,  0.0695,  0.0741,\n",
      "          0.0698,  0.2978]])\n",
      "\n",
      "dropout\n",
      "tensor([[ 0.1296, -0.0375, -0.2786,  0.1645, -0.1813,  0.0636,  0.0695,  0.0741,\n",
      "          0.0698,  0.2978]])\n",
      "\n",
      "out\n",
      "tensor([[ 0.0411, -0.1151]])\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0411, -0.1151]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_net = torch.load(model_path)\n",
    "loaded_net.eval()\n",
    "loaded_net(x, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save only parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_to_h1.weight \t torch.Size([10, 3])\n",
      "h1_to_out.weight \t torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "for param_tensor in net.state_dict():\n",
    "    print(param_tensor, \"\\t\", net.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (in_to_h1): Linear(in_features=3, out_features=10, bias=False)\n",
       "  (h1drop): Dropout(p=0.5)\n",
       "  (h1_to_out): Linear(in_features=10, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'sample_model_params.pt'\n",
    "torch.save(net.state_dict(), model_path)\n",
    "\n",
    "loaded_net = Net()\n",
    "loaded_net.load_state_dict(torch.load(model_path))\n",
    "loaded_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_to_h1\n",
      "tensor([[ 0.4802, -0.3685, -0.1947],\n",
      "        [-0.1639,  0.1439,  0.1251],\n",
      "        [-0.3477, -0.4726, -0.4202],\n",
      "        [ 0.2857,  0.2486, -0.4135],\n",
      "        [-0.3216, -0.1887,  0.1364],\n",
      "        [ 0.3519, -0.3512, -0.4188],\n",
      "        [ 0.2502, -0.1079, -0.4374],\n",
      "        [ 0.4281, -0.5304, -0.1201],\n",
      "        [ 0.2121, -0.1702,  0.1905],\n",
      "        [ 0.4310,  0.5214, -0.1435]])\n",
      "h1\n",
      "tensor([[ 0.1296, -0.0375, -0.2786,  0.1645, -0.1813,  0.0636,  0.0695,  0.0741,\n",
      "          0.0698,  0.2978]])\n",
      "\n",
      "dropout\n",
      "tensor([[ 0.1296, -0.0375, -0.2786,  0.1645, -0.1813,  0.0636,  0.0695,  0.0741,\n",
      "          0.0698,  0.2978]])\n",
      "\n",
      "out\n",
      "tensor([[ 0.0411, -0.1151]])\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0411, -0.1151]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_net(x, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
