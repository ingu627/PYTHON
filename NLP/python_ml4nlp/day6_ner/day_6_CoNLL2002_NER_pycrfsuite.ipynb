{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pycrfsuite 의 NER tutorials 에 필요한 주석을 추가하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20.0\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sklearn\n",
    "import pycrfsuite\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk 에서는 대표적인 NLP competitions 의 데이터를 공개합니다. \n",
    "\n",
    "데이터 다운로드가 되지 않으면 아래 명령어를 실행시켰는데 exception 이 발생합니다.\n",
    "\n",
    "    nltk.corpus.conll2002.fileids()\n",
    "\n",
    " exception message 를 살펴보면 아래와 같은 명령어를 실행하라는 구문이 있습니다.\n",
    " \n",
    "     nltk.download('conll2002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nltk.download('conll2002')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CoNLL 2002 는 NER competitions 입니다. esp 는 스페인어 데이터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['esp.testa', 'esp.testb', 'esp.train', 'ned.testa', 'ned.testb', 'ned.train']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.conll2002.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train, test 용 데이터를 가져옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sents = list(nltk.corpus.conll2002.iob_sents('esp.train'))\n",
    "test_sents = list(nltk.corpus.conll2002.iob_sents('esp.testb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 문장은 list of tuple 로 구성되어 있으며, 각 tuple 은 (단어, 품사, NER tag) 로 구성되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Melbourne', 'NP', 'B-LOC'),\n",
       " ('(', 'Fpa', 'O'),\n",
       " ('Australia', 'NP', 'B-LOC'),\n",
       " (')', 'Fpt', 'O'),\n",
       " (',', 'Fc', 'O'),\n",
       " ('25', 'Z', 'O'),\n",
       " ('may', 'NC', 'O'),\n",
       " ('(', 'Fpa', 'O'),\n",
       " ('EFE', 'NC', 'B-ORG'),\n",
       " (')', 'Fpt', 'O'),\n",
       " ('.', 'Fp', 'O')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pycrfsuite 에서 CoNLL 2002 를 위하여 이용하는 potential functions 입니다. \n",
    "\n",
    "주석으로 처리한 부분은 우리의 실험에서는 이용하지 않을 features 입니다. 우리는 앞/뒤의 단어와 현재 단어의 끝부분 (suffix) 만을 feature 로 이용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    features = [\n",
    "        'bias',\n",
    "#        'word.lower=' + word.lower(), \n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "#         'word.isupper=%s' % word.isupper(),\n",
    "#        'word.istitle=%s' % word.istitle(),\n",
    "#        'word.isdigit=%s' % word.isdigit(),\n",
    "#        'postag=' + postag,\n",
    "#        'postag[:2]=' + postag[:2],\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    " #           '-1:word.istitle=%s' % word1.istitle(),\n",
    " #           '-1:word.isupper=%s' % word1.isupper(),\n",
    " #           '-1:postag=' + postag1,\n",
    " #           '-1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "#            '+1:word.istitle=%s' % word1.istitle(),\n",
    "#            '+1:word.isupper=%s' % word1.isupper(),\n",
    "#            '+1:postag=' + postag1,\n",
    "#            '+1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 문장의 첫 단어에 대한 feature 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bias', 'word[-3:]=rne', 'word[-2:]=ne', 'BOS', '+1:word.lower=(']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2features(train_sents[0])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습과 테스트용 x, y 를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전 띄어쓰기때와 같이 pycrfsuite.Trainer 를 만들고, 데이터를 append 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 s, sys: 12 ms, total: 1.02 s\n",
      "Wall time: 1.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters 를 설정합니다.\n",
    "\n",
    "feature.minfreq 를 추가하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True,\n",
    "    \n",
    "    # minimum frequency\n",
    "    'feature.minfreq': 5\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습을 한 뒤, 학습된 모델을 불려옵니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.49 s, sys: 0 ns, total: 9.49 s\n",
      "Wall time: 9.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train('conll2002-esp.crfsuite')\n",
    "\n",
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('conll2002-esp.crfsuite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한 문장에 대하여 NER tag prediction 을 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Coruña , 23 may ( EFECOM ) .\n",
      "\n",
      "Predicted: B-LOC, I-LOC, O, O, O, O, B-ORG, O, O\n",
      "Correct:   B-LOC, I-LOC, O, O, O, O, B-ORG, O, O\n"
     ]
    }
   ],
   "source": [
    "example_sent = test_sents[0]\n",
    "print(' '.join(sent2tokens(example_sent)), end='\\n\\n')\n",
    "\n",
    "print(\"Predicted:\", ', '.join(tagger.tag(sent2features(example_sent))))\n",
    "print(\"Correct:  \", ', '.join(sent2labels(example_sent)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CoNLL 2002 의 NER tag 는 B, I, O tagset 을 이용합니다. \n",
    "\n",
    "이를 이용하여 성능 평가를 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bio_classification_report(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Classification report for a list of BIO-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "    \n",
    "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
    "    to calculate averages properly!\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "        \n",
    "    tagset = set(lb.classes_) - {'O'}\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 184 ms, sys: 0 ns, total: 184 ms\n",
      "Wall time: 181 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = [tagger.tag(xseq) for xseq in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 표는 위의 모든 features 를 이용할 때의 성능입니다. 더욱이 minfreq=1 로 설정되었기 때문에 overfitting 일 가능성이 있으며, word[i].lower 를 feature 로 이용하면 단어를 외웠을 때의 성능입니다.\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "      B-LOC       0.78      0.75      0.76      1084\n",
    "      I-LOC       0.87      0.93      0.90       634\n",
    "     B-MISC       0.69      0.47      0.56       339\n",
    "     I-MISC       0.87      0.93      0.90       634\n",
    "      B-ORG       0.82      0.87      0.84       735\n",
    "      I-ORG       0.87      0.93      0.90       634\n",
    "      B-PER       0.61      0.49      0.54       557\n",
    "      I-PER       0.87      0.93      0.90       634\n",
    "\n",
    "    avg / total       0.81      0.81      0.80      5251\n",
    "\n",
    "우리의 설정처럼 앞/뒤의 단어만 feature 로 이용해도 어느 정도의 성능이 나옵니다. NER 에서는 앞/뒤 단어가 가장 중요한 hints 입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.69      0.49      0.58      1084\n",
      "       I-LOC       0.60      0.47      0.52       325\n",
      "      B-MISC       0.52      0.20      0.29       339\n",
      "      I-MISC       0.52      0.36      0.43       557\n",
      "       B-ORG       0.74      0.55      0.63      1400\n",
      "       I-ORG       0.71      0.52      0.60      1104\n",
      "       B-PER       0.83      0.69      0.76       735\n",
      "       I-PER       0.86      0.86      0.86       634\n",
      "\n",
      "   micro avg       0.72      0.54      0.62      6178\n",
      "   macro avg       0.68      0.52      0.58      6178\n",
      "weighted avg       0.71      0.54      0.61      6178\n",
      " samples avg       0.07      0.07      0.07      6178\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lovit/anaconda2/envs/scrapper/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lovit/anaconda2/envs/scrapper/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(bio_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 feature 의 weights 를 확인합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "debugger = tagger.info()\n",
    "weights = debugger.state_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "655\n"
     ]
    }
   ],
   "source": [
    "location_features = {feature:weight for feature, weight in weights.items() if 'LOC' in feature[1]}\n",
    "print(len(location_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "확실히 힌트는 앞 뒤, 단어와 현재 단어의 형태입니다. \n",
    "\n",
    "    ('-1:word.lower=en', 'B-LOC') : 3.543269\n",
    "\n",
    "스페인어 en 은 영어의 in 입니다. in PLACE 형태로 이용됩니다. 장소를 알아차릴 수 있는 결정적인 힌트입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('-1:word.lower=despejado', 'B-LOC') : 6.919385\n",
      "('-1:word.lower=efe-cantabria', 'B-LOC') : 6.274558\n",
      "('word[-3:]=yun', 'B-LOC') : 5.874011\n",
      "('-1:word.lower=palacio', 'I-LOC') : 5.86573\n",
      "('-1:word.lower=puente', 'I-LOC') : 5.553516\n",
      "('-1:word.lower=costa', 'I-LOC') : 5.458388\n",
      "('-1:word.lower=avenida', 'I-LOC') : 5.372484\n",
      "('word[-3:]=nón', 'B-LOC') : 5.322154\n",
      "('word[-3:]=iés', 'B-LOC') : 5.147951\n",
      "('-1:word.lower=nuboso', 'B-LOC') : 5.10912\n",
      "('word[-3:]=ael', 'B-LOC') : 4.857369\n",
      "('-1:word.lower=cantabria', 'B-LOC') : 4.785114\n",
      "('-1:word.lower=santa', 'I-LOC') : 4.763376\n",
      "('-1:word.lower=parque', 'I-LOC') : 4.587954\n",
      "('word[-3:]=kio', 'B-LOC') : 4.379538\n",
      "('+1:word.lower=cairo', 'B-LOC') : 4.342166\n",
      "('+1:word.lower=coruña', 'B-LOC') : 4.315112\n",
      "('+1:word.lower=unido', 'B-LOC') : 3.890058\n",
      "('word[-3:]=lmo', 'B-LOC') : 3.739574\n",
      "('-1:word.lower=paseo', 'I-LOC') : 3.709889\n",
      "('-1:word.lower=bulevar', 'I-LOC') : 3.681638\n",
      "('-1:word.lower=lluvioso', 'B-LOC') : 3.674013\n",
      "('word[-3:]=uay', 'B-LOC') : 3.642079\n",
      "('word[-3:]=cón', 'B-LOC') : 3.596598\n",
      "('-1:word.lower=en', 'B-LOC') : 3.543269\n",
      "('+1:word.lower=24', 'B-LOC') : 3.542004\n",
      "('-1:word.lower=hacia', 'B-LOC') : 3.536268\n",
      "('word[-3:]=ami', 'B-LOC') : 3.509685\n",
      "('+1:word.lower=salvador', 'B-LOC') : 3.479515\n",
      "('word[-3:]=jón', 'B-LOC') : 3.455784\n",
      "('word[-3:]=lén', 'B-LOC') : 3.42167\n",
      "('-1:word.lower=oriente', 'I-LOC') : 3.322408\n",
      "('word[-3:]=joz', 'B-LOC') : 3.193083\n",
      "('word[-3:]=rís', 'B-LOC') : 3.173117\n",
      "('-1:word.lower=barrio', 'I-LOC') : 3.164656\n",
      "('word[-3:]=gón', 'B-LOC') : 3.154478\n",
      "('word[-3:]=otá', 'B-LOC') : 3.150019\n",
      "('-1:word.lower=9', 'B-LOC') : 3.140451\n",
      "('word[-3:]=dua', 'B-LOC') : 3.104703\n",
      "('word[-3:]=RFA', 'B-LOC') : 3.09722\n",
      "('word[-3:]=ovo', 'B-LOC') : 3.078659\n",
      "('-1:word.lower=calle', 'I-LOC') : 3.062484\n",
      "('+1:word.lower=26', 'B-LOC') : 3.007361\n",
      "('-1:word.lower=desde', 'B-LOC') : 3.000968\n",
      "('+1:word.lower=25', 'B-LOC') : 2.997031\n",
      "('-1:word.lower=campo', 'I-LOC') : 2.987284\n",
      "('-1:word.lower=12', 'B-LOC') : 2.940425\n",
      "('word[-3:]=ney', 'B-LOC') : 2.935831\n",
      "('-1:word.lower=plaza', 'I-LOC') : 2.934359\n",
      "('word[-3:]=uta', 'B-LOC') : 2.914302\n"
     ]
    }
   ],
   "source": [
    "for feature, weight in sorted(location_features.items(), key=lambda x:-x[1])[:50]:\n",
    "    print('{} : {}'.format(feature, weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total num of words in testset = 51533\n"
     ]
    }
   ],
   "source": [
    "print('total num of words in testset = {}'.format(\n",
    "    sum((len(sent) for sent in test_sents))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
