{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 대규모 데이터 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대규모 데이터(big data)의 경우에는 메모리 등의 문제로 특정한 모형은 사용할 수 없는 경우가 많다. 이 때는 \n",
    "\n",
    "* 사전 확률분포를 설정할 수 있는 생성 모형\n",
    "* 시작 가중치를 설정할 수 있는 모형\n",
    "\n",
    "등을 이용하고 전체 데이터를 처리 가능한 작은 주각으로 나누어 학습을 시키는 점진적 학습 방법을 사용한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "covtype = fetch_covtype(shuffle=True, random_state=0)\n",
    "X_covtype = covtype.data\n",
    "y_covtype = covtype.target - 1\n",
    "classes = np.unique(y_covtype)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_covtype, y_covtype)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "def read_Xy(start, end):\n",
    "    # 실무에서는 파일이나 데이터베이스에서 읽어온다.\n",
    "    idx = list(range(start, min(len(y_train) - 1, end)))\n",
    "    X = X_train[idx, :]\n",
    "    y = y_train[idx]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "퍼셉트론 모형은 가중치를 계속 업데이트하므로 일부 데이터를 사용하여 구한 가중치를 다음 단계에서 초기 가중치로 사용할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 train acc=0.707 test acc=0.707\n",
      "epoch=1 train acc=0.710 test acc=0.710\n",
      "epoch=2 train acc=0.711 test acc=0.710\n",
      "epoch=3 train acc=0.711 test acc=0.711\n",
      "epoch=4 train acc=0.711 test acc=0.711\n",
      "epoch=5 train acc=0.711 test acc=0.711\n",
      "epoch=6 train acc=0.711 test acc=0.711\n",
      "epoch=7 train acc=0.710 test acc=0.710\n",
      "epoch=8 train acc=0.711 test acc=0.711\n",
      "epoch=9 train acc=0.711 test acc=0.711\n",
      "CPU times: user 15.2 s, sys: 330 ms, total: 15.6 s\n",
      "Wall time: 9.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = SGDClassifier(random_state=0)\n",
    "n_split = 10\n",
    "n_X = len(y_train) // n_split\n",
    "n_epoch = 10\n",
    "for epoch in range(n_epoch):\n",
    "    for n in range(n_split):\n",
    "        X, y = read_Xy(n * n_X, (n + 1) * n_X)\n",
    "        model.partial_fit(X, y, classes=classes)\n",
    "    accuracy_train = accuracy_score(y_train, model.predict(X_train))\n",
    "    accuracy_test = accuracy_score(y_test, model.predict(X_test))\n",
    "    print(\"epoch={:d} train acc={:5.3f} test acc={:5.3f}\".format(epoch, accuracy_train, accuracy_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 나이브베이즈 모형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "나이브베이즈 모형과 같은 생성모형은 일부 데이터를 이용하여 구한 확률분포를 사전확률분포로 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=0 train accuracy=0.630 test accuracy=0.628\n",
      "n=1 train accuracy=0.630 test accuracy=0.629\n",
      "n=2 train accuracy=0.632 test accuracy=0.630\n",
      "n=3 train accuracy=0.633 test accuracy=0.632\n",
      "n=4 train accuracy=0.633 test accuracy=0.631\n",
      "n=5 train accuracy=0.632 test accuracy=0.631\n",
      "n=6 train accuracy=0.632 test accuracy=0.631\n",
      "n=7 train accuracy=0.632 test accuracy=0.630\n",
      "n=8 train accuracy=0.632 test accuracy=0.630\n",
      "n=9 train accuracy=0.632 test accuracy=0.630\n",
      "CPU times: user 10.1 s, sys: 920 ms, total: 11 s\n",
      "Wall time: 2.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = BernoulliNB(alpha=0.1)\n",
    "\n",
    "n_split = 10\n",
    "n_X = len(y_train) // n_split\n",
    "for n in range(n_split):\n",
    "    X, y = read_Xy(n * n_X, (n + 1) * n_X)\n",
    "    model.partial_fit(X, y, classes=classes)\n",
    "    accuracy_train = accuracy_score(y_train, model.predict(X_train))\n",
    "    accuracy_test = accuracy_score(y_test, model.predict(X_test)) \n",
    "    print(\"n={:d} train accuracy={:5.3f} test accuracy={:5.3f}\".format(n, accuracy_train, accuracy_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그레디언트 부스팅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그레디언트 부스팅에서는 초기 커미티 멤버로 일부 데이터를 사용하여 학습한 모형을 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=0 train accuracy=0.769 test accuracy=0.767\n",
      "n=1 train accuracy=0.792 test accuracy=0.788\n",
      "n=2 train accuracy=0.806 test accuracy=0.802\n",
      "n=3 train accuracy=0.816 test accuracy=0.812\n",
      "n=4 train accuracy=0.812 test accuracy=0.807\n",
      "n=5 train accuracy=0.808 test accuracy=0.804\n",
      "n=6 train accuracy=0.805 test accuracy=0.800\n",
      "n=7 train accuracy=0.793 test accuracy=0.788\n",
      "n=8 train accuracy=0.795 test accuracy=0.790\n",
      "n=9 train accuracy=0.794 test accuracy=0.789\n",
      "CPU times: user 3min 17s, sys: 3.59 s, total: 3min 20s\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from lightgbm import train, Dataset\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    \"num_class\": len(classes),\n",
    "    'learning_rate': 0.2,\n",
    "    'seed': 0,\n",
    "}\n",
    "\n",
    "n_split = 10\n",
    "n_X = len(y_train) // n_split\n",
    "num_tree = 10\n",
    "model = None\n",
    "for n in range(n_split):\n",
    "    X, y = read_Xy(n * n_X, (n + 1) * n_X)\n",
    "    model = train(params, init_model=model, train_set=Dataset(X, y),\n",
    "                  keep_training_booster=False, num_boost_round=num_tree)\n",
    "    accuracy_train = accuracy_score(y_train, np.argmax(model.predict(X_train), axis=1))\n",
    "    accuracy_test = accuracy_score(y_test, np.argmax(model.predict(X_test), axis=1)) \n",
    "    print(\"n={:d} train accuracy={:5.3f} test accuracy={:5.3f}\".format(n, accuracy_train, accuracy_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "랜덤 포레스트와 같은 앙상블 모형에서는 일부 데이터를 사용한 모형을 개별 분류기로 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 train accuracy=0.868 test accuracy=0.855\n",
      "epoch=1 train accuracy=0.892 test accuracy=0.874\n",
      "epoch=2 train accuracy=0.898 test accuracy=0.880\n",
      "epoch=3 train accuracy=0.902 test accuracy=0.884\n",
      "epoch=4 train accuracy=0.904 test accuracy=0.885\n",
      "epoch=5 train accuracy=0.906 test accuracy=0.886\n",
      "epoch=6 train accuracy=0.906 test accuracy=0.887\n",
      "epoch=7 train accuracy=0.907 test accuracy=0.887\n",
      "epoch=8 train accuracy=0.907 test accuracy=0.888\n",
      "epoch=9 train accuracy=0.907 test accuracy=0.888\n",
      "CPU times: user 4min 46s, sys: 11.4 s, total: 4min 57s\n",
      "Wall time: 1min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "n_split = 10\n",
    "n_X = len(y_train) // n_split\n",
    "num_tree_ini = 10\n",
    "num_tree_step = 10\n",
    "model = RandomForestClassifier(n_estimators=num_tree_ini, warm_start=True)\n",
    "for n in range(n_split):\n",
    "    X, y = read_Xy(n * n_X, (n + 1) * n_X)\n",
    "    model.fit(X, y)\n",
    "    accuracy_train = accuracy_score(y_train, model.predict(X_train))\n",
    "    accuracy_test = accuracy_score(y_test, model.predict(X_test))\n",
    "    print(\"epoch={:d} train accuracy={:5.3f} test accuracy={:5.3f}\".format(n, accuracy_train, accuracy_test))\n",
    "    \n",
    "    model.n_estimators += num_tree_step"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
