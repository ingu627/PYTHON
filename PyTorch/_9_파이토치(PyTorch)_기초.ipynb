{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9Xx-jP92OgP"
      },
      "source": [
        "# 파이토치(PyTorch)\n",
        "\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbuUgoV%2FbtqwWZvcHHX%2Fd6XzIFBEfiuFb0UvyV4A50%2Fimg.jpg\" width=\"300\">\n",
        "\n",
        "- 코드 출처: https://pytorch.org/tutorials/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cxreguz2sL0"
      },
      "source": [
        "## 파이토치의 구성요소\n",
        "\n",
        "- `torch`: 텐서를 생성하는 라이브러리\n",
        "\n",
        "- `torch.autograd`: 자동미분 기능을 제공하는 라이브러리\n",
        "\n",
        "- `torch.nn`: 신경망을 생성하는 라이브러리\n",
        "\n",
        "- `torch.multiprocessing`: 병럴처리 기능을 제공하는 라이브러리\n",
        "\n",
        "- `torch.utils`: 데이터 조작 등 유틸리티 기능 제공\n",
        "\n",
        "- `torch.legacy`(./nn/.optim): Torch로부터 포팅해온 코드\n",
        "\n",
        "- `torch.onnx`: ONNX(Open Neural Network Exchange)\n",
        "\n",
        "  - 서로 다른 프레임워크 간의 모델을 공유할 때 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb5O_aSvtHvb"
      },
      "source": [
        "## 텐서(Tensors)\n",
        "- 넘파이(NumPy)의 ndarray와 유사\n",
        "\n",
        "- GPU를 사용한 연산 가속도 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CmKIvnx0s8G6"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "49IHV-qJE5FI"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'1.9.1'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isUHVy-gtZeT"
      },
      "source": [
        "### 초기화 되지 않은 행렬 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3PqY3cZatU0D"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 7.8473e-44],\n",
            "        [3.3828e+21, 2.0798e+20]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.empty(4, 2)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPCIJ2pNteZv"
      },
      "source": [
        "### 무작위로 초기화된 행렬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "h6oPj2Q9tdYx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.7388, 0.5230],\n",
            "        [0.4597, 0.4458],\n",
            "        [0.2232, 0.8040],\n",
            "        [0.1677, 0.4414]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.rand(4, 2)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5aHphIHtiJk"
      },
      "source": [
        "### dtype이 long, 0으로 채워진 텐서"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4zykN8aMthXk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0, 0],\n",
            "        [0, 0],\n",
            "        [0, 0],\n",
            "        [0, 0]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.zeros(4, 2, dtype=torch.long)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W4VL8C_ctu8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([3.0000, 2.3000])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([3, 2.3])\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4RmVBVtIt46M"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "x = x.new_ones(2, 4, dtype=torch.double)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xxskTUfGuPUe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-1.4862, -1.3421, -1.1774,  0.6146],\n",
            "        [-0.6974, -0.8834,  1.4828,  0.1746]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn_like(x, dtype=torch.float) # x라는 shape을 그대로 가져와서\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7j5sGxGvucpH"
      },
      "source": [
        "### 텐서의 크기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "yy-JbqKEuYIR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 4])\n"
          ]
        }
      ],
      "source": [
        "print(x.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehOg0eDwufru"
      },
      "source": [
        "## 텐서의 연산(operations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8Doc_37uh3G"
      },
      "source": [
        "### 덧셈 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Rw4JCYkYuef9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-1.4862, -1.3421, -1.1774,  0.6146],\n",
            "        [-0.6974, -0.8834,  1.4828,  0.1746]])\n"
          ]
        }
      ],
      "source": [
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Wa44ur1Nuj5U"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.4856, 0.9806, 0.9667, 0.9494],\n",
            "        [0.5282, 0.3311, 0.4714, 0.3294]])\n",
            "tensor([[-1.0006, -0.3615, -0.2107,  1.5640],\n",
            "        [-0.1692, -0.5522,  1.9543,  0.5040]])\n"
          ]
        }
      ],
      "source": [
        "y = torch.rand(2, 4)\n",
        "print(y)\n",
        "print(x + y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5gcOo-Ouo9B"
      },
      "source": [
        "### 덧셈2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Qx-NzJhhumZx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-1.0006, -0.3615, -0.2107,  1.5640],\n",
            "        [-0.1692, -0.5522,  1.9543,  0.5040]])\n"
          ]
        }
      ],
      "source": [
        "print(torch.add(x, y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlvrQhLuuuIr"
      },
      "source": [
        "### 덧셈3\n",
        "- 결과 텐서를 인자로 제공"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lUsLAOTcur1-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-1.0006, -0.3615, -0.2107,  1.5640],\n",
            "        [-0.1692, -0.5522,  1.9543,  0.5040]])\n"
          ]
        }
      ],
      "source": [
        "result = torch.empty(2, 4)\n",
        "torch.add(x, y, out=result) # 결과값을 result로 뺄 수 있다.\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6BdyZFSu2Ei"
      },
      "source": [
        "### 덧셈4\n",
        "- `in-place` 방식\n",
        "\n",
        "- (참고) in-place 방식\n",
        "  - in-place방식으로 텐서의 값을 변경하는 연산 뒤에는 _''가 붙음\n",
        "  - `x.copy_(y), x.t_()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "lu8rR4WVu0wQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-1.4862, -1.3421, -1.1774,  0.6146],\n",
            "        [-0.6974, -0.8834,  1.4828,  0.1746]])\n",
            "tensor([[0.4856, 0.9806, 0.9667, 0.9494],\n",
            "        [0.5282, 0.3311, 0.4714, 0.3294]])\n",
            "tensor([[-1.0006, -0.3615, -0.2107,  1.5640],\n",
            "        [-0.1692, -0.5522,  1.9543,  0.5040]])\n"
          ]
        }
      ],
      "source": [
        "print(x)\n",
        "print(y)\n",
        "y.add_(x) # y+=x\n",
        "print(y) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo8nsrGjOw6W"
      },
      "source": [
        "### 그 외의 연산\n",
        "- `torch.sub` : 뺄셈\n",
        "\n",
        "- `torch.mul` : 곱셉\n",
        "\n",
        "- `torch.div` : 나눗셈\n",
        "\n",
        "- `torch.mm` : 내적(dot product)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "S51kxzPTO1ER"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-1., -1.],\n",
            "        [-1., -1.]])\n",
            "tensor([[-1., -1.],\n",
            "        [-1., -1.]])\n",
            "tensor([[-1., -1.],\n",
            "        [-1., -1.]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.Tensor(\n",
        "    [[1, 3],\n",
        "    [5,7]])\n",
        "y = torch.Tensor(\n",
        "    [[2, 4],\n",
        "    [6,8]])\n",
        "\n",
        "print(x - y)\n",
        "print(torch.sub(x, y))\n",
        "print(x.sub(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ou0dY8mkPR24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 2., 12.],\n",
            "        [30., 56.]])\n",
            "tensor([[ 2., 12.],\n",
            "        [30., 56.]])\n",
            "tensor([[ 2., 12.],\n",
            "        [30., 56.]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.Tensor(\n",
        "    [[1, 3],\n",
        "    [5,7]])\n",
        "y = torch.Tensor(\n",
        "    [[2, 4],\n",
        "    [6,8]])\n",
        "\n",
        "print(x * y)\n",
        "print(torch.mul(x, y))\n",
        "print(x.mul(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "6RlZZBp3PbE4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.5000, 0.7500],\n",
            "        [0.8333, 0.8750]])\n",
            "tensor([[0.5000, 0.7500],\n",
            "        [0.8333, 0.8750]])\n",
            "tensor([[0.5000, 0.7500],\n",
            "        [0.8333, 0.8750]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.Tensor(\n",
        "    [[1, 3],\n",
        "    [5,7]])\n",
        "y = torch.Tensor(\n",
        "    [[2, 4],\n",
        "    [6,8]])\n",
        "\n",
        "print(x / y)\n",
        "print(torch.div(x, y))\n",
        "print(x.div(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7MR-ofE5P7VC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[20., 28.],\n",
            "        [52., 76.]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.Tensor(\n",
        "    [[1, 3],\n",
        "    [5,7]])\n",
        "y = torch.Tensor(\n",
        "    [[2, 4],\n",
        "    [6,8]])\n",
        "\n",
        "print(torch.mm(x, y)) #matrix muliply = 행렬 곱"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8URGwHE_NjDi"
      },
      "source": [
        "## 텐서의 조작(manipulations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCsdZIPTvG53"
      },
      "source": [
        "### 인덱싱\n",
        "- 넘파이처럼 인덱싱 사용가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "jF2DE8kzvOs3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 3.],\n",
            "        [5., 7.]])\n"
          ]
        }
      ],
      "source": [
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "GQtBH3r3u7c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([3., 7.])\n"
          ]
        }
      ],
      "source": [
        "print(x[:, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEscXddKvQ5l"
      },
      "source": [
        "### view\n",
        "- 텐서의 크기(size)나 모양(shape)을 변경"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "xwhWeqhLvKKj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.6969, -1.6245,  0.3492,  1.1271,  0.3968],\n",
            "        [-0.3692,  0.6942,  1.7492,  0.5376, -1.6478],\n",
            "        [-0.1043, -0.3768, -0.5384,  0.3515, -0.7586],\n",
            "        [-1.4581,  0.7731,  2.3177,  1.2412, -0.1327]])\n",
            "tensor([-0.6969, -1.6245,  0.3492,  1.1271,  0.3968, -0.3692,  0.6942,  1.7492,\n",
            "         0.5376, -1.6478, -0.1043, -0.3768, -0.5384,  0.3515, -0.7586, -1.4581,\n",
            "         0.7731,  2.3177,  1.2412, -0.1327])\n",
            "tensor([[-0.6969, -1.6245,  0.3492,  1.1271],\n",
            "        [ 0.3968, -0.3692,  0.6942,  1.7492],\n",
            "        [ 0.5376, -1.6478, -0.1043, -0.3768],\n",
            "        [-0.5384,  0.3515, -0.7586, -1.4581],\n",
            "        [ 0.7731,  2.3177,  1.2412, -0.1327]])\n",
            "torch.Size([4, 5])\n",
            "torch.Size([20])\n",
            "torch.Size([5, 4])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(4, 5)\n",
        "y = x.view(20)\n",
        "z = x.view(5, -1)\n",
        "\n",
        "print(x)\n",
        "print(y) # 1차원 형태\n",
        "print(z) # -1은 자동으로 계산\n",
        "\n",
        "print(x.size())\n",
        "print(y.size())\n",
        "print(z.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBY_wuIRvf5j"
      },
      "source": [
        "### item\n",
        "- 텐서에 값이 단 하나라도 존재하면 숫자값을 얻을 수 있음\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "E0W24QqpvcmV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-0.6066])\n",
            "-0.6065935492515564\n",
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(1)\n",
        "print(x)\n",
        "print(x.item()) # item : 실제 안에 존재하는 값 \n",
        "print(x.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1sCUVwC3Nua"
      },
      "source": [
        "- 스칼라값 하나만 존재해야함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "jl4_FAgd3Lt9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-0.3643,  0.2732])\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "only one element tensors can be converted to Python scalars",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11236/4147517315.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
          ]
        }
      ],
      "source": [
        "# x = torch.randn(2)\n",
        "# print(x)\n",
        "# print(x.item()) # value error가 뜬다.\n",
        "# print(x.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uThndsy5M6wM"
      },
      "source": [
        "### squeeze \n",
        "- 차원을 축소(제거)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "OF3rOavnRxgM"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor = torch.rand(1, 3, 3)\n",
        "tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Y2jq0jHJR5Jw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.4969, 0.8329, 0.4914],\n",
            "        [0.8732, 0.2870, 0.2386],\n",
            "        [0.8530, 0.9249, 0.8019]])\n",
            "torch.Size([3, 3])\n"
          ]
        }
      ],
      "source": [
        "t = tensor.squeeze()\n",
        "\n",
        "print(t)\n",
        "print(t.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COv-dnTYNJ8Z"
      },
      "source": [
        "### unsqueeze\n",
        "- 차원을 증가(생성)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "PFxaHGY1NOBo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[0.0750, 0.5935, 0.7569],\n",
            "         [0.4388, 0.5325, 0.5615],\n",
            "         [0.0501, 0.2786, 0.4675]]])\n",
            "torch.Size([1, 3, 3])\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.rand(1, 3, 3)\n",
        "print(tensor)\n",
        "print(tensor.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "b6sa4tJ7SA8G"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[[0.0750, 0.5935, 0.7569],\n",
            "          [0.4388, 0.5325, 0.5615],\n",
            "          [0.0501, 0.2786, 0.4675]]]])\n",
            "torch.Size([1, 1, 3, 3])\n"
          ]
        }
      ],
      "source": [
        "t = tensor.unsqueeze(dim=0) # 차원이 오히려 증가\n",
        "\n",
        "print(t)\n",
        "print(t.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C_oa9JANOa6"
      },
      "source": [
        "### stack\n",
        "- 텐서간 결합"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "f3x_XaUYNOuc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 4.],\n",
            "        [2., 5.],\n",
            "        [3., 6.]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.FloatTensor([1, 4])\n",
        "y = torch.FloatTensor([2, 5])\n",
        "z = torch.FloatTensor([3, 6])\n",
        "\n",
        "print(torch.stack([x, y, z])) # stack = 쌓는다\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmJscbfg35-c"
      },
      "source": [
        "### cat\n",
        "- 텐서를 결합하는 메소드(concatenate)\n",
        "\n",
        "- 넘파이의 `stack`과 유사하지만, 쌓을 dim이 존재해야함\n",
        "  - 예를 들어, 해당 차원을 늘려준 후 결합\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Mv3zlaNm37P1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a :  tensor([[[[-1.1836,  0.0092,  0.7193],\n",
            "          [ 1.1564,  0.1212, -0.3557],\n",
            "          [ 1.2340,  1.6694,  0.8006]]]])\n",
            "b :  tensor([[[[ 2.0300,  0.9320, -0.0976],\n",
            "          [ 1.9815,  0.7354, -0.8266],\n",
            "          [-0.1027,  1.2076,  0.0698]]]])\n",
            "tensor([[[[-1.1836,  0.0092,  0.7193],\n",
            "          [ 1.1564,  0.1212, -0.3557],\n",
            "          [ 1.2340,  1.6694,  0.8006]]],\n",
            "\n",
            "\n",
            "        [[[ 2.0300,  0.9320, -0.0976],\n",
            "          [ 1.9815,  0.7354, -0.8266],\n",
            "          [-0.1027,  1.2076,  0.0698]]]])\n",
            "torch.Size([2, 1, 3, 3])\n"
          ]
        }
      ],
      "source": [
        "a = torch.randn(1, 1, 3, 3)\n",
        "b = torch.randn(1, 1, 3, 3)\n",
        "c = torch.cat((a, b), dim=0)\n",
        "\n",
        "print('a : ', a)\n",
        "print('b : ', b)\n",
        "print(c)\n",
        "print(c.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "69M5jY60S7Mi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a :  tensor([[[ 0.7126,  0.5637,  1.4222],\n",
            "         [-0.5656, -0.7211,  0.3971],\n",
            "         [-0.5972,  0.0381, -2.2858]]])\n",
            "b :  tensor([[[ 0.6700, -0.8062,  0.6849],\n",
            "         [ 0.5044, -0.1445, -0.1194],\n",
            "         [ 0.0154, -0.6785, -0.6289]]])\n",
            "tensor([[[ 0.7126,  0.5637,  1.4222],\n",
            "         [-0.5656, -0.7211,  0.3971],\n",
            "         [-0.5972,  0.0381, -2.2858],\n",
            "         [ 0.6700, -0.8062,  0.6849],\n",
            "         [ 0.5044, -0.1445, -0.1194],\n",
            "         [ 0.0154, -0.6785, -0.6289]]])\n",
            "torch.Size([1, 6, 3])\n"
          ]
        }
      ],
      "source": [
        "a = torch.randn(1, 3, 3)\n",
        "b = torch.randn(1, 3, 3)\n",
        "c = torch.cat((a, b), dim=1) # 차원을 지정해준다. 1단위로 \n",
        "# 내가 cat하고자 하는 dim 지정\n",
        "\n",
        "print('a : ', a)\n",
        "print('b : ', b)\n",
        "print(c)\n",
        "print(c.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gGXnOAqQTmG"
      },
      "source": [
        "### chuck\n",
        "- 텐서를 여러 개로 나눌 때 사용\n",
        "\n",
        "- 몇 개의 텐서로 나눌 것이냐"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "pNV80VzPQZgG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.3538, 0.0405, 0.9346, 0.8562, 0.1822, 0.0013],\n",
            "        [0.6756, 0.2766, 0.4767, 0.8419, 0.4189, 0.5001],\n",
            "        [0.0378, 0.1759, 0.4003, 0.5231, 0.2567, 0.3970]])\n",
            "tensor([[0.3538, 0.0405],\n",
            "        [0.6756, 0.2766],\n",
            "        [0.0378, 0.1759]])\n",
            "tensor([[0.9346, 0.8562],\n",
            "        [0.4767, 0.8419],\n",
            "        [0.4003, 0.5231]])\n",
            "tensor([[0.1822, 0.0013],\n",
            "        [0.4189, 0.5001],\n",
            "        [0.2567, 0.3970]])\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.rand(3, 6)\n",
        "t1, t2, t3 = torch.chunk(tensor, 3, dim=1) # tensor를 3으로 묶음 dim=1로\n",
        "\n",
        "print(tensor)\n",
        "print(t1)\n",
        "print(t2)\n",
        "print(t3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U0Qb0jWQgm-"
      },
      "source": [
        "### split\n",
        "- `chunck`와 동일한 기능이지만 조금 다름\n",
        "\n",
        "- 하나의 텐서당 크기가 얼마이냐"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "1V6DDnLVQqxz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.4239, 0.5405, 0.1660, 0.1185, 0.1737, 0.4505],\n",
            "        [0.2128, 0.1640, 0.5203, 0.2921, 0.9682, 0.5209],\n",
            "        [0.9468, 0.5017, 0.6463, 0.4637, 0.1088, 0.0976]])\n",
            "tensor([[0.4239, 0.5405, 0.1660],\n",
            "        [0.2128, 0.1640, 0.5203],\n",
            "        [0.9468, 0.5017, 0.6463]])\n",
            "tensor([[0.1185, 0.1737, 0.4505],\n",
            "        [0.2921, 0.9682, 0.5209],\n",
            "        [0.4637, 0.1088, 0.0976]])\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.rand(3, 6)\n",
        "t1, t2 = torch.split(tensor, 3, dim=1) # 3 = 크기 지정\n",
        "\n",
        "print(tensor)\n",
        "print(t1)\n",
        "print(t2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "estSwhCgvta6"
      },
      "source": [
        "### torch ↔ numpy\n",
        "- Torch Tensor(텐서)를 Numpy array(배열)로 변환 가능\n",
        "\n",
        "  - `numpy()`\n",
        "  - `from_numpy()`\n",
        "\n",
        "- (참고)\n",
        "  - Tensor가 CPU상에 있다면 Numpy 배열은 메모리 공간을 공유하므로 하나가 변하면, 다른 하나도 변함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "VxHI7c_yvmAT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1.])\n"
          ]
        }
      ],
      "source": [
        "a = torch.ones(7) # 하나로 채우는 것 7개\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "whbrhokHwJ3A"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1. 1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "b = a.numpy()\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "5StIhUWDwQjA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2., 2., 2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2. 2. 2.]\n"
          ]
        }
      ],
      "source": [
        "a.add_(1) # a에 1을 모두 더함\n",
        "print(a)\n",
        "print(b) # tensor가 cpu상에 있기 때문에 메모리 공유"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "3RNS5-cRwTt8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2. 2. 2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "a = np.ones(7)\n",
        "b = torch.from_numpy(a)\n",
        "np.add(a, 1, out=a)\n",
        "print(a)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-ZaxSvLxEej"
      },
      "source": [
        "## CUDA Tensors\n",
        "- `.to` 메소드를 사용하여 텐서를 어떠한 장치로도 옮길 수 있음\n",
        "  - 예) cpu, gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "xkaQznCRxpUj"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "SCnC0x2Rxpbk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-1.2078])\n",
            "-1.2078262567520142\n",
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(1)\n",
        "print(x)\n",
        "print(x.item()) # item = 실제값\n",
        "print(x.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "GcSsFLkDw-nI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n",
            "tensor([-0.2078], device='cuda:0')\n",
            "tensor([-0.2078], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# 만약 gpu환경이 아니면 cpu 선택\n",
        "y = torch.ones_like(x, device=device) # 직접 gpu상에서 tensor 만들어보겠다\n",
        "x = x.to(device) # x자체를 gpu환경으로 옮기겠다\n",
        "z = x + y\n",
        "print(device)\n",
        "print(z)\n",
        "print(z.to('cpu', torch.double))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKqiGvLWx2nk"
      },
      "source": [
        "## AUTOGRAD (자동미분)\n",
        "- autograd 패키지는 Tensor의 모든 연산에 대해 **자동 미분** 제공\n",
        "\n",
        "- 이는 코드를 어떻게 작성하여 실행하느냐에 따라 역전파가 정의된다는 뜻\n",
        "\n",
        "- backprop를 위한 미분값을 자동으로 계산"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zH41l-MyMHi"
      },
      "source": [
        "### Tensor\n",
        "\n",
        "- data: tensor형태의 데이터\n",
        "\n",
        "- grad: data가 겨쳐온 layer에 대한 미분값 저장\n",
        "\n",
        "- grad_fn: 미분값을 계산한 함수에 대한 정보 저장 (어떤 함수에 대해서 backprop 했는지)\n",
        "\n",
        "- `requires_grad` 속성을 `True`로 설정하면, 해당 텐서에서 이루어지는 모든 연산들을 추적하기 시작\n",
        "\n",
        "- 계산이 완료된 후, `.backward()`를 호출하면 자동으로 `gradient`를 계산할 수 있으며, `.grad` 속성에 누적됨\n",
        "\n",
        "- 기록을 추적하는 것을 중단하게 하려면, `.detach()`를 호출하여 연산기록으로부터 분리\n",
        "\n",
        "- 기록을 추적하는 것을 방지하기 위해 코드 블럭을 `with torch.no_grad():`로 감싸면 `gradient`는 필요없지만, `requires_grad=True`로 설정되어 학습 가능한 매개변수를 갖는 모델을 평가(evaluate)할 때 유용\n",
        "\n",
        "- Autograd 구현에서 매우 중요한 클래스 : `Function` 클래스"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "ipdk_1jfx47I"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "ljNU-r9p0Rpo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "x = torch.ones(3, 3, requires_grad=True)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "or6sQ4EB0UYz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[6., 6., 6.],\n",
            "        [6., 6., 6.],\n",
            "        [6., 6., 6.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "y = x + 5\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "PuQ7xDmu0Wpj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<AddBackward0 object at 0x000002A3F9C8E688>\n"
          ]
        }
      ],
      "source": [
        "print(y.grad_fn) # +5 연산에 대해서 backward 할 수 있는 연산이 붙음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "6_2iM-Zq0ZdG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[72., 72., 72.],\n",
            "        [72., 72., 72.],\n",
            "        [72., 72., 72.]], grad_fn=<MulBackward0>) tensor(72., grad_fn=<MeanBackward0>)\n"
          ]
        }
      ],
      "source": [
        "z = y * y * 2\n",
        "out = z.mean()\n",
        "# MulBackward0 : 곱에 대한 backward가 붙음\n",
        "\n",
        "print(z, out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aZ8SWn_0nqt"
      },
      "source": [
        "- `requires_grad_(...)`는 기존 텐서의 `requires_grad`값을 바꿔치기(`in-place`)하여 변경"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "mHGROgrM0ebO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n",
            "<SumBackward0 object at 0x000002A3F9BAE988>\n"
          ]
        }
      ],
      "source": [
        "a = torch.randn(3, 3)\n",
        "a = ((a * 3) / (a - 1))\n",
        "print(a.requires_grad) # False 상태\n",
        "\n",
        "a.requires_grad_(True) # True 상태\n",
        "print(a.requires_grad)\n",
        "\n",
        "b = (a * a).sum()\n",
        "print(b.grad_fn) # sumbackward가 붙음"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiEn_stZ1VgU"
      },
      "source": [
        "### 기울기(Gradient)\n",
        "- 역전파: `.backward()`를 통해 역전파 계산 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "1tdoN9p-1kn4"
      },
      "outputs": [],
      "source": [
        "out.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "CixGTXbV1B9p"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[2.6667, 2.6667, 2.6667],\n",
            "        [2.6667, 2.6667, 2.6667],\n",
            "        [2.6667, 2.6667, 2.6667]])\n"
          ]
        }
      ],
      "source": [
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "SY63Mcc-1iNI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-1496.9336,   574.8242,  -963.9843], grad_fn=<MulBackward0>)\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y = x * 2\n",
        "while y.data.norm() < 1000: # norm : 현재값이\n",
        "    y = y * 2\n",
        "\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "YPaVAbIT3gx_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2.0480e+02, 2.0480e+03, 2.0480e-01])\n"
          ]
        }
      ],
      "source": [
        "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
        "y.backward(v)\n",
        "\n",
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b9amArPXtcX"
      },
      "source": [
        "- `with torch.no_grad()`를 사용하여 gradient의 업데이트를 하지 않음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "weeIe5_Z3jVe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "print(x.requires_grad)\n",
        "print((x**2).requires_grad)\n",
        "\n",
        "with torch.no_grad(): # ~~ 옵션을 붙인 상태에서\n",
        "    print((x**2).requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLcTLVRSmCdH"
      },
      "source": [
        "- `detach()`: 내용물(content)은 같지만 require_grad가 다른 새로운 Tensor를 가져올 때"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "ALcth7Ew3l7H"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "False\n",
            "tensor(True)\n"
          ]
        }
      ],
      "source": [
        "print(x.requires_grad)\n",
        "y = x.detach()\n",
        "print(y.requires_grad)\n",
        "print(x.eq(y).all())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSarysrqBh9D"
      },
      "source": [
        "### 자동 미분 흐름 다시 보기(1)\n",
        "- 계산 흐름  \n",
        "  $a \\rightarrow b  \\rightarrow c  \\rightarrow out $\n",
        "\n",
        "<br>\n",
        "\n",
        "## $\\quad \\frac{\\partial out}{\\partial a} = ?$\n",
        "- `backward()`를 통해  \n",
        "  $a \\leftarrow b  \\leftarrow c  \\leftarrow out $을 계산하면  \n",
        "    $\\frac{\\partial out}{\\partial a}$값이 `a.grad`에 채워짐\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "NUAc1etP3oBc"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "tCW7dq9uB89T"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "a = torch.ones(2, 2)\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "-AyyGy49FLz9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "a = torch.ones(2, 2, requires_grad=True)\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "SmmJa-hvFPGH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a.data:  tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "a.grad tensor([[6., 6.],\n",
            "        [6., 6.]])\n",
            "a.grad_fn None\n"
          ]
        }
      ],
      "source": [
        "print('a.data: ', a.data)\n",
        "print('a.grad', a.grad)\n",
        "print('a.grad_fn', a.grad_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCwhTsiHGCmG"
      },
      "source": [
        "- $b = a + 2$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "iUPt042iF9V1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "b = a +2\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cw2zoq9GHLF"
      },
      "source": [
        "- $c = b^2$ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "FRDS6gP0GFZG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[9., 9.],\n",
            "        [9., 9.]], grad_fn=<PowBackward0>)\n"
          ]
        }
      ],
      "source": [
        "c = b**2\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "VynoiUywGSwh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(36., grad_fn=<SumBackward0>)\n"
          ]
        }
      ],
      "source": [
        "out = c.sum()\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "v3ryJon9GeMn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(36., grad_fn=<SumBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(out)\n",
        "out.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0aoNsPDHsoG"
      },
      "source": [
        "- a의 `grad_fn`이 None인 이유  \n",
        "  직접적으로 계산한 부분이 없었기 때문"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "bccI4vIWGgqj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a.data:  tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n",
            "a.grad tensor([[6., 6.],\n",
            "        [6., 6.]])\n",
            "a.grad_fn None\n"
          ]
        }
      ],
      "source": [
        "print('a.data: ', a)\n",
        "print('a.grad', a.grad)\n",
        "print('a.grad_fn', a.grad_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "oka1mkadHq-N"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b.data:  tensor([[3., 3.],\n",
            "        [3., 3.]])\n",
            "b.grad None\n",
            "b.grad_fn <AddBackward0 object at 0x000002A3F9C95F88>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\poeun\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more information.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "print('b.data: ', b.data)\n",
        "print('b.grad', b.grad)\n",
        "print('b.grad_fn', b.grad_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "ZiYNajdLccUF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c.data:  tensor([[9., 9.],\n",
            "        [9., 9.]])\n",
            "c.grad None\n",
            "c.grad_fn <PowBackward0 object at 0x000002A3F9CAE6C8>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\poeun\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more information.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "print('c.data: ', c.data)\n",
        "print('c.grad', c.grad)\n",
        "print('c.grad_fn', c.grad_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "BcLoMYite0vU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "out.data:  tensor(36.)\n",
            "out.grad None\n",
            "out.grad_fn <SumBackward0 object at 0x000002A3F9BD8848>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\poeun\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more information.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "print('out.data: ', out.data)\n",
        "print('out.grad', out.grad)\n",
        "print('out.grad_fn', out.grad_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZXgwviHfovj"
      },
      "source": [
        "### 자동 미분 흐름 다시 보기(2)\n",
        "- `grad`값을 넣어서 `backward`\n",
        "\n",
        "- 아래의 코드에서 `.grad`값이 None은 gradient값이 필요하지 않기 때문"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "bB6DCYXRfcI_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6., grad_fn=<SumBackward0>)\n"
          ]
        }
      ],
      "source": [
        "x = torch.ones(3, requires_grad=True)\n",
        "y = (x**2)\n",
        "z = y ** 2 + x\n",
        "out = z.sum()\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "AVo-glm8fvFv"
      },
      "outputs": [],
      "source": [
        "grad = torch.Tensor([0.1, 1, 100])\n",
        "z.backward(grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "tdBklrepf2qq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x.data:  tensor([1., 1., 1.])\n",
            "x.grad tensor([  0.5000,   5.0000, 500.0000])\n",
            "x.grad_fn None\n"
          ]
        }
      ],
      "source": [
        "print('x.data: ', x.data)\n",
        "print('x.grad', x.grad)\n",
        "print('x.grad_fn', x.grad_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "HQvUGlfRf7jU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y.data:  tensor([1., 1., 1.])\n",
            "y.grad None\n",
            "y.grad_fn <PowBackward0 object at 0x000002A3D3CDBA08>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\poeun\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more information.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "print('y.data: ', y.data)\n",
        "print('y.grad', y.grad)\n",
        "print('y.grad_fn', y.grad_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "h7TFHdMfgxvW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "z.data:  tensor([2., 2., 2.])\n",
            "z.grad None\n",
            "z.grad_fn <AddBackward0 object at 0x000002A3F9C75748>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\poeun\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more information.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "print('z.data: ', z.data)\n",
        "print('z.grad', z.grad)\n",
        "print('z.grad_fn', z.grad_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKv-osmNmWiA"
      },
      "source": [
        "## nn & nn.functional\n",
        "\n",
        "- 두 패키지가 같은 기능이지만 방식이 조금 다름\n",
        "\n",
        "- 위의 `autograd` 관련 작업들을 두 패키지를 통해 진행할 수 있음\n",
        "\n",
        "- 텐서를 직접 다룰 때 `requires_grad`와 같은 방식으로 진행할 수 있음\n",
        "\n",
        "- 결론적으로, `torch.nn`은 attribute를 활용해 state를 저장하고 활용하고,  \n",
        "  `torch.nn.functional`로 구현한 함수의 경우에는 인스턴스화 시킬 필요 없이 사용이 가능\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk8fkKq3nWP1"
      },
      "source": [
        "### nn 패키지\n",
        "\n",
        "- 주로 가중치(weights), 편향(bias)값들이 내부에서 자동으로 생성되는 레이어들을 사용할 때  \n",
        "  - 따라서, `weight`값들을 직접 선언 안함\n",
        "\n",
        "- 예시\n",
        "  - Containers\n",
        "\n",
        "  - Convolution Layers\n",
        "\n",
        "  - Pooling layers\n",
        "\n",
        "  - Padding Layers\n",
        "\n",
        "  - Non-linear Activations (weighted sum, nonlinearity)\n",
        "\n",
        "  - Non-linear Activations (other)\n",
        "\n",
        "  - Normalization Layers\n",
        "\n",
        "  - Recurrent Layers\n",
        "\n",
        "  - Transformer Layers\n",
        "\n",
        "  - Linear Layers\n",
        "\n",
        "  - Dropout Layers\n",
        "\n",
        "  - Sparse Layers\n",
        "\n",
        "  - Distance Functions\n",
        "\n",
        "  - Loss Functions\n",
        "\n",
        "  - ..\n",
        "- https://pytorch.org/docs/stable/nn.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "8tEtWHAsmZMy"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcjCbeEQqPSI"
      },
      "source": [
        "- Convolution Layer 예시 (1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "NQ7Y0tCOpkhM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[[ 2.2576e+00,  1.6124e-01, -4.5301e-01,  ..., -1.7705e+00,\n",
            "            9.7331e-01,  2.2469e-02],\n",
            "          [ 9.0245e-01,  2.8341e+00, -1.4440e-01,  ..., -9.7495e-01,\n",
            "           -1.1915e+00,  1.0638e-01],\n",
            "          [ 7.7335e-01,  2.9824e-01,  1.9133e-02,  ...,  2.9562e-01,\n",
            "            1.5380e+00, -9.0006e-02],\n",
            "          ...,\n",
            "          [-2.3486e-01,  3.5011e+00,  1.2189e+00,  ..., -8.8096e-01,\n",
            "           -1.2272e+00,  7.6250e-01],\n",
            "          [-1.2236e-01, -3.0480e-01,  7.8640e-01,  ..., -1.3818e+00,\n",
            "           -7.8562e-01, -1.5457e-01],\n",
            "          [ 8.4872e-01, -1.4933e+00, -1.1984e+00,  ..., -7.7623e-02,\n",
            "           -2.0382e-01,  9.8702e-01]],\n",
            "\n",
            "         [[ 4.3345e-01,  1.1153e+00, -9.2674e-02,  ...,  9.4741e-01,\n",
            "            4.5397e-01, -8.8490e-01],\n",
            "          [-1.7370e-03, -1.4731e+00, -6.8177e-01,  ...,  5.6230e-02,\n",
            "           -8.3274e-01, -7.4983e-01],\n",
            "          [ 1.1238e+00, -1.2013e+00,  1.0518e+00,  ...,  2.9532e-01,\n",
            "            2.1011e+00,  1.9327e-01],\n",
            "          ...,\n",
            "          [-7.0866e-01, -1.6286e+00, -3.1041e-01,  ..., -1.1956e+00,\n",
            "            2.4875e+00,  1.7252e+00],\n",
            "          [ 2.8941e-01,  4.7657e-01, -1.2913e+00,  ..., -6.8987e-01,\n",
            "           -8.9568e-01,  9.3335e-01],\n",
            "          [-1.4759e+00, -1.1991e+00,  1.1150e+00,  ..., -1.1032e+00,\n",
            "            1.9502e+00,  3.0301e-01]],\n",
            "\n",
            "         [[ 5.9385e-01,  1.8514e+00,  9.8182e-01,  ..., -1.1907e-01,\n",
            "           -1.3238e+00,  3.6632e-01],\n",
            "          [-1.2517e+00,  2.5639e-01, -1.8152e+00,  ...,  1.1187e+00,\n",
            "           -9.4953e-01,  7.9415e-01],\n",
            "          [-1.1266e+00,  2.0020e-01, -2.7140e+00,  ..., -7.0190e-01,\n",
            "            2.2209e+00,  2.2705e+00],\n",
            "          ...,\n",
            "          [-1.5277e-01, -5.8614e-02,  1.4445e+00,  ...,  6.5084e-01,\n",
            "            1.7900e+00,  1.8077e+00],\n",
            "          [-4.8005e-01,  3.6560e-01,  9.8183e-01,  ..., -5.3800e-01,\n",
            "           -9.6865e-01,  2.7216e-01],\n",
            "          [ 1.6656e-01,  3.3236e-01,  7.9950e-01,  ...,  1.2210e+00,\n",
            "           -2.3534e-01, -1.3174e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.1470e-01,  4.0593e-01, -3.5495e-02,  ..., -1.1920e+00,\n",
            "           -8.1992e-01, -6.2657e-01],\n",
            "          [ 1.9176e+00, -1.0197e+00,  2.6620e-01,  ..., -1.6302e+00,\n",
            "            1.2067e+00, -3.7205e-01],\n",
            "          [-6.3073e-01,  2.9292e-01, -8.7522e-01,  ..., -8.3756e-01,\n",
            "            2.1352e+00, -6.1256e-01],\n",
            "          ...,\n",
            "          [ 1.1344e+00, -6.8024e-03, -3.7257e-01,  ..., -6.4719e-01,\n",
            "           -1.3470e+00, -2.2263e-01],\n",
            "          [-1.6567e-01,  9.5035e-01,  2.2805e-02,  ...,  8.1092e-01,\n",
            "            4.8159e-01, -5.9582e-02],\n",
            "          [ 3.9422e-01,  3.3326e-01, -7.4829e-01,  ..., -9.5052e-02,\n",
            "           -1.0145e+00, -1.4655e+00]],\n",
            "\n",
            "         [[-1.3970e+00,  1.0190e+00, -1.2460e+00,  ...,  1.0709e+00,\n",
            "            3.6584e-01, -9.0580e-01],\n",
            "          [ 4.2095e-01,  3.8289e-01, -1.4831e+00,  ..., -1.1349e+00,\n",
            "           -1.3405e+00,  7.9625e-01],\n",
            "          [-2.4810e-01, -9.3002e-02, -8.7818e-01,  ...,  1.1496e+00,\n",
            "            1.1703e-01,  1.3232e+00],\n",
            "          ...,\n",
            "          [-9.2157e-02, -7.7698e-02,  8.7702e-01,  ...,  1.8063e+00,\n",
            "            1.1107e+00, -2.4528e-01],\n",
            "          [ 9.1549e-01, -4.7808e-01,  2.9675e-01,  ..., -2.7878e-02,\n",
            "           -4.1775e-01, -6.2213e-01],\n",
            "          [-1.1345e+00, -4.2175e-01, -6.2248e-02,  ..., -1.3148e-01,\n",
            "            1.2772e+00,  1.5817e+00]],\n",
            "\n",
            "         [[ 1.3094e-01,  3.7901e-01,  1.2578e-01,  ...,  1.4712e-01,\n",
            "            1.9523e+00,  4.9293e-01],\n",
            "          [ 9.1272e-01, -4.7436e-01, -1.4016e+00,  ..., -4.9097e-01,\n",
            "           -5.3342e-01, -1.9266e+00],\n",
            "          [-5.0380e-02, -1.8046e+00, -5.7836e-01,  ...,  1.4406e+00,\n",
            "            1.0462e+00,  2.2109e-01],\n",
            "          ...,\n",
            "          [ 2.1761e+00,  1.5422e-01, -6.8084e-01,  ...,  2.4261e-01,\n",
            "           -4.4913e-01, -2.5320e+00],\n",
            "          [ 1.0757e+00,  7.2711e-01, -2.0235e+00,  ..., -6.2293e-01,\n",
            "            1.4408e+00, -1.0695e+00],\n",
            "          [ 2.6889e-01, -3.1842e-02,  2.0303e+00,  ...,  7.4532e-01,\n",
            "           -5.3190e-02, -2.6911e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.6401e-01,  4.8792e-01,  1.0688e+00,  ..., -7.3801e-02,\n",
            "            1.5126e+00, -1.1556e+00],\n",
            "          [ 9.0854e-01,  1.8751e-01, -5.9124e-01,  ...,  7.5700e-01,\n",
            "           -1.7209e+00, -7.8388e-01],\n",
            "          [-4.1080e-01, -2.8209e-01, -6.3718e-01,  ...,  4.3061e-01,\n",
            "            1.3977e+00,  1.3564e+00],\n",
            "          ...,\n",
            "          [ 1.8808e+00, -1.7476e+00, -2.3585e-02,  ..., -7.5718e-01,\n",
            "            5.8727e-01,  2.7819e-01],\n",
            "          [-1.3011e+00,  5.4567e-01, -2.9678e+00,  ...,  4.7113e-02,\n",
            "            2.1147e-01,  1.0524e+00],\n",
            "          [-3.1367e-01, -3.3486e-01, -9.1216e-01,  ..., -1.1966e+00,\n",
            "           -1.1547e+00,  6.8194e-01]],\n",
            "\n",
            "         [[-2.2091e+00, -2.6208e-01, -5.0133e-02,  ..., -1.8903e+00,\n",
            "            1.3155e+00,  5.0622e-01],\n",
            "          [ 9.4680e-01,  1.9544e+00, -5.7362e-01,  ..., -2.9788e-01,\n",
            "           -9.3085e-01,  9.5067e-01],\n",
            "          [ 2.4002e+00,  1.5091e+00, -4.7507e-01,  ..., -1.8300e-01,\n",
            "           -1.4739e+00,  5.2943e-02],\n",
            "          ...,\n",
            "          [-2.6802e-01, -4.7839e-01,  1.6609e+00,  ...,  1.9234e+00,\n",
            "           -6.1642e-01, -1.0578e+00],\n",
            "          [ 4.2877e-01,  3.0667e+00,  8.6344e-01,  ..., -9.8564e-02,\n",
            "            8.1391e-02,  1.9464e+00],\n",
            "          [-2.3106e+00, -2.4807e-02,  1.2805e-01,  ...,  7.9960e-01,\n",
            "            1.1528e+00,  2.0956e-01]],\n",
            "\n",
            "         [[-8.0013e-02, -8.7772e-01, -9.4482e-01,  ..., -1.0659e-01,\n",
            "           -1.3377e-01, -3.4658e-01],\n",
            "          [ 6.9437e-01,  9.3122e-01, -6.8567e-01,  ..., -8.7015e-01,\n",
            "            6.9078e-01,  1.9436e+00],\n",
            "          [ 1.7669e+00, -1.0540e+00, -8.7245e-01,  ...,  2.8440e-02,\n",
            "           -6.1098e-01,  1.5727e+00],\n",
            "          ...,\n",
            "          [ 2.8993e-01,  1.5019e-01,  3.0329e-02,  ...,  2.5981e-01,\n",
            "            3.8528e-01,  9.4314e-01],\n",
            "          [-7.3278e-01, -2.5076e+00,  7.7471e-01,  ...,  1.9526e+00,\n",
            "            1.4097e+00,  4.4028e-01],\n",
            "          [-4.8387e-01,  1.4526e-01,  6.7560e-01,  ..., -1.0691e-01,\n",
            "            4.8191e-01, -4.1828e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.4227e-01,  9.1159e-01,  1.2018e+00,  ..., -1.9124e-01,\n",
            "           -7.7606e-01,  5.6515e-01],\n",
            "          [-1.1946e-01, -7.5971e-01, -3.7361e-01,  ..., -1.2178e-01,\n",
            "            7.8398e-01, -7.9309e-01],\n",
            "          [-1.8165e+00,  3.6122e-01, -4.1656e-01,  ..., -8.1943e-01,\n",
            "           -8.8987e-01,  1.0061e+00],\n",
            "          ...,\n",
            "          [ 5.5163e-01,  1.6064e+00,  6.0448e-01,  ...,  2.8678e-02,\n",
            "            6.7180e-01, -4.8608e-01],\n",
            "          [ 3.5325e-01,  6.9920e-01, -9.7640e-01,  ...,  7.3815e-01,\n",
            "           -8.3021e-02, -6.1474e-01],\n",
            "          [ 1.4152e+00,  4.8116e-01, -8.8111e-01,  ..., -4.5096e-01,\n",
            "            5.6611e-01,  1.1322e+00]],\n",
            "\n",
            "         [[ 8.4082e-01,  2.0084e-01,  1.3264e+00,  ...,  5.6740e-01,\n",
            "            1.0590e+00, -3.8339e-01],\n",
            "          [ 1.5370e+00, -1.4926e+00, -1.1670e+00,  ...,  1.4269e+00,\n",
            "           -7.8052e-01, -1.1280e+00],\n",
            "          [ 3.2798e-01,  1.1356e+00, -1.1369e-01,  ..., -1.9930e-01,\n",
            "            2.6084e-01,  5.9176e-01],\n",
            "          ...,\n",
            "          [-8.7902e-01, -2.0681e+00,  5.5446e-01,  ...,  8.9353e-01,\n",
            "            9.5604e-02, -4.4391e-01],\n",
            "          [ 1.0768e+00, -9.9825e-01,  1.9128e-02,  ...,  7.8948e-01,\n",
            "            7.8642e-01, -4.8183e-01],\n",
            "          [-2.5788e-01, -1.4663e-01,  2.4613e+00,  ...,  8.9143e-01,\n",
            "            1.7466e+00, -1.0332e+00]],\n",
            "\n",
            "         [[ 6.2994e-01,  1.3990e+00, -6.2032e-02,  ..., -1.1667e+00,\n",
            "           -8.9137e-01,  4.6561e-01],\n",
            "          [ 4.5070e-01,  7.7295e-01,  1.5818e+00,  ..., -7.8474e-01,\n",
            "            1.2273e+00, -4.3923e-01],\n",
            "          [-2.0290e+00,  2.2423e+00, -9.2575e-01,  ..., -1.2909e+00,\n",
            "            3.4081e-01,  9.4489e-01],\n",
            "          ...,\n",
            "          [ 2.6555e-01, -6.3335e-01,  8.4897e-01,  ...,  1.5889e-01,\n",
            "            1.4181e+00,  3.3304e-01],\n",
            "          [ 3.7485e-01,  7.2698e-01, -8.1438e-01,  ..., -9.5218e-01,\n",
            "           -1.2214e+00,  1.6604e+00],\n",
            "          [ 2.0513e-01,  8.4458e-01,  3.7541e-01,  ...,  1.4006e+00,\n",
            "            1.4553e+00, -2.0408e+00]]],\n",
            "\n",
            "\n",
            "        [[[-8.6945e-02,  3.7049e-01,  3.7645e-01,  ..., -1.0860e-01,\n",
            "           -9.7631e-01, -3.4947e-01],\n",
            "          [-8.4227e-01,  1.3107e+00,  7.6530e-01,  ..., -3.3279e-01,\n",
            "           -1.3593e-01,  3.4130e-01],\n",
            "          [ 6.2291e-01,  2.3924e+00, -6.6435e-02,  ..., -2.7453e+00,\n",
            "            2.1768e-01, -3.7685e-01],\n",
            "          ...,\n",
            "          [ 7.9774e-01, -5.7448e-01,  1.2197e+00,  ..., -7.7797e-01,\n",
            "            9.7778e-01, -6.7658e-01],\n",
            "          [-3.7794e-01, -2.0909e+00,  7.7717e-01,  ..., -5.5147e-01,\n",
            "           -8.5001e-01, -1.6932e-02],\n",
            "          [ 1.0736e+00,  2.3792e+00,  9.4901e-01,  ..., -7.9062e-02,\n",
            "           -1.7099e-01, -2.6090e-01]],\n",
            "\n",
            "         [[-4.1738e-01, -8.4940e-01,  1.3723e+00,  ..., -1.1891e+00,\n",
            "           -1.8069e-01, -1.3414e-01],\n",
            "          [ 2.2187e-01, -3.3711e-02,  4.7879e-01,  ..., -1.1722e-01,\n",
            "            1.2605e+00,  1.2431e+00],\n",
            "          [ 5.6407e-01,  6.1445e-01, -8.2175e-01,  ...,  3.5157e-01,\n",
            "            1.3762e+00, -3.0762e-01],\n",
            "          ...,\n",
            "          [ 8.3257e-01, -8.9471e-02,  1.7830e-01,  ..., -5.8131e-01,\n",
            "            2.4849e-01,  9.5466e-01],\n",
            "          [ 1.7010e+00, -2.5281e+00, -1.6723e-01,  ...,  1.1637e+00,\n",
            "            1.4672e+00, -3.0843e+00],\n",
            "          [ 8.9641e-02,  6.7312e-01,  1.2372e+00,  ..., -2.4745e-01,\n",
            "            1.0910e-01, -1.3993e+00]],\n",
            "\n",
            "         [[-1.5794e+00,  6.2200e-01,  8.5357e-02,  ..., -1.7226e-01,\n",
            "           -1.6915e-01,  1.5546e+00],\n",
            "          [-1.7494e-01,  1.6479e-01,  9.5287e-01,  ...,  5.8391e-01,\n",
            "            1.0162e+00, -1.6911e-02],\n",
            "          [-3.3969e-02, -1.3399e-01, -7.7051e-01,  ...,  6.0760e-01,\n",
            "            1.1508e-01, -2.2656e-01],\n",
            "          ...,\n",
            "          [ 4.0868e-01,  1.3205e+00,  1.2107e+00,  ..., -1.4339e+00,\n",
            "           -5.0303e-01, -6.3177e-01],\n",
            "          [-2.5480e-01, -1.0095e+00,  9.4216e-01,  ..., -1.2705e+00,\n",
            "           -1.6286e+00, -2.1799e-01],\n",
            "          [ 2.8064e-01,  3.4893e-01, -7.8365e-01,  ...,  3.8227e-01,\n",
            "            9.7663e-01, -1.5932e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.5622e-02, -2.0147e+00,  9.3780e-01,  ..., -1.4471e+00,\n",
            "            1.4145e-02,  1.5650e+00],\n",
            "          [ 1.5236e+00,  1.1912e+00, -5.0704e-01,  ...,  1.6019e+00,\n",
            "           -5.2527e-01,  1.1098e+00],\n",
            "          [-4.6739e-01, -4.3294e-01,  1.2943e-01,  ...,  8.9662e-01,\n",
            "            2.6893e-01, -4.2910e-02],\n",
            "          ...,\n",
            "          [ 3.6916e-01, -1.2906e+00, -3.1526e-01,  ...,  3.2269e-01,\n",
            "            4.7140e-01, -1.1674e+00],\n",
            "          [-1.6740e+00,  1.2256e-01, -2.9680e-02,  ..., -9.1402e-01,\n",
            "           -1.0746e+00, -8.2863e-01],\n",
            "          [ 2.7580e-01,  2.6313e-01, -1.2612e+00,  ...,  2.7107e-01,\n",
            "            2.8274e+00, -9.6619e-01]],\n",
            "\n",
            "         [[-8.9184e-02,  7.7946e-01,  3.6778e-01,  ..., -1.2960e+00,\n",
            "           -1.0594e+00,  3.6477e-01],\n",
            "          [ 9.2916e-01,  1.4370e+00, -9.8636e-01,  ...,  5.3358e-01,\n",
            "           -1.0669e+00, -4.1803e-01],\n",
            "          [ 8.7585e-01, -8.5978e-01, -3.6753e-01,  ...,  9.7352e-01,\n",
            "            8.5283e-01,  2.9593e-01],\n",
            "          ...,\n",
            "          [-8.1791e-02, -8.0352e-01, -3.3210e-01,  ...,  3.4337e-01,\n",
            "            3.1818e-01, -2.2800e+00],\n",
            "          [ 8.9603e-01, -2.0973e+00,  7.5730e-01,  ..., -1.0527e-01,\n",
            "           -1.4376e-01,  3.1008e-01],\n",
            "          [-2.8633e+00, -2.8150e+00,  1.5987e-01,  ..., -3.1663e-01,\n",
            "           -1.8517e+00,  2.4080e+00]],\n",
            "\n",
            "         [[ 1.2018e+00, -1.1707e+00, -1.2371e-01,  ..., -5.5383e-01,\n",
            "           -1.2202e+00, -1.9573e+00],\n",
            "          [ 8.7798e-02, -1.4097e+00, -1.6528e+00,  ...,  3.3355e-01,\n",
            "            4.3284e-01,  3.2870e-01],\n",
            "          [-3.9099e-02, -2.8880e-01, -3.8564e-01,  ...,  7.5758e-01,\n",
            "            1.5002e+00,  5.9265e-01],\n",
            "          ...,\n",
            "          [ 1.7299e-01, -9.2485e-02,  1.4146e+00,  ..., -3.0225e-01,\n",
            "            1.7455e+00, -2.9405e-01],\n",
            "          [ 1.6165e-01, -2.9539e-01,  1.0213e+00,  ..., -1.1581e-01,\n",
            "           -2.1495e+00,  8.6169e-01],\n",
            "          [-7.6420e-01, -3.0529e-01,  7.3223e-01,  ..., -6.1593e-01,\n",
            "            6.4651e-01, -7.0015e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 8.7637e-01, -7.7643e-01,  1.6700e+00,  ..., -2.6470e-01,\n",
            "           -2.1284e+00, -9.0811e-02],\n",
            "          [-1.0697e+00, -4.7942e-01,  5.4489e-01,  ...,  3.5285e-01,\n",
            "            3.7744e-01,  4.0248e-01],\n",
            "          [ 9.4055e-01, -1.1331e+00, -5.6169e-01,  ...,  6.7660e-01,\n",
            "            1.0355e+00,  1.0988e+00],\n",
            "          ...,\n",
            "          [-2.0895e+00, -7.4043e-01,  1.0403e+00,  ...,  1.3703e+00,\n",
            "            5.4090e-01, -5.0814e-01],\n",
            "          [-5.9343e-01,  2.0768e+00,  1.9207e-01,  ..., -3.1427e-01,\n",
            "           -6.7569e-01,  1.1468e+00],\n",
            "          [-7.5323e-01,  1.7924e-01, -1.0035e+00,  ...,  8.3540e-01,\n",
            "            5.7733e-01,  8.5930e-01]],\n",
            "\n",
            "         [[-7.0544e-01,  4.3619e-02,  1.1303e+00,  ..., -1.6934e+00,\n",
            "           -6.9003e-01,  8.2747e-01],\n",
            "          [-1.3128e+00,  5.2168e-01, -4.9761e-01,  ..., -5.0501e-01,\n",
            "           -1.5511e+00, -1.2684e+00],\n",
            "          [ 1.3347e-01, -2.3955e-01,  2.2798e+00,  ...,  6.9810e-01,\n",
            "           -1.7384e+00, -1.6977e+00],\n",
            "          ...,\n",
            "          [-1.7534e-01, -8.7935e-01, -1.7123e+00,  ..., -1.6848e-01,\n",
            "            3.1343e-01,  1.7927e-01],\n",
            "          [-8.2154e-01,  6.8894e-01,  6.3202e-01,  ...,  1.2560e+00,\n",
            "           -5.5529e-01, -5.4889e-01],\n",
            "          [-6.8403e-01,  4.0394e-01, -2.2053e+00,  ...,  1.3613e-01,\n",
            "           -1.0166e+00,  4.8905e-01]],\n",
            "\n",
            "         [[-3.3619e-01, -4.0223e-01, -2.8993e-01,  ...,  8.6977e-01,\n",
            "            8.5962e-01, -7.1331e-02],\n",
            "          [-2.6072e-02, -1.1079e+00,  1.2264e+00,  ...,  2.2705e-01,\n",
            "           -6.1895e-01,  1.0674e+00],\n",
            "          [-1.1032e+00, -4.7020e-01,  2.6139e-01,  ...,  2.2171e+00,\n",
            "            9.0008e-02, -2.0228e+00],\n",
            "          ...,\n",
            "          [-7.8434e-01,  1.4135e-01, -1.0430e+00,  ...,  8.2448e-01,\n",
            "           -5.2467e-01,  6.9125e-01],\n",
            "          [-2.6537e-01,  9.8823e-01, -2.9739e-01,  ...,  2.5326e+00,\n",
            "            6.1451e-01, -1.3646e+00],\n",
            "          [-1.5102e+00, -2.9126e-01, -2.9955e-01,  ..., -9.1445e-01,\n",
            "            2.0070e+00, -1.9320e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0927e+00, -1.1577e+00, -3.4547e-01,  ..., -3.1587e-01,\n",
            "           -5.9379e-01, -9.9587e-01],\n",
            "          [ 1.5894e+00,  1.4322e-01,  2.4585e-01,  ..., -3.3777e-01,\n",
            "           -1.1156e+00,  2.3045e+00],\n",
            "          [-4.4269e-01, -1.0919e-01, -9.7486e-01,  ..., -5.2246e-02,\n",
            "           -1.1713e+00,  2.1237e+00],\n",
            "          ...,\n",
            "          [-1.1507e+00,  9.7584e-01,  1.8555e-02,  ...,  1.2493e+00,\n",
            "            1.9435e+00, -1.0525e-01],\n",
            "          [-1.9003e-01,  6.9258e-01,  6.2993e-01,  ..., -1.0415e+00,\n",
            "            3.5552e-01, -2.7065e+00],\n",
            "          [-7.6377e-01, -6.9468e-01,  1.1832e+00,  ...,  2.6093e-01,\n",
            "           -1.9090e-01,  8.1352e-01]],\n",
            "\n",
            "         [[-4.4037e-01, -1.0806e+00, -2.3196e-01,  ...,  6.4102e-01,\n",
            "            2.2031e-01,  1.8435e+00],\n",
            "          [ 1.0612e+00,  9.7002e-01, -1.3442e-01,  ...,  1.2883e+00,\n",
            "            1.0597e+00,  1.2801e-01],\n",
            "          [ 1.1222e+00, -1.2236e+00,  1.6424e+00,  ..., -2.7566e-01,\n",
            "            5.3944e-01, -3.1985e-01],\n",
            "          ...,\n",
            "          [-1.1625e+00, -7.3092e-01,  5.7142e-01,  ..., -9.3010e-01,\n",
            "            2.7717e-01, -3.5816e-01],\n",
            "          [ 6.2867e-01, -1.5099e+00, -2.9062e-01,  ..., -1.4586e+00,\n",
            "            9.0278e-01,  5.4085e-01],\n",
            "          [ 7.1259e-01,  1.1121e+00,  1.9906e-01,  ..., -9.9484e-01,\n",
            "            1.6472e+00,  1.5605e-01]],\n",
            "\n",
            "         [[-9.5900e-01, -2.7257e+00, -7.3553e-01,  ..., -6.3522e-01,\n",
            "           -1.2280e+00,  9.7434e-01],\n",
            "          [ 4.6412e-01, -1.2258e+00, -8.5590e-01,  ..., -4.7535e-01,\n",
            "            8.3232e-01,  1.6768e-01],\n",
            "          [ 8.3957e-02, -9.6191e-01,  2.9267e-01,  ..., -3.3142e-01,\n",
            "            8.0811e-01,  2.4981e-01],\n",
            "          ...,\n",
            "          [-2.0515e+00,  1.0742e-01,  1.6725e+00,  ..., -2.1951e-01,\n",
            "           -1.3466e-01,  2.9528e+00],\n",
            "          [ 2.6381e-01,  3.9758e-01, -1.8583e+00,  ...,  8.1421e-01,\n",
            "           -5.5175e-01,  1.0865e+00],\n",
            "          [-1.5701e+00, -5.3608e-01, -4.7080e-01,  ..., -1.9757e-01,\n",
            "           -1.9003e+00,  7.2825e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.5438e-02,  2.0517e-01, -3.3953e-01,  ...,  1.3074e+00,\n",
            "           -7.4222e-01,  2.0819e+00],\n",
            "          [-1.1456e+00,  6.7151e-01, -9.7903e-01,  ..., -5.3638e-01,\n",
            "            6.5235e-01, -1.6927e-01],\n",
            "          [ 3.7986e-01, -1.1832e+00,  5.0941e-01,  ..., -6.1714e-01,\n",
            "           -4.0594e-01, -1.0876e+00],\n",
            "          ...,\n",
            "          [ 1.2427e+00, -1.0207e+00, -9.5117e-01,  ..., -3.3924e-01,\n",
            "            1.0385e+00,  1.4728e+00],\n",
            "          [ 7.9083e-01,  2.8340e-01,  8.1103e-02,  ..., -6.6845e-01,\n",
            "            1.1716e+00, -2.9763e-02],\n",
            "          [ 1.3478e-01,  2.2454e+00, -1.0333e+00,  ..., -3.2576e-01,\n",
            "            4.8560e-01, -6.6679e-01]],\n",
            "\n",
            "         [[-1.7698e+00, -1.0857e+00,  1.2974e+00,  ..., -5.6508e-01,\n",
            "           -1.0487e+00,  3.6489e-01],\n",
            "          [ 3.0914e-01,  8.2846e-01,  2.1690e+00,  ...,  9.6188e-01,\n",
            "           -6.0254e-01,  1.9444e-01],\n",
            "          [ 3.4574e-01, -8.8372e-01, -9.4067e-01,  ..., -2.0852e+00,\n",
            "            1.1345e+00,  9.9213e-01],\n",
            "          ...,\n",
            "          [-5.3620e-01,  3.4083e-01, -6.5695e-01,  ..., -1.8105e-01,\n",
            "            4.4573e-01,  2.3333e-01],\n",
            "          [-1.1150e+00,  7.8932e-01, -8.8520e-01,  ..., -5.3989e-01,\n",
            "            5.3017e-02, -3.2101e-01],\n",
            "          [-1.9740e+00,  4.6764e-01, -6.8943e-01,  ...,  3.1062e-01,\n",
            "            3.7892e-01, -6.2049e-02]],\n",
            "\n",
            "         [[ 4.5186e-01, -5.0573e-01,  1.0480e+00,  ..., -4.4192e-01,\n",
            "            9.9773e-01,  1.2108e+00],\n",
            "          [-2.8863e+00,  7.5742e-01, -4.2294e-01,  ..., -1.0588e-01,\n",
            "            6.1399e-01,  4.1604e-01],\n",
            "          [-7.4410e-01, -1.0804e-01, -1.8585e+00,  ..., -1.5176e+00,\n",
            "            1.4809e+00,  4.5247e-01],\n",
            "          ...,\n",
            "          [ 1.7184e+00,  8.0422e-01, -1.5310e+00,  ..., -1.0576e+00,\n",
            "           -8.7300e-01, -1.1538e+00],\n",
            "          [ 1.5476e+00, -9.2144e-01, -1.1632e+00,  ...,  1.7312e-01,\n",
            "           -2.0631e-01,  4.9783e-01],\n",
            "          [-1.1961e+00, -5.9992e-01,  1.1254e+00,  ...,  4.7452e-01,\n",
            "            9.8217e-01,  9.2936e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.7470e-01, -3.1686e-01, -9.8515e-01,  ...,  1.8691e-01,\n",
            "           -1.3331e+00, -4.6496e-01],\n",
            "          [ 5.6657e-01, -6.2295e-01,  7.5272e-01,  ..., -1.3229e+00,\n",
            "            1.0498e+00, -1.0548e+00],\n",
            "          [-3.4355e+00,  1.5497e-01, -1.4464e+00,  ..., -1.1922e+00,\n",
            "           -7.3662e-02, -1.8863e+00],\n",
            "          ...,\n",
            "          [-2.7992e-01, -8.1375e-01, -1.2286e+00,  ..., -2.2725e+00,\n",
            "            4.3233e-01, -2.3691e-01],\n",
            "          [ 3.4960e-02, -2.0659e+00,  1.2258e+00,  ..., -4.7613e-01,\n",
            "            6.6973e-01,  5.6697e-01],\n",
            "          [ 8.7738e-01, -6.2473e-01, -6.0874e-01,  ..., -4.2835e-01,\n",
            "           -1.1837e+00, -9.3138e-01]],\n",
            "\n",
            "         [[-6.3631e-01,  1.6742e+00,  7.0652e-02,  ..., -7.2321e-01,\n",
            "            6.4467e-01,  1.3543e+00],\n",
            "          [ 1.0364e+00,  5.5881e-02,  7.4108e-02,  ...,  7.2072e-01,\n",
            "            1.4353e+00,  2.1728e+00],\n",
            "          [-2.2642e+00,  1.2053e+00, -1.0113e+00,  ..., -2.0141e-03,\n",
            "           -1.9911e-01,  4.7038e-01],\n",
            "          ...,\n",
            "          [-4.2201e-01,  1.9508e-01, -4.4100e-01,  ..., -5.6105e-01,\n",
            "            1.5005e+00, -3.2535e-01],\n",
            "          [-2.4265e+00, -1.5205e-01, -5.7714e-01,  ..., -5.4431e-01,\n",
            "            7.1180e-02, -2.2435e-01],\n",
            "          [ 1.3871e+00,  4.5379e-01,  8.9479e-01,  ...,  1.7647e-01,\n",
            "           -2.3975e-01,  8.6741e-01]],\n",
            "\n",
            "         [[-4.1683e-01,  9.2062e-01,  9.7171e-01,  ...,  1.8414e+00,\n",
            "            1.6497e+00,  5.9404e-01],\n",
            "          [ 7.5270e-01,  1.0933e+00, -1.1332e-01,  ...,  8.7330e-01,\n",
            "            2.1262e+00, -8.7463e-01],\n",
            "          [-1.3539e+00,  3.3984e+00,  1.4548e+00,  ...,  7.6226e-01,\n",
            "            2.1178e-02,  1.8541e-01],\n",
            "          ...,\n",
            "          [ 8.5230e-01,  4.6040e-01,  3.1365e+00,  ..., -5.1309e-01,\n",
            "           -1.7801e-01, -4.8416e-01],\n",
            "          [-1.5117e+00, -1.6382e+00, -9.7167e-02,  ..., -5.0738e-01,\n",
            "           -1.1039e+00,  1.6810e-01],\n",
            "          [ 7.7167e-01, -1.0546e+00, -1.2760e-02,  ...,  9.5420e-01,\n",
            "           -1.4752e-01, -1.7209e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0348e+00,  1.4665e+00, -1.1268e+00,  ..., -6.7868e-01,\n",
            "           -1.0937e+00,  1.1676e+00],\n",
            "          [-1.4356e+00, -5.3279e-01, -4.7168e-01,  ...,  6.5255e-01,\n",
            "           -4.0139e-02,  3.8350e-01],\n",
            "          [-9.8481e-01, -2.2104e-01, -3.0130e-01,  ..., -6.7542e-01,\n",
            "            5.2915e-01,  6.9763e-01],\n",
            "          ...,\n",
            "          [ 3.9676e-01,  6.3435e-01,  7.9200e-01,  ...,  5.2759e-01,\n",
            "            9.9205e-01,  2.6814e-01],\n",
            "          [ 1.9440e+00,  5.7888e-01, -1.7688e-02,  ...,  9.2709e-01,\n",
            "            1.1512e-01,  7.2537e-01],\n",
            "          [-4.8535e-02,  3.6261e-01, -7.7644e-02,  ..., -6.1119e-01,\n",
            "           -3.6493e-01,  3.9765e-01]],\n",
            "\n",
            "         [[ 1.0729e+00, -1.4918e+00,  1.5745e+00,  ..., -1.1508e+00,\n",
            "           -1.2652e+00,  7.9931e-01],\n",
            "          [-9.5847e-02, -4.9627e-01, -2.3306e-01,  ...,  8.6266e-01,\n",
            "           -5.4336e-01,  4.5800e-01],\n",
            "          [ 2.5729e-01,  2.2684e-01,  1.1577e+00,  ...,  1.3250e+00,\n",
            "            6.5816e-02, -2.0844e-01],\n",
            "          ...,\n",
            "          [ 1.4418e+00, -1.5988e-02,  6.2323e-01,  ...,  3.9673e+00,\n",
            "           -5.2817e-01,  5.1635e-01],\n",
            "          [ 2.0643e+00,  2.3789e+00,  1.0671e+00,  ..., -1.2290e+00,\n",
            "            7.0325e-01,  4.7451e-02],\n",
            "          [ 1.9236e+00,  5.8484e-01, -6.3834e-01,  ..., -9.7732e-01,\n",
            "            6.6765e-01, -9.4766e-01]],\n",
            "\n",
            "         [[-1.1731e+00, -1.0245e+00,  3.9932e-01,  ..., -1.7206e+00,\n",
            "           -4.7778e-01,  1.7985e-01],\n",
            "          [-7.2447e-01, -6.2323e-01,  1.4536e+00,  ...,  1.6379e+00,\n",
            "            6.2963e-01,  7.3060e-02],\n",
            "          [ 1.6083e-01,  1.8161e-01,  1.7334e+00,  ..., -4.1560e-01,\n",
            "           -1.7092e+00,  1.3216e+00],\n",
            "          ...,\n",
            "          [-1.0092e+00,  2.2910e-01, -6.5947e-01,  ...,  1.9378e-01,\n",
            "           -1.2367e+00, -1.2037e+00],\n",
            "          [ 1.0395e+00, -1.2373e+00,  4.0730e-01,  ...,  1.0838e+00,\n",
            "           -1.1341e+00,  1.0608e+00],\n",
            "          [-1.2648e+00,  3.4112e-01, -5.1144e-01,  ...,  1.1459e+00,\n",
            "            5.5270e-01,  1.2320e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.7367e+00,  1.2963e+00, -4.0017e-01,  ..., -2.5366e+00,\n",
            "            1.9988e-01,  1.1465e+00],\n",
            "          [-5.9801e-01, -8.2458e-02,  2.8252e-01,  ...,  1.5038e+00,\n",
            "            3.9443e-01,  1.6663e+00],\n",
            "          [ 6.0123e-01,  6.3166e-01, -2.0919e-02,  ..., -4.9536e-01,\n",
            "            4.7782e-01,  9.6651e-01],\n",
            "          ...,\n",
            "          [-5.0985e-01,  2.1457e+00, -2.6685e-02,  ...,  6.4951e-01,\n",
            "           -4.0581e-01,  8.9598e-01],\n",
            "          [ 1.5150e+00, -3.5902e-01,  2.9252e-01,  ...,  7.3640e-01,\n",
            "            7.4937e-01,  6.0523e-01],\n",
            "          [ 6.4693e-01,  2.2078e+00,  1.8548e-02,  ..., -4.0983e-01,\n",
            "            9.0629e-01,  1.0558e+00]],\n",
            "\n",
            "         [[-1.1723e+00,  1.1466e+00,  1.3559e+00,  ..., -2.1722e+00,\n",
            "           -6.9016e-01,  2.3961e-01],\n",
            "          [-9.3888e-01, -9.8757e-02, -2.1403e-01,  ...,  6.8370e-02,\n",
            "            3.7569e-02,  7.5733e-01],\n",
            "          [-2.5750e-01,  2.3642e-01,  1.6118e+00,  ..., -3.4897e-01,\n",
            "           -1.1221e+00,  9.8042e-01],\n",
            "          ...,\n",
            "          [ 7.0894e-01, -6.2415e-01,  4.5983e-01,  ...,  9.4624e-01,\n",
            "           -1.8601e-01,  4.3808e-01],\n",
            "          [-5.9977e-01, -6.0989e-02,  2.0477e+00,  ..., -3.3923e-01,\n",
            "            9.6189e-01,  8.6430e-01],\n",
            "          [ 8.3275e-01, -1.9425e+00,  1.8258e-01,  ..., -8.9708e-01,\n",
            "            1.7836e-01,  7.4115e-01]],\n",
            "\n",
            "         [[ 1.7356e+00, -1.5736e+00,  9.8006e-02,  ..., -1.2138e+00,\n",
            "           -2.1825e-01, -2.1247e+00],\n",
            "          [-2.1405e-01, -1.1805e+00, -2.7447e-01,  ..., -4.1105e-01,\n",
            "           -1.9814e-01, -1.2907e+00],\n",
            "          [ 3.1268e-01, -5.5591e-01,  1.7547e+00,  ..., -8.3437e-01,\n",
            "            1.0344e+00,  7.0467e-01],\n",
            "          ...,\n",
            "          [ 1.2409e+00,  5.9848e-01,  4.2277e-01,  ..., -2.2287e+00,\n",
            "           -2.7355e-01, -2.1826e+00],\n",
            "          [-9.8813e-01,  7.8908e-01,  3.3047e-01,  ...,  2.1330e+00,\n",
            "            2.1546e+00,  1.6785e-02],\n",
            "          [ 1.9569e-01,  4.2533e-01,  2.3920e-01,  ..., -6.6577e-01,\n",
            "           -8.4575e-01, -9.7635e-01]]]])\n",
            "tensor([[[[-1.7699e-01, -9.4949e-02,  3.5838e-01,  ..., -1.6983e-01,\n",
            "            2.6814e-01, -1.7236e-01],\n",
            "          [ 3.0934e-02,  6.0378e-01,  3.1803e-01,  ...,  3.1036e-01,\n",
            "            4.0966e-01,  8.4989e-02],\n",
            "          [-7.9051e-01, -1.6819e-01,  2.3566e-01,  ..., -1.0843e+00,\n",
            "           -9.5939e-02,  4.6204e-03],\n",
            "          ...,\n",
            "          [-1.4459e-01, -7.1704e-01,  4.7048e-01,  ...,  3.6356e-03,\n",
            "           -4.6022e-01,  3.8653e-01],\n",
            "          [-8.7121e-01, -5.5898e-01, -5.3481e-01,  ..., -4.2756e-01,\n",
            "            3.5245e-01, -5.0558e-01],\n",
            "          [-8.4564e-02,  3.6126e-01, -6.3361e-01,  ..., -4.4292e-01,\n",
            "           -3.2915e-01,  8.1528e-01]],\n",
            "\n",
            "         [[-4.8981e-02, -1.0010e+00,  6.0621e-02,  ..., -9.5932e-02,\n",
            "           -2.6285e-01, -3.4270e-01],\n",
            "          [ 2.1130e-01, -1.8434e-01,  4.4789e-01,  ...,  5.8896e-01,\n",
            "            3.8381e-01,  3.0676e-01],\n",
            "          [-1.1020e-01, -4.2932e-01, -1.0711e-01,  ..., -4.0052e-02,\n",
            "            7.8952e-01, -4.0538e-01],\n",
            "          ...,\n",
            "          [-9.3432e-01,  1.0706e+00, -6.5298e-01,  ..., -7.3259e-01,\n",
            "            4.5919e-01,  1.1680e-02],\n",
            "          [-2.5699e-01, -4.9099e-01, -1.4982e-01,  ...,  1.0883e-01,\n",
            "            2.3665e-01,  1.8426e-01],\n",
            "          [ 7.3983e-02, -1.1500e+00,  3.7208e-02,  ..., -3.9375e-01,\n",
            "           -7.0957e-01,  4.7559e-01]],\n",
            "\n",
            "         [[ 5.1547e-01, -1.0146e-01,  1.4071e-02,  ...,  1.2573e-01,\n",
            "            4.7343e-01, -2.3696e-01],\n",
            "          [ 9.6690e-02,  8.4299e-01,  5.7491e-01,  ...,  1.1587e+00,\n",
            "            2.0682e-01,  2.8147e-01],\n",
            "          [ 3.6839e-01,  1.0228e+00,  1.2562e+00,  ...,  1.6520e+00,\n",
            "           -7.8038e-01,  4.9750e-01],\n",
            "          ...,\n",
            "          [ 4.1046e-01, -5.5960e-01,  5.6246e-01,  ..., -4.7399e-01,\n",
            "           -2.2258e-03,  5.1805e-01],\n",
            "          [ 2.4261e-01, -4.3461e-01,  5.8069e-01,  ..., -2.1455e-01,\n",
            "           -5.5687e-01, -2.2770e-01],\n",
            "          [ 2.5414e-01, -2.6292e-01,  8.0323e-01,  ..., -7.1925e-01,\n",
            "           -3.4715e-01,  1.1125e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.7562e-01,  8.6725e-02, -4.6918e-01,  ...,  7.7871e-03,\n",
            "            1.4456e-01,  4.1028e-03],\n",
            "          [ 3.3010e-01, -3.8395e-01,  2.8994e-03,  ...,  5.0546e-01,\n",
            "            2.3256e-01, -2.8893e-01],\n",
            "          [ 5.5381e-01, -6.8281e-01,  3.8330e-02,  ..., -5.8437e-01,\n",
            "           -1.1949e-01, -8.0206e-01],\n",
            "          ...,\n",
            "          [ 3.6226e-01, -2.7577e-01,  2.8153e-01,  ..., -2.0703e-01,\n",
            "           -4.7726e-01,  1.5652e-01],\n",
            "          [-6.3953e-02, -4.8464e-01, -2.5407e-01,  ...,  3.3975e-01,\n",
            "           -3.0874e-01, -2.8334e-01],\n",
            "          [ 1.0060e-01,  7.2139e-01,  3.6735e-01,  ...,  4.9913e-01,\n",
            "           -5.3080e-02, -2.0221e-02]],\n",
            "\n",
            "         [[ 1.8974e-01, -2.4935e-01,  4.1410e-01,  ..., -1.2509e-02,\n",
            "           -4.3308e-01,  1.8879e-02],\n",
            "          [ 3.0706e-01, -8.0998e-01, -4.0197e-01,  ...,  6.2266e-01,\n",
            "            1.8260e-02,  3.7238e-01],\n",
            "          [-3.3071e-01, -2.2731e-01,  4.0369e-01,  ...,  9.7601e-01,\n",
            "            1.6647e-01,  2.8980e-01],\n",
            "          ...,\n",
            "          [ 1.2926e-01, -2.0193e-01,  4.8729e-01,  ..., -7.5966e-02,\n",
            "            7.0962e-01,  9.0160e-02],\n",
            "          [ 2.4185e-01,  1.0272e-01, -1.4710e-01,  ...,  3.9833e-01,\n",
            "            3.5216e-01,  6.9790e-02],\n",
            "          [-3.6948e-01, -3.8492e-01, -2.1411e-01,  ...,  2.9565e-01,\n",
            "            2.8525e-01,  5.2939e-01]],\n",
            "\n",
            "         [[-1.2540e-01, -3.8342e-01,  2.2634e-01,  ...,  4.8354e-01,\n",
            "           -7.3315e-02,  1.1822e-01],\n",
            "          [ 8.5618e-01,  2.1846e-01,  3.7437e-01,  ..., -3.8353e-01,\n",
            "            4.6662e-02, -4.4748e-01],\n",
            "          [ 2.1813e-01, -8.7266e-01,  4.1684e-01,  ...,  8.8653e-01,\n",
            "           -2.1144e-01,  3.3476e-02],\n",
            "          ...,\n",
            "          [-8.5353e-02,  3.0955e-01,  3.4070e-01,  ..., -2.5316e-02,\n",
            "            2.9895e-01,  2.1840e-01],\n",
            "          [-1.6780e-01,  4.8091e-01,  1.4109e-01,  ..., -1.1442e+00,\n",
            "            4.9281e-01, -2.8239e-01],\n",
            "          [-4.3380e-01,  6.4910e-01, -1.5622e+00,  ..., -5.9204e-01,\n",
            "            1.4176e-01, -3.7923e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 4.2907e-01, -5.9472e-01, -2.6448e-01,  ..., -4.5448e-01,\n",
            "            4.0015e-01,  4.2974e-01],\n",
            "          [-7.0189e-01, -1.0266e-01,  5.2317e-02,  ...,  4.0448e-01,\n",
            "            6.0642e-01, -5.3929e-02],\n",
            "          [ 1.7268e-01, -4.0991e-01,  3.4980e-02,  ..., -3.4663e-01,\n",
            "           -2.3146e-01, -1.3080e-01],\n",
            "          ...,\n",
            "          [ 1.0426e+00, -3.9636e-01,  2.5972e-01,  ...,  5.0015e-01,\n",
            "            3.4868e-02, -1.2391e-01],\n",
            "          [ 8.2592e-01,  1.9196e-01, -9.3295e-01,  ..., -4.2723e-01,\n",
            "            2.0045e-01, -7.2757e-01],\n",
            "          [ 5.8068e-01, -3.0155e-01, -1.0915e+00,  ...,  9.1318e-02,\n",
            "            2.7761e-01,  3.0816e-01]],\n",
            "\n",
            "         [[-4.7098e-01,  1.6016e-01, -8.4921e-01,  ...,  1.2887e-01,\n",
            "            6.9744e-01,  2.1972e-02],\n",
            "          [-2.6358e-01,  1.1125e-01, -4.5085e-01,  ..., -1.6656e-01,\n",
            "           -5.4155e-02, -6.0830e-01],\n",
            "          [-5.6396e-01,  8.5009e-01,  2.9569e-01,  ..., -1.2206e+00,\n",
            "           -1.3437e+00,  6.5889e-01],\n",
            "          ...,\n",
            "          [-3.1558e-01,  2.6017e-01, -4.6709e-01,  ..., -3.7457e-01,\n",
            "           -9.6094e-01,  2.1124e-01],\n",
            "          [-3.7973e-01, -1.8182e-01, -4.2587e-01,  ...,  2.2266e-01,\n",
            "            1.4660e-01, -8.3172e-02],\n",
            "          [-1.1744e-01, -2.3136e-01,  5.0645e-01,  ..., -6.4111e-02,\n",
            "           -4.9213e-01,  8.7252e-01]],\n",
            "\n",
            "         [[ 2.7018e-01, -2.7741e-01, -7.7404e-02,  ...,  5.9005e-01,\n",
            "           -6.1312e-02,  1.8732e-01],\n",
            "          [ 4.1397e-02, -5.9135e-01, -1.7611e-01,  ...,  3.1066e-01,\n",
            "            1.0942e-01, -1.2266e-01],\n",
            "          [-2.2982e-01, -1.7114e-01, -2.8146e-01,  ..., -8.8879e-01,\n",
            "            6.6469e-01,  1.6379e-03],\n",
            "          ...,\n",
            "          [ 2.2681e-02, -6.1773e-01,  5.7905e-02,  ..., -5.2148e-01,\n",
            "           -1.4172e-01,  4.0255e-01],\n",
            "          [ 4.3450e-01, -3.1462e-01,  4.6135e-01,  ...,  8.2591e-02,\n",
            "            2.1647e-01, -4.1586e-01],\n",
            "          [ 3.4730e-01, -3.1720e-01,  1.7643e-01,  ...,  2.3237e-02,\n",
            "           -2.3485e-01,  1.1288e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.8486e-01,  9.6539e-02,  8.7259e-02,  ..., -5.3006e-02,\n",
            "           -3.6816e-01, -1.6731e-01],\n",
            "          [-2.9684e-02, -2.3344e-01,  3.9933e-01,  ..., -1.4425e-01,\n",
            "           -2.6763e-01,  2.6144e-01],\n",
            "          [ 3.7789e-02, -2.3000e-02, -1.7918e-02,  ...,  2.9057e-01,\n",
            "           -1.3503e-01,  7.5511e-02],\n",
            "          ...,\n",
            "          [-2.6077e-02, -6.8875e-01,  3.5914e-01,  ..., -6.1342e-01,\n",
            "           -5.6534e-02,  1.4305e-01],\n",
            "          [ 1.7543e-02, -3.3200e-01, -1.1738e+00,  ..., -1.0829e-01,\n",
            "            3.0799e-01,  4.0229e-01],\n",
            "          [-1.2562e-02,  2.0029e-01, -1.9500e-01,  ..., -6.8535e-01,\n",
            "           -3.1822e-01, -4.4005e-01]],\n",
            "\n",
            "         [[ 2.8530e-01,  5.7252e-01, -1.1895e-01,  ..., -1.6774e-01,\n",
            "           -1.8504e-02, -3.0470e-01],\n",
            "          [ 1.2639e-01, -3.2013e-01, -6.6919e-01,  ..., -5.5583e-02,\n",
            "           -6.3846e-01,  2.4559e-01],\n",
            "          [-3.2934e-01,  9.9343e-01,  7.2249e-01,  ...,  1.1212e+00,\n",
            "            2.5550e-01,  1.5096e-01],\n",
            "          ...,\n",
            "          [-2.3620e-01,  5.4917e-01, -3.9043e-01,  ..., -4.1653e-01,\n",
            "            1.0985e-03, -1.8099e-02],\n",
            "          [-4.0589e-01, -2.6429e-01,  4.8800e-01,  ...,  6.8308e-01,\n",
            "           -3.7970e-01, -4.9386e-01],\n",
            "          [ 5.6137e-01,  1.9008e-01,  5.5274e-01,  ...,  1.7962e-01,\n",
            "           -2.1786e-02, -1.6299e-01]],\n",
            "\n",
            "         [[-4.7253e-01,  5.8192e-01,  1.7172e-01,  ...,  2.1424e-01,\n",
            "           -3.2057e-01, -2.3135e-01],\n",
            "          [-5.4946e-01,  3.7459e-01,  6.5267e-03,  ...,  2.9366e-01,\n",
            "           -2.8181e-01, -3.7901e-01],\n",
            "          [ 7.3560e-02,  4.5886e-01,  6.8106e-01,  ...,  5.9871e-01,\n",
            "            2.6916e-01,  1.1831e-01],\n",
            "          ...,\n",
            "          [-2.7269e-01,  5.6792e-01, -6.8794e-01,  ...,  7.4873e-01,\n",
            "           -2.1186e-02, -5.2664e-02],\n",
            "          [-8.0189e-02, -3.7539e-01,  3.5283e-01,  ...,  1.9541e-01,\n",
            "            7.0489e-01,  1.1744e-01],\n",
            "          [-6.6682e-01, -2.1424e-01,  3.9989e-01,  ..., -3.4764e-01,\n",
            "           -2.7680e-01, -8.0234e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.3526e-01, -3.7621e-01, -5.2183e-02,  ...,  2.0803e-01,\n",
            "            5.7922e-03, -3.6340e-01],\n",
            "          [-7.9289e-03, -2.3714e-01, -3.1138e-01,  ...,  7.2089e-01,\n",
            "           -2.5762e-01, -3.1519e-01],\n",
            "          [-3.5326e-01, -5.6287e-01,  1.1888e+00,  ..., -1.0675e+00,\n",
            "            1.1226e-01, -9.4720e-01],\n",
            "          ...,\n",
            "          [-3.1578e-01, -7.5193e-01,  9.6142e-01,  ...,  1.4034e+00,\n",
            "           -6.4859e-01,  4.6835e-01],\n",
            "          [-3.7114e-01, -7.7636e-01, -2.4857e-01,  ...,  9.8895e-02,\n",
            "            6.5981e-02, -3.3477e-01],\n",
            "          [ 2.1723e-02, -4.5200e-01,  9.2364e-02,  ...,  3.0282e-01,\n",
            "           -6.1555e-01,  3.0253e-01]],\n",
            "\n",
            "         [[-9.2401e-02,  9.8259e-02,  1.6332e-01,  ..., -1.1252e-02,\n",
            "           -2.2726e-01, -3.6050e-01],\n",
            "          [ 2.8643e-01,  2.5836e-02,  4.8370e-01,  ...,  5.5084e-01,\n",
            "           -5.5980e-01, -7.6695e-01],\n",
            "          [-1.7172e-01,  3.8026e-02,  9.0045e-01,  ..., -1.3077e-01,\n",
            "            1.0857e+00, -3.6557e-01],\n",
            "          ...,\n",
            "          [-9.8654e-01,  7.2389e-02,  9.9321e-01,  ..., -9.4252e-01,\n",
            "            3.5462e-01,  9.7343e-02],\n",
            "          [ 3.5853e-01, -4.3509e-01,  3.0149e-01,  ..., -5.7969e-01,\n",
            "           -5.6410e-01,  1.5042e-01],\n",
            "          [-2.2759e-01,  3.6048e-01,  5.1515e-01,  ...,  6.5022e-02,\n",
            "           -4.9577e-01, -1.9115e-02]],\n",
            "\n",
            "         [[ 3.6383e-01, -1.7403e-01, -7.0915e-01,  ..., -2.0536e-01,\n",
            "           -1.8515e-01, -1.7506e-01],\n",
            "          [ 2.9479e-01,  1.2027e+00,  2.4236e-01,  ...,  8.4228e-01,\n",
            "           -6.9416e-01,  2.1189e-01],\n",
            "          [-2.3227e-01, -4.2536e-01,  4.8214e-01,  ..., -7.3810e-01,\n",
            "            9.8716e-02, -3.3186e-01],\n",
            "          ...,\n",
            "          [ 5.1308e-01,  5.5275e-02,  4.8242e-01,  ..., -2.1614e-01,\n",
            "           -5.4784e-01, -2.5875e-01],\n",
            "          [ 2.3643e-01,  3.5797e-01,  3.2635e-01,  ..., -1.6481e-01,\n",
            "            9.5923e-02,  4.0013e-01],\n",
            "          [ 6.0928e-01, -2.0141e-01, -7.3060e-01,  ...,  1.3656e-01,\n",
            "            4.1747e-01,  4.0379e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.4075e-01,  3.6696e-02, -1.0435e-01,  ..., -1.7426e-01,\n",
            "            3.3395e-01,  9.7554e-02],\n",
            "          [ 2.1058e-01, -7.4137e-01,  1.8633e-02,  ..., -4.1718e-01,\n",
            "           -6.9052e-02,  2.8281e-01],\n",
            "          [-6.2396e-02, -1.4740e-01,  2.0113e-01,  ..., -5.0255e-02,\n",
            "           -2.8887e-01,  1.9680e-01],\n",
            "          ...,\n",
            "          [-4.0983e-02, -9.3693e-01,  1.5378e-01,  ...,  7.3077e-01,\n",
            "           -4.3136e-01, -8.0921e-01],\n",
            "          [ 6.1603e-02, -3.6759e-01,  4.4964e-01,  ..., -3.4775e-01,\n",
            "           -4.2343e-01,  6.9117e-02],\n",
            "          [ 2.2824e-01,  9.6251e-03,  2.7226e-01,  ..., -4.2954e-01,\n",
            "            3.7096e-01,  3.1754e-01]],\n",
            "\n",
            "         [[ 2.1396e-01,  1.4326e-01,  3.2556e-01,  ..., -8.2319e-02,\n",
            "            2.6378e-01, -3.7063e-01],\n",
            "          [-3.8477e-01, -3.1323e-01,  4.4913e-02,  ..., -3.9084e-01,\n",
            "            7.9924e-01,  6.1371e-02],\n",
            "          [-1.4290e+00, -3.4037e-01,  1.7029e+00,  ...,  9.0201e-01,\n",
            "            5.1018e-01, -8.7622e-02],\n",
            "          ...,\n",
            "          [ 4.0199e-03,  3.5863e-03,  5.8512e-01,  ..., -9.7044e-01,\n",
            "            4.3642e-01,  9.6606e-02],\n",
            "          [-3.0189e-01, -2.5216e-01,  2.7817e-01,  ...,  7.2777e-01,\n",
            "           -1.4388e-01, -2.4327e-01],\n",
            "          [-2.8445e-01, -3.3051e-01,  3.6617e-01,  ...,  4.1976e-02,\n",
            "           -7.6844e-02,  3.7576e-01]],\n",
            "\n",
            "         [[-2.8277e-01, -3.9203e-01,  5.0288e-02,  ...,  1.9714e-01,\n",
            "           -4.1131e-01,  1.6069e-01],\n",
            "          [ 1.2516e-02, -1.9578e-01, -7.7510e-01,  ..., -3.6999e-01,\n",
            "            1.7604e-01,  1.7806e-01],\n",
            "          [-6.4376e-01,  4.7011e-01, -1.0547e+00,  ..., -2.0802e-01,\n",
            "            7.1077e-01, -4.1548e-01],\n",
            "          ...,\n",
            "          [ 4.3956e-01,  1.9762e-01, -5.7212e-01,  ..., -3.5125e-01,\n",
            "            9.0174e-02,  1.3427e-01],\n",
            "          [-1.4272e-01,  9.3296e-02, -1.5393e-01,  ...,  4.5947e-01,\n",
            "           -5.0061e-01, -3.1574e-01],\n",
            "          [-9.9108e-01,  1.7834e-01, -1.1429e-01,  ..., -1.1430e-01,\n",
            "           -6.7232e-02,  3.3930e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.7446e-01,  6.9204e-02, -2.5148e-01,  ..., -4.5814e-02,\n",
            "           -7.8123e-02,  3.4686e-02],\n",
            "          [ 8.2409e-02,  2.7031e-01, -2.6854e-01,  ...,  4.8595e-02,\n",
            "            4.9968e-01, -2.7448e-01],\n",
            "          [-8.5312e-01, -6.5898e-02,  8.5368e-02,  ...,  3.2987e-01,\n",
            "           -3.5568e-01, -7.8469e-01],\n",
            "          ...,\n",
            "          [ 3.4062e-01,  8.1270e-02,  6.9875e-02,  ..., -2.9112e-01,\n",
            "           -2.6486e-01, -1.8814e-01],\n",
            "          [-1.2540e-01, -8.1500e-01, -3.4104e-01,  ..., -8.4462e-01,\n",
            "            4.6753e-02,  1.7402e-01],\n",
            "          [ 3.6357e-01,  6.6153e-01,  5.9380e-01,  ...,  2.1615e-01,\n",
            "           -2.9214e-01,  2.7769e-01]],\n",
            "\n",
            "         [[-2.9338e-01,  9.3850e-02,  2.2178e-01,  ..., -5.5193e-02,\n",
            "            1.5697e-01, -3.2893e-01],\n",
            "          [-3.7072e-01,  3.0081e-01, -1.2069e-01,  ..., -2.1514e-01,\n",
            "            1.2017e-01,  4.9525e-01],\n",
            "          [-4.4216e-01, -2.8627e-01, -1.2512e+00,  ...,  4.8328e-02,\n",
            "           -4.8685e-01, -6.8107e-01],\n",
            "          ...,\n",
            "          [-1.1121e-01,  8.0831e-01, -3.6027e-01,  ..., -1.2860e-01,\n",
            "           -2.9184e-01,  4.3351e-01],\n",
            "          [-1.0316e-01,  4.3265e-01, -4.4298e-01,  ..., -8.2396e-01,\n",
            "           -1.8698e-02, -3.0726e-01],\n",
            "          [ 2.1343e-01, -5.7870e-01,  1.1992e-01,  ...,  9.3959e-01,\n",
            "            3.4089e-01, -3.5338e-01]],\n",
            "\n",
            "         [[ 9.8283e-02, -2.7147e-01,  1.0613e-01,  ...,  7.7180e-01,\n",
            "            7.5529e-01, -1.2293e-02],\n",
            "          [-4.8765e-01, -2.9011e-01, -4.2015e-01,  ..., -2.7994e-01,\n",
            "           -8.8301e-01,  3.1205e-01],\n",
            "          [ 4.5177e-01, -9.0376e-01, -2.7813e-01,  ..., -1.1811e-01,\n",
            "            3.2782e-01, -2.3127e-01],\n",
            "          ...,\n",
            "          [ 9.3723e-01,  5.2657e-01,  6.4776e-01,  ...,  1.6114e+00,\n",
            "           -6.1517e-01,  7.1287e-01],\n",
            "          [ 4.5210e-01, -3.2448e-01,  5.4507e-01,  ..., -1.1216e+00,\n",
            "           -1.1801e-01, -3.9024e-01],\n",
            "          [-1.2176e-01,  1.0581e-01,  3.3689e-01,  ...,  3.5767e-01,\n",
            "           -7.6020e-02, -1.4911e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.3248e-01, -6.7737e-02,  1.4456e-01,  ...,  3.6206e-02,\n",
            "            1.9713e-01,  8.4254e-02],\n",
            "          [ 5.8110e-02,  4.7541e-01,  1.6543e-01,  ..., -1.6064e-01,\n",
            "            3.1529e-01, -5.5047e-02],\n",
            "          [-4.7172e-01, -1.6729e-01,  8.3630e-01,  ...,  1.0815e+00,\n",
            "            7.5645e-01,  6.2686e-01],\n",
            "          ...,\n",
            "          [-5.4084e-01,  4.0323e-01,  2.2265e-01,  ...,  4.6619e-01,\n",
            "            1.1223e+00, -5.9419e-01],\n",
            "          [-2.4393e-01,  1.8222e-01,  1.1043e+00,  ..., -6.1174e-01,\n",
            "            5.9636e-02,  3.4151e-01],\n",
            "          [-2.9451e-01,  1.5018e-01, -4.5463e-02,  ..., -5.5099e-01,\n",
            "           -5.2218e-01, -4.8571e-02]],\n",
            "\n",
            "         [[-1.2307e-01, -1.4244e-01,  1.0064e+00,  ..., -2.4356e-02,\n",
            "           -4.4271e-02, -3.7636e-01],\n",
            "          [ 5.7374e-01,  2.4456e-01, -4.4954e-01,  ...,  5.5355e-03,\n",
            "           -4.6465e-02,  4.6192e-01],\n",
            "          [-1.8703e-02, -4.1480e-01, -1.5601e-01,  ...,  4.7633e-01,\n",
            "            4.2984e-01, -2.0248e-01],\n",
            "          ...,\n",
            "          [ 3.5675e-01,  3.1671e-01, -1.4434e-01,  ...,  4.1498e-01,\n",
            "            3.5634e-01, -4.4818e-02],\n",
            "          [-1.5288e-01,  9.2972e-02,  3.0194e-01,  ..., -8.4739e-02,\n",
            "            5.7332e-01, -1.6513e-01],\n",
            "          [ 4.3610e-01,  4.0076e-01, -3.3505e-01,  ...,  2.7780e-01,\n",
            "            2.1016e-01, -3.1247e-01]],\n",
            "\n",
            "         [[ 3.0903e-01, -1.6403e-01,  2.2871e-01,  ..., -1.5702e-01,\n",
            "            1.2532e-01, -1.9184e-01],\n",
            "          [ 5.9749e-02,  9.1235e-02, -6.7411e-02,  ..., -3.6856e-01,\n",
            "           -8.1976e-01, -1.7930e-01],\n",
            "          [-1.6277e-01, -4.1266e-02,  1.3426e-01,  ...,  1.1611e+00,\n",
            "           -2.0892e-02,  1.5166e-01],\n",
            "          ...,\n",
            "          [ 6.5458e-02, -1.0583e-01,  6.5173e-01,  ..., -4.0825e-02,\n",
            "            3.7715e-02,  4.2040e-01],\n",
            "          [-2.6010e-01, -7.8396e-01,  2.0976e-01,  ..., -1.9820e-01,\n",
            "           -1.0283e-01, -1.9479e-01],\n",
            "          [ 1.3387e-01, -2.1678e-01, -8.6783e-01,  ...,  8.2697e-01,\n",
            "            1.7823e-01, -9.8824e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.4418e-01, -1.6599e-01, -1.7179e-01,  ..., -3.1572e-01,\n",
            "            3.4050e-02, -2.4644e-01],\n",
            "          [ 1.1685e-01, -1.3955e-01, -2.0842e-01,  ...,  9.9573e-02,\n",
            "           -2.1824e-01,  4.9328e-01],\n",
            "          [-1.8749e-01,  1.1245e-02,  1.7480e-01,  ...,  6.6325e-01,\n",
            "            1.4047e-01,  3.7263e-01],\n",
            "          ...,\n",
            "          [-2.3812e-01, -3.9619e-01, -5.0428e-01,  ...,  5.6366e-01,\n",
            "            5.4605e-01, -2.5242e-02],\n",
            "          [-1.9082e-01, -3.2024e-01, -3.6861e-01,  ..., -5.7378e-01,\n",
            "            3.4827e-01,  2.9189e-01],\n",
            "          [-4.0673e-01,  9.3046e-01, -1.9530e-01,  ..., -7.2184e-02,\n",
            "           -1.0547e-01, -1.8649e-01]],\n",
            "\n",
            "         [[-1.7390e-03,  7.1798e-02, -4.1565e-01,  ...,  9.4223e-02,\n",
            "           -6.1497e-02,  1.8161e-01],\n",
            "          [ 1.1598e-01, -1.8545e-01, -4.7143e-02,  ..., -2.1542e-01,\n",
            "            2.9448e-03, -3.5492e-01],\n",
            "          [ 4.3857e-02,  7.6810e-01, -2.2297e+00,  ...,  6.5899e-02,\n",
            "           -1.0451e+00,  2.7844e-01],\n",
            "          ...,\n",
            "          [-4.3420e-01, -3.1695e-01, -6.4572e-01,  ...,  4.2852e-01,\n",
            "            2.5684e-01, -1.9833e-01],\n",
            "          [-7.7285e-01, -6.4663e-01, -3.7829e-01,  ..., -3.4738e-01,\n",
            "           -4.6290e-01, -5.1741e-01],\n",
            "          [-4.6889e-01, -7.6072e-01, -1.1122e-01,  ...,  6.8742e-01,\n",
            "            2.8251e-01,  7.6857e-02]],\n",
            "\n",
            "         [[ 3.7340e-01,  1.4154e-01,  9.0770e-02,  ..., -3.4813e-01,\n",
            "           -1.6806e-01, -2.7384e-02],\n",
            "          [-3.4453e-01, -1.3085e-01, -2.6108e-02,  ...,  8.5549e-01,\n",
            "           -8.0890e-01,  1.4891e-01],\n",
            "          [-5.3585e-01, -4.0193e-01, -8.3521e-01,  ..., -2.9865e-02,\n",
            "            1.0797e+00,  8.8138e-01],\n",
            "          ...,\n",
            "          [ 3.0731e-01,  3.4797e-01, -9.4902e-01,  ...,  5.0374e-01,\n",
            "            8.9917e-02, -9.5090e-01],\n",
            "          [ 8.7031e-03, -3.7977e-01, -4.8342e-01,  ..., -5.8176e-01,\n",
            "            2.5429e-01, -2.9816e-01],\n",
            "          [ 3.7410e-01,  1.6463e-01,  8.6638e-01,  ..., -2.5729e-01,\n",
            "           -1.1252e-01, -8.0987e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-8.8340e-02, -2.4876e-01,  7.8543e-01,  ...,  1.1092e-01,\n",
            "           -4.4770e-02,  3.3548e-01],\n",
            "          [ 4.2535e-02, -3.0719e-01,  2.0399e-01,  ...,  4.0164e-01,\n",
            "            5.3933e-01,  1.1428e-01],\n",
            "          [-1.8360e-01,  5.0278e-02,  3.8107e-01,  ...,  9.1982e-01,\n",
            "           -4.3576e-01, -4.7705e-02],\n",
            "          ...,\n",
            "          [-4.2521e-02,  7.8789e-01,  3.7487e-01,  ...,  3.9772e-01,\n",
            "           -1.6912e-01,  4.5546e-01],\n",
            "          [ 2.3229e-01, -3.0830e-01, -7.2104e-02,  ...,  6.3224e-02,\n",
            "           -5.4861e-01, -2.1054e-01],\n",
            "          [ 1.1831e-01, -8.3769e-02, -1.5014e+00,  ...,  4.0489e-01,\n",
            "            2.9866e-01,  1.7849e-01]],\n",
            "\n",
            "         [[-8.4939e-02,  1.0797e-02, -1.9965e-01,  ...,  2.2802e-02,\n",
            "           -5.7051e-01,  2.3989e-01],\n",
            "          [-2.9802e-01,  5.9178e-01,  1.5269e+00,  ..., -2.4005e-01,\n",
            "           -5.8846e-02, -1.4116e-01],\n",
            "          [-1.8463e-01,  5.9181e-01,  6.3909e-01,  ..., -6.7960e-01,\n",
            "           -9.6606e-02, -5.9665e-01],\n",
            "          ...,\n",
            "          [ 4.7030e-01,  6.7933e-01,  2.9919e-02,  ...,  9.6701e-01,\n",
            "           -1.3062e-01,  4.0264e-01],\n",
            "          [-3.3127e-01,  1.6300e-01,  2.8913e-01,  ...,  8.2389e-03,\n",
            "            5.7854e-01,  1.9334e-01],\n",
            "          [ 3.4019e-01,  1.8519e-01, -6.5845e-02,  ...,  4.6358e-01,\n",
            "            3.7242e-01, -5.2385e-01]],\n",
            "\n",
            "         [[ 1.5709e-02, -3.6175e-01, -6.8060e-01,  ...,  4.0092e-01,\n",
            "           -6.8521e-01,  2.7784e-02],\n",
            "          [ 1.0104e-01, -4.7450e-01, -4.0127e-01,  ..., -6.9650e-01,\n",
            "            7.2840e-01,  6.2832e-01],\n",
            "          [ 4.8926e-01,  2.6447e-01, -8.5293e-01,  ...,  8.0690e-02,\n",
            "            2.9708e-01,  4.0018e-01],\n",
            "          ...,\n",
            "          [-1.9206e-01, -4.5012e-01,  2.2218e-01,  ...,  1.3394e+00,\n",
            "            1.6355e-01, -7.6054e-01],\n",
            "          [-2.0603e-01, -1.5903e-01,  3.1618e-01,  ...,  5.8555e-01,\n",
            "            2.0887e-01,  4.4621e-01],\n",
            "          [ 1.9141e-02,  2.8380e-01, -1.8604e-01,  ..., -4.4293e-01,\n",
            "            6.8315e-01, -1.2620e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.0272e-01,  2.4803e-02,  1.2716e-01,  ...,  1.3349e-01,\n",
            "           -1.7261e-01, -9.6022e-02],\n",
            "          [-4.2225e-01,  1.1087e+00, -5.4141e-01,  ..., -6.9515e-01,\n",
            "           -5.8896e-01,  1.1229e-01],\n",
            "          [-3.6031e-01, -2.6674e-01, -7.0266e-01,  ..., -6.0998e-01,\n",
            "           -3.0383e-01, -9.2215e-01],\n",
            "          ...,\n",
            "          [-2.0298e-01, -3.5872e-01, -1.8832e+00,  ..., -1.0087e-01,\n",
            "           -1.0425e+00, -4.6456e-01],\n",
            "          [ 1.4374e-02, -1.4601e-01, -4.8847e-01,  ..., -6.5123e-01,\n",
            "           -8.3021e-02, -1.3499e-01],\n",
            "          [-2.4821e-01,  1.3633e-01,  3.2939e-01,  ...,  1.3468e-01,\n",
            "           -1.8420e-01,  3.7053e-01]],\n",
            "\n",
            "         [[ 7.9810e-02,  1.2173e-01, -1.3473e-01,  ...,  2.1206e-01,\n",
            "            5.3114e-01,  3.9385e-02],\n",
            "          [ 8.1137e-01, -3.1207e-01, -3.4206e-01,  ...,  1.6611e-01,\n",
            "            9.7161e-01,  2.8587e-01],\n",
            "          [-5.3110e-01, -3.4524e-01,  9.3375e-02,  ...,  3.5067e-01,\n",
            "           -7.7297e-01, -3.8255e-01],\n",
            "          ...,\n",
            "          [-4.2387e-01, -3.0820e-01, -7.5977e-01,  ..., -6.9508e-01,\n",
            "            1.9196e-01, -4.2972e-01],\n",
            "          [ 3.7748e-01,  5.3325e-01, -6.0532e-03,  ..., -6.6992e-01,\n",
            "            1.3983e-01,  2.0076e-01],\n",
            "          [-2.1228e-01,  2.2147e-01, -6.2441e-01,  ...,  1.4490e-01,\n",
            "           -3.1258e-02,  2.9345e-01]],\n",
            "\n",
            "         [[ 2.7981e-01,  1.1404e-01,  6.6145e-01,  ...,  7.2359e-02,\n",
            "            1.3450e-01, -4.9123e-02],\n",
            "          [ 5.3306e-01,  7.5724e-01,  8.5452e-01,  ..., -4.5305e-01,\n",
            "            2.7617e-01,  2.9807e-01],\n",
            "          [-2.9405e-01,  2.7415e-01, -4.6438e-01,  ..., -7.0135e-01,\n",
            "            9.0735e-03, -4.9816e-01],\n",
            "          ...,\n",
            "          [ 2.6670e-01, -5.6623e-01,  1.1798e+00,  ..., -2.5405e-01,\n",
            "           -4.7351e-01, -2.5135e-01],\n",
            "          [ 1.9203e-01, -1.0954e-01, -1.1759e-01,  ..., -6.5176e-02,\n",
            "           -1.7077e-01,  4.6642e-01],\n",
            "          [ 2.0224e-01, -1.1114e-01,  9.4936e-01,  ..., -4.8697e-02,\n",
            "            8.2026e-02,  3.1735e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.4073e-01, -6.6387e-02,  7.5112e-02,  ..., -3.0100e-02,\n",
            "           -3.6138e-01,  4.2763e-01],\n",
            "          [-1.8964e-01,  3.2717e-01, -2.8973e-02,  ..., -3.0624e-01,\n",
            "           -9.9793e-01, -2.6596e-01],\n",
            "          [-2.0429e-01,  7.5868e-01,  3.7501e-01,  ..., -3.6881e-01,\n",
            "            7.3638e-01,  5.5392e-02],\n",
            "          ...,\n",
            "          [-2.4240e-01,  7.5578e-01,  1.0433e+00,  ..., -3.5211e-01,\n",
            "            7.5116e-01, -6.1975e-01],\n",
            "          [-2.8809e-01,  5.0833e-01, -2.3120e-02,  ..., -2.6434e-01,\n",
            "           -6.6330e-01, -3.9496e-02],\n",
            "          [-4.2110e-01,  4.8214e-02, -4.2788e-01,  ...,  4.6636e-02,\n",
            "            7.1747e-01,  1.1547e-01]],\n",
            "\n",
            "         [[-3.8772e-01, -4.1108e-01, -5.1253e-01,  ...,  1.1782e-01,\n",
            "           -1.0626e-01,  6.7099e-03],\n",
            "          [-4.0474e-01, -6.3867e-01,  2.4377e-01,  ...,  6.0929e-01,\n",
            "           -8.2569e-01,  3.3818e-01],\n",
            "          [-7.2867e-01,  3.2803e-01, -8.8098e-01,  ...,  9.7693e-02,\n",
            "           -1.1673e-01, -8.6843e-01],\n",
            "          ...,\n",
            "          [-6.8575e-01, -7.4752e-01, -2.2841e-01,  ..., -5.3707e-01,\n",
            "           -2.5336e-01,  1.8449e-01],\n",
            "          [ 4.9207e-01,  2.1882e-01,  7.8963e-01,  ..., -2.0864e-01,\n",
            "            1.7230e-01,  3.4210e-02],\n",
            "          [ 4.3044e-02, -4.7618e-01, -6.5855e-01,  ...,  1.8674e-01,\n",
            "           -1.6948e-01,  2.8313e-03]],\n",
            "\n",
            "         [[ 1.1044e-01, -5.1581e-01, -4.5410e-01,  ..., -4.7818e-02,\n",
            "            1.8633e-01, -2.8232e-01],\n",
            "          [-1.7111e-01, -1.4238e-01, -6.3886e-02,  ..., -2.7795e-01,\n",
            "            1.0679e+00, -4.8935e-01],\n",
            "          [ 6.2440e-01,  3.2452e-01,  7.0391e-01,  ...,  4.0832e-01,\n",
            "           -4.8317e-01,  1.4668e-01],\n",
            "          ...,\n",
            "          [-1.0381e+00,  2.1801e-01,  8.5529e-01,  ..., -8.0799e-01,\n",
            "           -1.6612e-01,  1.7166e-01],\n",
            "          [-3.7267e-01,  5.8682e-01, -1.4958e-01,  ..., -4.0631e-01,\n",
            "            5.3087e-01, -1.9612e-01],\n",
            "          [-4.1967e-01,  1.0950e-02, -1.3873e-01,  ...,  2.8639e-01,\n",
            "            1.1664e-01, -2.4766e-01]]]], grad_fn=<MkldnnConvolutionBackward>)\n"
          ]
        }
      ],
      "source": [
        "m = nn.Conv2d(16, 33, 3, stride=2)\n",
        "\n",
        "m = nn.Conv2d(16, 33, (3, 5), stride=(2,1), padding=(4,2))\n",
        "\n",
        "m = nn.Conv2d(16, 33, (3, 5), stride=(2,1), padding=(4,2), dilation=(3,1))\n",
        "\n",
        "input = torch.randn(20, 16, 50, 100)\n",
        "print(input)\n",
        "output = m(input)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "RLqGbclbp3_N"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([20, 33, 26, 100])"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYeGAJEuneqW"
      },
      "source": [
        "### nn.functional 패키지\n",
        "\n",
        "- 가중치를 직접 선언하여 인자로 넣어줘야함\n",
        "\n",
        "- 예시)\n",
        "  - Convolution functions\n",
        "\n",
        "  - Pooling functions\n",
        "  \n",
        "  - Non-linear activation functions\n",
        "\n",
        "  - Normalization functions\n",
        "\n",
        "  - Linear functions\n",
        "\n",
        "  - Dropout functions\n",
        "  \n",
        "  - Sparse functions\n",
        "  \n",
        "  - Distance functions\n",
        "\n",
        "  - Loss functions\n",
        "  - ..\n",
        "\n",
        "- https://pytorch.org/docs/stable/nn.functional.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "NpwbO9Dhpflm"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUYaJ5aLqKed"
      },
      "source": [
        "- Convolution Layer 예시 (2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "GAWLQE2GouHP"
      },
      "outputs": [],
      "source": [
        "filters = torch.randn(8, 4, 3, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "lWmSlFBrpms1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 5, 5])"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs = torch.randn(1,4,5,5)\n",
        "conv = F.conv2d(inputs, filters, padding=1)\n",
        "conv.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wah4RsmgrRDP"
      },
      "source": [
        "## Torchvision\n",
        "\n",
        "- `transforms`: 전처리할 때 사용하는 메소드\n",
        "\n",
        "- `transforms`에서 제공하는 클래스 이외에  \n",
        "  일반적으로 클래스를 따로 만들어 전처리 단계를 진행\n",
        "  \n",
        "  - 아래의 코드에서 다양한 전처리 기술 확인  \n",
        "    https://pytorch.org/docs/stable/torchvision/transforms.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "akvq4QWmqSil"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKu5mzyTs-Qj"
      },
      "source": [
        "- 예시)\n",
        "  - `DataLoader`의 인자로 들어갈 `transform`을 미리 정의할 수 있음\n",
        "\n",
        "  - `Compose`를 통해 리스트 안에 순서대로 전처리 진행\n",
        "\n",
        "  - 대표적인 예로, `ToTensor`()를 하는 이유는  \n",
        "   <u>torchvision이 PIL Image형태로만 입력을 받기 때문에</u> 데이터 처리를 위해서 Tensor형으로 변환해야함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "y6K7FH-Rs9my"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.5), std=(0.5))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4l1GvIlslKa"
      },
      "source": [
        "## utils.data\n",
        "\n",
        "- `Dataset`에는 다양한 데이터셋이 존재  \n",
        "  - MNIST, CIFAR10, ...\n",
        "\n",
        "- `DataLoader`, `Dataset`을 통해  \n",
        "  `batch_size`, `train`여부, `transform`등을 인자로 넣어 데이터를 어떻게 load할 것인지 정해줄 수 있음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "1wsZKY7-s2Vv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "lldpI2lquBu3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /content/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /content/MNIST\\raw\\train-images-idx3-ubyte.gz to /content/MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /content/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "102.8%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /content/MNIST\\raw\\train-labels-idx1-ubyte.gz to /content/MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /content/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /content/MNIST\\raw\\t10k-images-idx3-ubyte.gz to /content/MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /content/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "112.7%"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /content/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to /content/MNIST\\raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "C:\\Users\\poeun\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ]
        }
      ],
      "source": [
        "trainset = torchvision.datasets.MNIST(\n",
        "    root='/content/',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(\n",
        "    root='/content/',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "fKddZnT1uQmT"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(trainset, batch_size=8, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(testset, batch_size=8, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrxymquLxeo8"
      },
      "source": [
        "- `batch_size`만큼 데이터를 하나씩 가져옴"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "hvgMIyF6uUuU"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([8, 1, 28, 28]), torch.Size([8]))"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "images.shape, labels.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPUC0a0aw6OM"
      },
      "source": [
        "<u>**(중요) torch에서는 channel(채널)이 앞에 옴**</u>\n",
        "\n",
        "- `channel first`\n",
        "\n",
        "- tensorflow, keras 등에서는 channel이 뒤에 옴(`channel last`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuhylD3iyFYr"
      },
      "source": [
        "### 데이터 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "C9hAQmQlul8P"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-white')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "zDcUY6o4xUQp"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([28, 28])"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch_image = torch.squeeze(images[0])\n",
        "torch_image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "MZmPWiGbxoiW"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image = torch_image.numpy()\n",
        "image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "AUOdd4UaxaXO"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label = labels[0].numpy()\n",
        "label.shape # 스칼라"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "PDQfjw4wxr1z"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(6, dtype=int64)"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "JDCVw59ax3-A"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.title(label)\n",
        "plt.imshow(image, 'gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVcWQlxzihtS"
      },
      "source": [
        "## 각 Layer 설명"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "IGXn1_weif5H"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73kJ3heBi26y"
      },
      "source": [
        "### nn.Conv2d\n",
        "\n",
        "- `in_channels`: channel의 갯수\n",
        "\n",
        "- `out_channels`: 출력 채널의 갯수\n",
        "\n",
        "- `kernel_size`: 커널(필터) 사이즈\n",
        "\n",
        "- 텐서플로우, 케라스와 다르게 레이어의 `input`인자에도 값을 집어 넣어줘야함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "RcHJguyFipTl"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5, stride=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "iWiJbViHjFG0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "layer = nn.Conv2d(1, 20, 5, 1).to(torch.device('cpu'))\n",
        "layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxWYFm2xjUeN"
      },
      "source": [
        "- `wegiht`확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "za0enRbyjPzV"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([20, 1, 5, 5])"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weight = layer.weight\n",
        "weight.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAZcTU2gjiCX"
      },
      "source": [
        "- `weight`는 `detach()`를 통해 꺼내줘야 `numpy()`변환이 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "9eN_oUBkjT85"
      },
      "outputs": [],
      "source": [
        "weight = weight.detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "kwso9tsijmz8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20, 1, 5, 5)"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weight = weight.numpy()\n",
        "weight.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "mUegf6HPjdPl"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(weight[0, 0, :, :], 'jet')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "DMeTOqVmcdWa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "print(images.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "cvolnNsscdHs"
      },
      "outputs": [],
      "source": [
        "input_image = torch.unsqueeze(images[0], dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "NLOAfD5mjup1"
      },
      "outputs": [],
      "source": [
        "output_data = layer(input_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "r50wFkl6j1sY"
      },
      "outputs": [],
      "source": [
        "output = output_data.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "ZiIp-frJj2Hl"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 20, 24, 24)"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_arr = output.numpy()\n",
        "output_arr.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "uOHMu-UQkW3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x2a3af137108>"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1080x2160 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(15, 30))\n",
        "\n",
        "plt.subplot(131)\n",
        "plt.title('Input')\n",
        "plt.imshow(image, 'gray')\n",
        "plt.subplot(132)\n",
        "plt.title('Weight')\n",
        "plt.imshow(weight[0,0,:,:], 'jet')\n",
        "plt.subplot(133)\n",
        "plt.title('Output')\n",
        "plt.imshow(output_arr[0,0,:,:], 'gray')\n",
        "\n",
        "# layout 하나 통과한 결과"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sCqGmH_kwHm"
      },
      "source": [
        "### Pooling\n",
        "- `F.max_pool2d` \n",
        "  - `stride`\n",
        "\n",
        "  - `kernel_size`\n",
        "\n",
        "- `torch.nn.MaxPool2d` 도 많이 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "AYqPrLH1kxQl"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "tvI8W_8Yk81S"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 20, 12, 12])"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pool = F.max_pool2d(output, 2, 2)\n",
        "pool.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV3HK4FulCaJ"
      },
      "source": [
        "- MaxPool Layer는 weight가 없기 때문에 바로 `numpy()`변환 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "fseB_qlflBta"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 20, 12, 12)"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pool_arr = pool.numpy()\n",
        "pool_arr.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "6w8DQnNtlNCq"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x2a3af26a988>"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x1080 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(10, 15))\n",
        "plt.subplot(121)\n",
        "plt.title('Input')\n",
        "plt.imshow(image, 'gray')\n",
        "plt.subplot(122)\n",
        "plt.title('Output')\n",
        "plt.imshow(pool_arr[00,0,:,:], 'gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7RVioKwlbH1"
      },
      "source": [
        "### Linear\n",
        "- 1d만 가능 `.view()`를 통해 1D로 펼쳐줘야함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "Kwcedadrlcbl"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([28, 28])"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image = torch.from_numpy(image)\n",
        "image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "_mYQy4I3lmAm"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 784])"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "flatten = image.view(1, 28*28)\n",
        "flatten.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "6wgSmY0Zlofk"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 10])"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lin = nn.Linear(784, 10)(flatten)\n",
        "lin.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "LcJFqf0alsxr"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.5675, -0.5826,  0.2911, -0.2903,  0.2079,  0.0962, -0.9182,  0.0198,\n",
              "          0.0881,  1.1769]], grad_fn=<AddmmBackward>)"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "ewEpebSVluHz"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(lin.detach().numpy(), 'jet')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IjPKDKRl3CV"
      },
      "source": [
        "### Softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "obhBb3O-lzbs"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    flatten = image.view(1, 28*28)\n",
        "    lin = nn.Linear(784, 10)(flatten)\n",
        "    softmax = F.softmax(lin, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "ljgOEyNMmBEE"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0806, 0.0675, 0.0715, 0.1629, 0.0728, 0.0619, 0.1814, 0.0482, 0.0925,\n",
              "         0.1606]])"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "18ymFSRAmBo7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.sum(softmax.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYh13Bnj5wEN"
      },
      "source": [
        "### F.relu\n",
        "\n",
        "- ReLU 함수를 적용하는 레이어\n",
        "\n",
        "- `nn.ReLU`로도 사용 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "D4VFePpR9_Ak"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 3, 28, 28])"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs = torch.randn(4, 3, 28, 28).to(device)\n",
        "inputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "1lKlSiaY5wZW"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 20, 24, 24])"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "layer = nn.Conv2d(3, 20, 5, 1).to(device)\n",
        "output = F.relu(layer(inputs))\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yuABl4h-yye"
      },
      "source": [
        "## Optimizer\n",
        "\n",
        "- `import torch.optim as optim`\n",
        "\n",
        "- `model`의 파라미터를 업데이트\n",
        "\n",
        "- 예시)\n",
        "  ```python\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "  optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "  ```\n",
        "\n",
        "- `.zero_grad()`로 초기화\n",
        "- `.step()`으로 업데이트\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "_9 파이토치(PyTorch) 기초.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "79eb8b551db2b880459dff10818154367dbe519dd3f614e5f214e4642a67d99b"
    },
    "kernelspec": {
      "display_name": "Python 3.7.11 64-bit ('pytorch': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
